{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7SXF6jEBd5_"
   },
   "source": [
    "# Lambda School Data Science - Logistic Regression\n",
    "\n",
    "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7-AOngjadRN"
   },
   "source": [
    "## Lecture - Where Linear goes Wrong\n",
    "### Return of the Titanic 🚢\n",
    "\n",
    "You've likely already explored the rich dataset that is the Titanic - let's use regression and try to predict survival with it. The data is [available from Kaggle](https://www.kaggle.com/c/titanic/data), so we'll also play a bit with [the Kaggle API](https://github.com/Kaggle/kaggle-api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data, option 1: Kaggle API\n",
    "\n",
    "#### Sign up for Kaggle and get an API token\n",
    "1. [Sign up for a Kaggle account](https://www.kaggle.com/), if you don’t already have one. \n",
    "2. [Follow these instructions](https://github.com/Kaggle/kaggle-api#api-credentials) to create a Kaggle “API Token” and download your `kaggle.json` file. If you are using Anaconda, put the file in the directory specified in the instructions.\n",
    "\n",
    "_This will enable you to download data directly from Kaggle. If you run into problems, don’t worry — I’ll give you an easy alternative way to download today’s data, so you can still follow along with the lecture hands-on. And then we’ll help you through the Kaggle process after the lecture._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put `kaggle.json` in the correct location\n",
    "\n",
    "- ***If you're using Anaconda,*** put the file in the directory specified in the [instructions](https://github.com/Kaggle/kaggle-api#api-credentials).\n",
    "\n",
    "- ***If you're using Google Colab,*** upload the file to your Google Drive, and run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%env KAGGLE_CONFIG_DIR=/content/drive/My Drive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the Kaggle API package and use it to get the data\n",
    "\n",
    "You also have to join the Titanic competition to have access to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "MnHLWPYDcyIe",
    "outputId": "1d0b1c18-7dc4-46e0-8d52-2e3693868670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /anaconda3/lib/python3.7/site-packages (1.5.3)\n",
      "Requirement already satisfied: certifi in /anaconda3/lib/python3.7/site-packages (from kaggle) (2018.11.29)\n",
      "Requirement already satisfied: tqdm in /anaconda3/lib/python3.7/site-packages (from kaggle) (4.28.1)\n",
      "Requirement already satisfied: python-slugify in /anaconda3/lib/python3.7/site-packages (from kaggle) (3.0.2)\n",
      "Requirement already satisfied: six>=1.10 in /anaconda3/lib/python3.7/site-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil in /anaconda3/lib/python3.7/site-packages (from kaggle) (2.7.5)\n",
      "Requirement already satisfied: requests in /anaconda3/lib/python3.7/site-packages (from kaggle) (2.21.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from kaggle) (1.24.1)\n",
      "Requirement already satisfied: text-unidecode==1.2 in /anaconda3/lib/python3.7/site-packages (from python-slugify->kaggle) (1.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests->kaggle) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Downloading gender_submission.csv to /Users/azel/Documents/GitHub/DS-Unit-2-Sprint-3-Classification-Validation/module1-logistic-regression\n",
      "  0%|                                               | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 3.18k/3.18k [00:00<00:00, 1.79MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data, option 2: Download from the competition page\n",
    "1. [Sign up for a Kaggle account](https://www.kaggle.com/), if you don’t already have one. \n",
    "2. [Go to the Titanic competition page](https://www.kaggle.com/c/titanic) to download the [data](https://www.kaggle.com/c/titanic/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data, option 3: Use Seaborn\n",
    "\n",
    "```\n",
    "import seaborn as sns\n",
    "train = sns.load_dataset('titanic')\n",
    "```\n",
    "\n",
    "But Seaborn's version of the Titanic dataset is not identical to Kaggle's version, as we'll see during this lesson!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/azel/Documents/GitHub/DS-Unit-2-Sprint-3-Classification-Validation/module1-logistic-regression/train.csv')\n",
    "test = pd.read_csv('/Users/azel/Documents/GitHub/DS-Unit-2-Sprint-3-Classification-Validation/module1-logistic-regression/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would we try to do this with linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/impute.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fcxfpsjdFJwM",
    "outputId": "590a3bba-67fe-48b4-bf6e-91e67bd29bd4"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "features = ['Pclass','Age','Fare']\n",
    "target = 'Survived'\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        , 22.        ,  7.25      ],\n",
       "       [ 1.        , 38.        , 71.2833    ],\n",
       "       [ 3.        , 26.        ,  7.925     ],\n",
       "       [ 1.        , 35.        , 53.1       ],\n",
       "       [ 3.        , 35.        ,  8.05      ],\n",
       "       [ 3.        , 29.69911765,  8.4583    ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imputed[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age     Fare\n",
       "0       3  22.0   7.2500\n",
       "1       1  38.0  71.2833\n",
       "2       3  26.0   7.9250\n",
       "3       1  35.0  53.1000\n",
       "4       3  35.0   8.0500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>108.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.3583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age      Fare\n",
       "413       3   NaN    8.0500\n",
       "414       1  39.0  108.9000\n",
       "415       3  38.5    7.2500\n",
       "416       3   NaN    8.0500\n",
       "417       3   NaN   22.3583"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.        ,  30.27259036,   8.05      ],\n",
       "       [  1.        ,  39.        , 108.9       ],\n",
       "       [  3.        ,  38.5       ,   7.25      ],\n",
       "       [  3.        ,  30.27259036,   8.05      ],\n",
       "       [  3.        ,  30.27259036,  22.3583    ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_imputed[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.19207871])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_case = np.array([[1, 5, 500]])# Rich 5-year old in first class\n",
    "lin_reg.predict(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass   -0.210390\n",
       "Age      -0.007358\n",
       "Fare      0.000751\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lin_reg.coef_, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "dpUm8Dl-u2aB",
    "outputId": "44bc9b92-52ac-4e13-ab03-e87cbfd5fea7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would we do this with Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(solver = 'lbfgs')\n",
    "log_reg.fit(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02778799, 0.97221201]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict_proba(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19085685, 0.13076995, 0.18486051, 0.23627608, 0.27300709,\n",
       "       0.33031372, 0.21675828, 0.47074764, 0.2977617 , 0.29035639,\n",
       "       0.21530085, 0.52267833, 0.75938256, 0.18990847, 0.55071029,\n",
       "       0.48721585, 0.37549991, 0.27586047, 0.23571485, 0.13921516,\n",
       "       0.47763266, 0.3649756 , 0.66288758, 0.75630594, 0.73439675,\n",
       "       0.12243134, 0.75014158, 0.2652934 , 0.57156891, 0.22529204,\n",
       "       0.27159598, 0.49120168, 0.20798568, 0.2265992 , 0.68910514,\n",
       "       0.29404308, 0.21541083, 0.27707412, 0.25006306, 0.25196894,\n",
       "       0.17058217, 0.65802896, 0.15757318, 0.41885796, 0.55935625,\n",
       "       0.2488185 , 0.53546271, 0.21519691, 0.45097775, 0.1878664 ,\n",
       "       0.73489845, 0.44724964, 0.51792142, 0.84987609, 0.41913919,\n",
       "       0.38225551, 0.18815861, 0.24860162, 0.22120867, 0.80929153,\n",
       "       0.3058765 , 0.40209402, 0.29822154, 0.26920185, 0.90606015,\n",
       "       0.42471955, 0.29833567, 0.53103445, 0.65406254, 0.64366709,\n",
       "       0.25540976, 0.2764264 , 0.22309632, 0.67321035, 0.78012297,\n",
       "       0.79504795, 0.21541083, 0.44231642, 0.41885796, 0.25540976,\n",
       "       0.40232756, 0.54176622, 0.49592102, 0.21530085, 0.41414246,\n",
       "       0.2200143 , 0.23568002, 0.2984866 , 0.21519691, 0.67134347,\n",
       "       0.27435996, 0.21521473, 0.70656561, 0.21541083, 0.6985534 ,\n",
       "       0.24871659, 0.31928059, 0.22309632, 0.28358739, 0.19941186,\n",
       "       0.57984367, 0.45871855, 0.21519691, 0.2420902 , 0.31407196,\n",
       "       0.24041723, 0.27636309, 0.21519691, 0.21588379, 0.52075195,\n",
       "       0.32926773, 0.21521772, 0.61579045, 0.29409048, 0.57694488,\n",
       "       0.30417715, 0.21426281, 0.44740724, 0.65826731, 0.44105114,\n",
       "       0.58095495, 0.21519691, 0.64963896, 0.22884148, 0.21519691,\n",
       "       0.31327745, 0.26926064, 0.22645129, 0.31955212, 0.25565063,\n",
       "       0.20517201, 0.46292972, 0.22809439, 0.21426281, 0.14835041,\n",
       "       0.25549341, 0.23840863, 0.45396222, 0.26250263, 0.18605027,\n",
       "       0.40012052, 0.74739136, 0.63482692, 0.44986904, 0.55869961,\n",
       "       0.21813228, 0.68164872, 0.26947179, 0.65802896, 0.43227028,\n",
       "       0.7600695 , 0.21530085, 0.09489713, 0.1854847 , 0.35950155,\n",
       "       0.25524926, 0.82111972, 0.26234267, 0.55869961, 0.24676703,\n",
       "       0.215185  , 0.39377452, 0.45448538, 0.21466277, 0.32736357,\n",
       "       0.25329617, 0.53065403, 0.32225993, 0.65914008, 0.27023064,\n",
       "       0.21505438, 0.235183  , 0.26731064, 0.2148259 , 0.17633837,\n",
       "       0.57877188, 0.53239228, 0.48237267, 0.39367051, 0.42298577,\n",
       "       0.41885796, 0.65775338, 0.76935635, 0.21519691, 0.84605565,\n",
       "       0.33809968, 0.506894  , 0.30601469, 0.26249497, 0.33527189,\n",
       "       0.39762194, 0.6575064 , 0.35542908, 0.19203783, 0.63185439,\n",
       "       0.19927995, 0.87831951, 0.29824362, 0.47798074, 0.21545542,\n",
       "       0.22077271, 0.45092291, 0.71210963, 0.62544997, 0.46020221,\n",
       "       0.65726085, 0.18806462, 0.46908167, 0.63693907, 0.24879547,\n",
       "       0.21531461, 0.21469835, 0.59675275, 0.20693291, 0.17227036,\n",
       "       0.57522608, 0.21528902, 0.57058006, 0.67500795, 0.21541083,\n",
       "       0.41974002, 0.2765566 , 0.48689382, 0.27634199, 0.46182365,\n",
       "       0.22058819, 0.26229498, 0.21519691, 0.16411164, 0.36780451,\n",
       "       0.61376568, 0.72820396, 0.27524608, 0.21528902, 0.62989893,\n",
       "       0.28358739, 0.41486077, 0.28304816, 0.52520465, 0.58875711,\n",
       "       0.44442136, 0.31191728, 0.64208321, 0.21529494, 0.2265992 ,\n",
       "       0.59349186, 0.49797013, 0.33770743, 0.44105114, 0.2200143 ,\n",
       "       0.68414119, 0.2836481 , 0.77496962, 0.25667602, 0.20326596,\n",
       "       0.21505438, 0.21519691, 0.2294379 , 0.51629594, 0.27632443,\n",
       "       0.18611544, 0.27639128, 0.437932  , 0.44269894, 0.41858829,\n",
       "       0.21530085, 0.63238535, 0.21505438, 0.21541083, 0.30656398,\n",
       "       0.57410253, 0.21519691, 0.78113377, 0.22077271, 0.21482291,\n",
       "       0.52108211, 0.43373695, 0.34760865, 0.42709881, 0.48689382,\n",
       "       0.26300342, 0.44656156, 0.21519691, 0.37686689, 0.44225279,\n",
       "       0.1823595 , 0.21484071, 0.75279967, 0.2148259 , 0.21541083,\n",
       "       0.6703134 , 0.21627199, 0.2148259 , 0.51915435, 0.18377975,\n",
       "       0.24218377, 0.69601269, 0.22529204, 0.67792138, 0.22304454,\n",
       "       0.20498279, 0.41859118, 0.31913222, 0.25614289, 0.21519691,\n",
       "       0.36599103, 0.76706988, 0.44124629, 0.51359573, 0.14273325,\n",
       "       0.2990282 , 0.26878688, 0.21507219, 0.17740486, 0.55779742,\n",
       "       0.3057309 , 0.55151304, 0.51366038, 0.23566102, 0.50904843,\n",
       "       0.2420902 , 0.24827   , 0.45396222, 0.63579557, 0.75452774,\n",
       "       0.26168635, 0.60463743, 0.57818233, 0.44105114, 0.49845307,\n",
       "       0.29530148, 0.58813798, 0.21482291, 0.29781007, 0.23569264,\n",
       "       0.65969431, 0.40158676, 0.16691897, 0.48228387, 0.2148259 ,\n",
       "       0.52257275, 0.20484815, 0.26249497, 0.84749029, 0.22004747,\n",
       "       0.31328444, 0.45396222, 0.17194212, 0.47223627, 0.4183878 ,\n",
       "       0.57056349, 0.46020221, 0.58813374, 0.3129774 , 0.45880158,\n",
       "       0.48699954, 0.43395089, 0.21528902, 0.21519691, 0.22248776,\n",
       "       0.38461572, 0.49700868, 0.4183878 , 0.23627608, 0.72405842,\n",
       "       0.26249497, 0.22001727, 0.29655184, 0.56646526, 0.42845844,\n",
       "       0.49687035, 0.74728409, 0.46852813, 0.30423206, 0.51023798,\n",
       "       0.7547554 , 0.26998101, 0.49687035, 0.46774397, 0.42752657,\n",
       "       0.21519691, 0.24217091, 0.22004747, 0.29812641, 0.41636301,\n",
       "       0.5265241 , 0.25542983, 0.21563451, 0.27630333, 0.40825761,\n",
       "       0.76793893, 0.49221222, 0.34875049, 0.27991787, 0.23358083,\n",
       "       0.77448351, 0.25500863, 0.56067982, 0.26924337, 0.2108322 ,\n",
       "       0.77696127, 0.35909916, 0.74809567, 0.77119189, 0.55110354,\n",
       "       0.50828672, 0.47798074, 0.67500795, 0.21517609, 0.42680661,\n",
       "       0.21519691, 0.664224  , 0.22923275, 0.21541083, 0.66608961,\n",
       "       0.16942808, 0.21541083, 0.2257927 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict_proba(X_test_imputed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " = log_reg.predict_proba(X_test_imputed)[:, 1]\n",
    " = log_reg.predict(X_test_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How accurate is the Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7025813692480359\n"
     ]
    }
   ],
   "source": [
    "score = log_reg.score(X_train_imputed, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_train_imputed)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63333333, 0.62222222, 0.68539326, 0.71910112, 0.69662921,\n",
       "       0.69662921, 0.76404494, 0.75280899, 0.73033708, 0.71590909])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(log_reg, X_train_imputed, y_train, cv = 10)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6222222222222222, 0.7016408466689366, 0.7640449438202247)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.Series(scores)\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the math for the Logistic Regression?\n",
    "\n",
    "https://en.wikipedia.org/wiki/Logistic_function\n",
    "\n",
    "https://en.wikipedia.org/wiki/Logistic_regression#Probability_of_passing_an_exam_versus_hours_of_study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Get the [Category Encoder](http://contrib.scikit-learn.org/categorical-encoding/) library\n",
    "\n",
    "If you're running on Google Colab:\n",
    "\n",
    "```\n",
    "!pip install category_encoders\n",
    "```\n",
    "\n",
    "If you're running locally with Anaconda:\n",
    "\n",
    "```\n",
    "!conda install -c conda-forge category_encoders\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iblW74C8afuR"
   },
   "source": [
    "## Assignment: real-world classification\n",
    "\n",
    "We're going to check out a larger dataset - the [FMA Free Music Archive data](https://github.com/mdeff/fma). It has a selection of CSVs with metadata and calculated audio features that you can load and try to use to classify genre of tracks. To get you started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and unzip the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "SsySnuKaKtQf",
    "outputId": "d2855f29-b12c-4c1d-b86e-5867510e797a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "unzip:  cannot find or open fma_metadata.zip, fma_metadata.zip.zip or fma_metadata.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
    "!unzip fma_metadata.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Windows\n",
    "- Download the [zip file](https://os.unil.cloud.switch.ch/fma/fma_metadata.zip)\n",
    "- You may need to use [7zip](https://www.7-zip.org/download.html) to unzip it\n",
    "\n",
    "\n",
    "#### Mac\n",
    "- Download the [zip file](https://os.unil.cloud.switch.ch/fma/fma_metadata.zip)\n",
    "- You may need to use [p7zip](https://superuser.com/a/626731) to unzip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at first 3 lines of raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",album,album,album,album,album,album,album,album,album,album,album,album,album,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,set,set,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track\r\n",
      ",comments,date_created,date_released,engineer,favorites,id,information,listens,producer,tags,title,tracks,type,active_year_begin,active_year_end,associated_labels,bio,comments,date_created,favorites,id,latitude,location,longitude,members,name,related_projects,tags,website,wikipedia_page,split,subset,bit_rate,comments,composer,date_created,date_recorded,duration,favorites,genre_top,genres,genres_all,information,interest,language_code,license,listens,lyricist,number,publisher,tags,title\r\n",
      "track_id,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 /Users/azel/fma_metadata/tracks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read with pandas\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('/Users/azel/fma_metadata/tracks.csv', header = [0,1], index_col = 0)\n",
    "del tracks.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106574, 52)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 106574 entries, 2 to 155320\n",
      "Data columns (total 52 columns):\n",
      "(album, comments)              106574 non-null int64\n",
      "(album, date_created)          103045 non-null object\n",
      "(album, date_released)         70294 non-null object\n",
      "(album, engineer)              15295 non-null object\n",
      "(album, favorites)             106574 non-null int64\n",
      "(album, id)                    106574 non-null int64\n",
      "(album, information)           83149 non-null object\n",
      "(album, listens)               106574 non-null int64\n",
      "(album, producer)              18060 non-null object\n",
      "(album, tags)                  106574 non-null object\n",
      "(album, title)                 105549 non-null object\n",
      "(album, tracks)                106574 non-null int64\n",
      "(album, type)                  100066 non-null object\n",
      "(artist, active_year_begin)    22711 non-null object\n",
      "(artist, active_year_end)      5375 non-null object\n",
      "(artist, associated_labels)    14271 non-null object\n",
      "(artist, bio)                  71156 non-null object\n",
      "(artist, comments)             106574 non-null int64\n",
      "(artist, date_created)         105718 non-null object\n",
      "(artist, favorites)            106574 non-null int64\n",
      "(artist, id)                   106574 non-null int64\n",
      "(artist, latitude)             44544 non-null float64\n",
      "(artist, location)             70210 non-null object\n",
      "(artist, longitude)            44544 non-null float64\n",
      "(artist, members)              46849 non-null object\n",
      "(artist, name)                 106574 non-null object\n",
      "(artist, related_projects)     13152 non-null object\n",
      "(artist, tags)                 106574 non-null object\n",
      "(artist, website)              79256 non-null object\n",
      "(artist, wikipedia_page)       5581 non-null object\n",
      "(set, split)                   106574 non-null object\n",
      "(set, subset)                  106574 non-null object\n",
      "(track, bit_rate)              106574 non-null int64\n",
      "(track, comments)              106574 non-null int64\n",
      "(track, composer)              3670 non-null object\n",
      "(track, date_created)          106574 non-null object\n",
      "(track, date_recorded)         6159 non-null object\n",
      "(track, duration)              106574 non-null int64\n",
      "(track, favorites)             106574 non-null int64\n",
      "(track, genre_top)             49598 non-null object\n",
      "(track, genres)                106574 non-null object\n",
      "(track, genres_all)            106574 non-null object\n",
      "(track, information)           2349 non-null object\n",
      "(track, interest)              106574 non-null int64\n",
      "(track, language_code)         15024 non-null object\n",
      "(track, license)               106487 non-null object\n",
      "(track, listens)               106574 non-null int64\n",
      "(track, lyricist)              311 non-null object\n",
      "(track, number)                106574 non-null int64\n",
      "(track, publisher)             1263 non-null object\n",
      "(track, tags)                  106574 non-null object\n",
      "(track, title)                 106573 non-null object\n",
      "dtypes: float64(2), int64(15), object(35)\n",
      "memory usage: 43.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"13\" halign=\"left\">album</th>\n",
       "      <th colspan=\"17\" halign=\"left\">artist</th>\n",
       "      <th colspan=\"2\" halign=\"left\">set</th>\n",
       "      <th colspan=\"20\" halign=\"left\">track</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>name</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>tags</th>\n",
       "      <th>website</th>\n",
       "      <th>wikipedia_page</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>information</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206</td>\n",
       "      <td>6</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:08</td>\n",
       "      <td>2008-02-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>2</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexican Summer, Richie Records, Woodsist, Skul...</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family:Verdana, Geneva, A...</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-11-26 01:42:55</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Vile, the Violators</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['philly', 'kurt vile']</td>\n",
       "      <td>http://kurtvile.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>192000</td>\n",
       "      <td>0</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>2008-11-25 17:49:06</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>161</td>\n",
       "      <td>178</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54881</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Freeway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:05</td>\n",
       "      <td>2009-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt; \"spiritual songs\" from Nicky Cook&lt;/p&gt;</td>\n",
       "      <td>2710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Niris</td>\n",
       "      <td>13</td>\n",
       "      <td>Album</td>\n",
       "      <td>1990-01-01 00:00:00</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Songs written by: Nicky Cook&lt;/p&gt;\\n&lt;p&gt;VOCALS...</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-11-26 01:42:52</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>51.895927</td>\n",
       "      <td>Colchester England</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>Nicky Cook\\n</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['instrumentals', 'experimental pop', 'post pu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:56</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[76, 103]</td>\n",
       "      <td>[17, 10, 76, 103]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Spiritual Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      album                                                                  \\\n",
       "   comments         date_created        date_released engineer favorites id   \n",
       "2         0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN         4  1   \n",
       "3         0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN         4  1   \n",
       "5         0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN         4  1   \n",
       "10        0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN         4  6   \n",
       "20        0  2008-11-26 01:45:05  2009-01-06 00:00:00      NaN         2  4   \n",
       "\n",
       "                                                                     \\\n",
       "                                  information listens producer tags   \n",
       "2                                     <p></p>    6073      NaN   []   \n",
       "3                                     <p></p>    6073      NaN   []   \n",
       "5                                     <p></p>    6073      NaN   []   \n",
       "10                                        NaN   47632      NaN   []   \n",
       "20  <p> \"spiritual songs\" from Nicky Cook</p>    2710      NaN   []   \n",
       "\n",
       "                                                     artist  \\\n",
       "                   title tracks   type    active_year_begin   \n",
       "2   AWOL - A Way Of Life      7  Album  2006-01-01 00:00:00   \n",
       "3   AWOL - A Way Of Life      7  Album  2006-01-01 00:00:00   \n",
       "5   AWOL - A Way Of Life      7  Album  2006-01-01 00:00:00   \n",
       "10     Constant Hitmaker      2  Album                  NaN   \n",
       "20                 Niris     13  Album  1990-01-01 00:00:00   \n",
       "\n",
       "                                                                            \\\n",
       "        active_year_end                                  associated_labels   \n",
       "2                   NaN                                                NaN   \n",
       "3                   NaN                                                NaN   \n",
       "5                   NaN                                                NaN   \n",
       "10                  NaN  Mexican Summer, Richie Records, Woodsist, Skul...   \n",
       "20  2011-01-01 00:00:00                                                NaN   \n",
       "\n",
       "                                                                \\\n",
       "                                                  bio comments   \n",
       "2   <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "3   <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "5   <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "10  <p><span style=\"font-family:Verdana, Geneva, A...        3   \n",
       "20  <p>Songs written by: Nicky Cook</p>\\n<p>VOCALS...        2   \n",
       "\n",
       "                                                                     \\\n",
       "           date_created favorites id   latitude            location   \n",
       "2   2008-11-26 01:42:32         9  1  40.058324          New Jersey   \n",
       "3   2008-11-26 01:42:32         9  1  40.058324          New Jersey   \n",
       "5   2008-11-26 01:42:32         9  1  40.058324          New Jersey   \n",
       "10  2008-11-26 01:42:55        74  6        NaN                 NaN   \n",
       "20  2008-11-26 01:42:52        10  4  51.895927  Colchester England   \n",
       "\n",
       "                                                                              \\\n",
       "    longitude                                            members        name   \n",
       "2  -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "3  -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "5  -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "10        NaN                           Kurt Vile, the Violators   Kurt Vile   \n",
       "20   0.891874                                       Nicky Cook\\n  Nicky Cook   \n",
       "\n",
       "                                                       \\\n",
       "                                     related_projects   \n",
       "2   The list of past projects is 2 long but every1...   \n",
       "3   The list of past projects is 2 long but every1...   \n",
       "5   The list of past projects is 2 long but every1...   \n",
       "10                                                NaN   \n",
       "20                                                NaN   \n",
       "\n",
       "                                                       \\\n",
       "                                                 tags   \n",
       "2                                            ['awol']   \n",
       "3                                            ['awol']   \n",
       "5                                            ['awol']   \n",
       "10                            ['philly', 'kurt vile']   \n",
       "20  ['instrumentals', 'experimental pop', 'post pu...   \n",
       "\n",
       "                                                                 set          \\\n",
       "                                    website wikipedia_page     split  subset   \n",
       "2   http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "3   http://www.AzillionRecords.blogspot.com            NaN  training  medium   \n",
       "5   http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "10                      http://kurtvile.com            NaN  training   small   \n",
       "20                                      NaN            NaN  training   large   \n",
       "\n",
       "      track                                                                \\\n",
       "   bit_rate comments   composer         date_created        date_recorded   \n",
       "2    256000        0        NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
       "3    256000        0        NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
       "5    256000        0        NaN  2008-11-26 01:48:20  2008-11-26 00:00:00   \n",
       "10   192000        0  Kurt Vile  2008-11-25 17:49:06  2008-11-26 00:00:00   \n",
       "20   256000        0        NaN  2008-11-26 01:48:56  2008-01-01 00:00:00   \n",
       "\n",
       "                                                                           \\\n",
       "   duration favorites genre_top     genres         genres_all information   \n",
       "2       168         2   Hip-Hop       [21]               [21]         NaN   \n",
       "3       237         1   Hip-Hop       [21]               [21]         NaN   \n",
       "5       206         6   Hip-Hop       [21]               [21]         NaN   \n",
       "10      161       178       Pop       [10]               [10]         NaN   \n",
       "20      311         0       NaN  [76, 103]  [17, 10, 76, 103]         NaN   \n",
       "\n",
       "                                                                              \\\n",
       "   interest language_code                                            license   \n",
       "2      4656            en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "3      1470            en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "5      1933            en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "10    54881            en  Attribution-NonCommercial-NoDerivatives (aka M...   \n",
       "20      978            en  Attribution-NonCommercial-NoDerivatives (aka M...   \n",
       "\n",
       "                                                            \n",
       "   listens lyricist number publisher tags            title  \n",
       "2     1293      NaN      3       NaN   []             Food  \n",
       "3      514      NaN      4       NaN   []     Electric Ave  \n",
       "5     1151      NaN      6       NaN   []       This World  \n",
       "10   50135      NaN      1       NaN   []          Freeway  \n",
       "20     361      NaN      3       NaN   []  Spiritual Level  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tracks.shape)\n",
    "print()\n",
    "print(tracks.info())\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "album   comments                  0\n",
       "        date_created           3529\n",
       "        date_released         36280\n",
       "        engineer              91279\n",
       "        favorites                 0\n",
       "        id                        0\n",
       "        information           23425\n",
       "        listens                   0\n",
       "        producer              88514\n",
       "        tags                      0\n",
       "        title                  1025\n",
       "        tracks                    0\n",
       "        type                   6508\n",
       "artist  active_year_begin     83863\n",
       "        active_year_end      101199\n",
       "        associated_labels     92303\n",
       "        bio                   35418\n",
       "        comments                  0\n",
       "        date_created            856\n",
       "        favorites                 0\n",
       "        id                        0\n",
       "        latitude              62030\n",
       "        location              36364\n",
       "        longitude             62030\n",
       "        members               59725\n",
       "        name                      0\n",
       "        related_projects      93422\n",
       "        tags                      0\n",
       "        website               27318\n",
       "        wikipedia_page       100993\n",
       "set     split                     0\n",
       "        subset                    0\n",
       "track   bit_rate                  0\n",
       "        comments                  0\n",
       "        composer             102904\n",
       "        date_created              0\n",
       "        date_recorded        100415\n",
       "        duration                  0\n",
       "        favorites                 0\n",
       "        genre_top             56976\n",
       "        genres                    0\n",
       "        genres_all                0\n",
       "        information          104225\n",
       "        interest                  0\n",
       "        language_code         91550\n",
       "        license                  87\n",
       "        listens                   0\n",
       "        lyricist             106263\n",
       "        number                    0\n",
       "        publisher            105311\n",
       "        tags                      0\n",
       "        title                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Logistic Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81574"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tracks['set']['subset'] == 'large').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the columns\n",
    "\n",
    "album = tracks['album'][['engineer','information','producer','tracks','type']]\n",
    "artist = tracks['artist'][['active_year_begin', 'active_year_end', 'associated_labels', 'bio', \n",
    "                           'id', 'latitude', 'location','longitude', 'members', \n",
    "                           'name', 'related_projects']]\n",
    "train_split = tracks['set'][['split','subset']]\n",
    "track_info = tracks['track'][['bit_rate', 'comments', 'composer', 'date_created', 'date_recorded',\n",
    "                              'duration', 'favorites', 'genre_top', 'genres', 'genres_all',\n",
    "                              'interest', 'language_code', 'license', 'listens',\n",
    "                              'lyricist', 'number', 'publisher', 'tags']]\n",
    "\n",
    "df = pd.concat([album, artist, train_split, track_info], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106574, 36)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engineer</th>\n",
       "      <th>information</th>\n",
       "      <th>producer</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>name</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206</td>\n",
       "      <td>6</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexican Summer, Richie Records, Woodsist, Skul...</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family:Verdana, Geneva, A...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Vile, the Violators</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>192000</td>\n",
       "      <td>0</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>2008-11-25 17:49:06</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>161</td>\n",
       "      <td>178</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>54881</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt; \"spiritual songs\" from Nicky Cook&lt;/p&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Album</td>\n",
       "      <td>1990-01-01 00:00:00</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Songs written by: Nicky Cook&lt;/p&gt;\\n&lt;p&gt;VOCALS...</td>\n",
       "      <td>4</td>\n",
       "      <td>51.895927</td>\n",
       "      <td>Colchester England</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>Nicky Cook\\n</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:56</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[76, 103]</td>\n",
       "      <td>[17, 10, 76, 103]</td>\n",
       "      <td>978</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engineer                                information producer  tracks  \\\n",
       "2       NaN                                    <p></p>      NaN       7   \n",
       "3       NaN                                    <p></p>      NaN       7   \n",
       "5       NaN                                    <p></p>      NaN       7   \n",
       "10      NaN                                        NaN      NaN       2   \n",
       "20      NaN  <p> \"spiritual songs\" from Nicky Cook</p>      NaN      13   \n",
       "\n",
       "     type    active_year_begin      active_year_end  \\\n",
       "2   Album  2006-01-01 00:00:00                  NaN   \n",
       "3   Album  2006-01-01 00:00:00                  NaN   \n",
       "5   Album  2006-01-01 00:00:00                  NaN   \n",
       "10  Album                  NaN                  NaN   \n",
       "20  Album  1990-01-01 00:00:00  2011-01-01 00:00:00   \n",
       "\n",
       "                                    associated_labels  \\\n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "5                                                 NaN   \n",
       "10  Mexican Summer, Richie Records, Woodsist, Skul...   \n",
       "20                                                NaN   \n",
       "\n",
       "                                                  bio  id   latitude  \\\n",
       "2   <p>A Way Of Life, A Collective of Hip-Hop from...   1  40.058324   \n",
       "3   <p>A Way Of Life, A Collective of Hip-Hop from...   1  40.058324   \n",
       "5   <p>A Way Of Life, A Collective of Hip-Hop from...   1  40.058324   \n",
       "10  <p><span style=\"font-family:Verdana, Geneva, A...   6        NaN   \n",
       "20  <p>Songs written by: Nicky Cook</p>\\n<p>VOCALS...   4  51.895927   \n",
       "\n",
       "              location  longitude  \\\n",
       "2           New Jersey -74.405661   \n",
       "3           New Jersey -74.405661   \n",
       "5           New Jersey -74.405661   \n",
       "10                 NaN        NaN   \n",
       "20  Colchester England   0.891874   \n",
       "\n",
       "                                              members        name  \\\n",
       "2   Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "3   Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "5   Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "10                           Kurt Vile, the Violators   Kurt Vile   \n",
       "20                                       Nicky Cook\\n  Nicky Cook   \n",
       "\n",
       "                                     related_projects     split  subset  \\\n",
       "2   The list of past projects is 2 long but every1...  training   small   \n",
       "3   The list of past projects is 2 long but every1...  training  medium   \n",
       "5   The list of past projects is 2 long but every1...  training   small   \n",
       "10                                                NaN  training   small   \n",
       "20                                                NaN  training   large   \n",
       "\n",
       "    bit_rate  comments   composer         date_created        date_recorded  \\\n",
       "2     256000         0        NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
       "3     256000         0        NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
       "5     256000         0        NaN  2008-11-26 01:48:20  2008-11-26 00:00:00   \n",
       "10    192000         0  Kurt Vile  2008-11-25 17:49:06  2008-11-26 00:00:00   \n",
       "20    256000         0        NaN  2008-11-26 01:48:56  2008-01-01 00:00:00   \n",
       "\n",
       "    duration  favorites genre_top     genres         genres_all  interest  \\\n",
       "2        168          2   Hip-Hop       [21]               [21]      4656   \n",
       "3        237          1   Hip-Hop       [21]               [21]      1470   \n",
       "5        206          6   Hip-Hop       [21]               [21]      1933   \n",
       "10       161        178       Pop       [10]               [10]     54881   \n",
       "20       311          0       NaN  [76, 103]  [17, 10, 76, 103]       978   \n",
       "\n",
       "   language_code                                            license  listens  \\\n",
       "2             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1293   \n",
       "3             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...      514   \n",
       "5             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1151   \n",
       "10            en  Attribution-NonCommercial-NoDerivatives (aka M...    50135   \n",
       "20            en  Attribution-NonCommercial-NoDerivatives (aka M...      361   \n",
       "\n",
       "   lyricist  number publisher tags  \n",
       "2       NaN       3       NaN   []  \n",
       "3       NaN       4       NaN   []  \n",
       "5       NaN       6       NaN   []  \n",
       "10      NaN       1       NaN   []  \n",
       "20      NaN       3       NaN   []  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "engineer              91279\n",
       "information           23425\n",
       "producer              88514\n",
       "tracks                    0\n",
       "type                   6508\n",
       "active_year_begin     83863\n",
       "active_year_end      101199\n",
       "associated_labels     92303\n",
       "bio                   35418\n",
       "id                        0\n",
       "latitude              62030\n",
       "location              36364\n",
       "longitude             62030\n",
       "members               59725\n",
       "name                      0\n",
       "related_projects      93422\n",
       "split                     0\n",
       "subset                    0\n",
       "bit_rate                  0\n",
       "comments                  0\n",
       "composer             102904\n",
       "date_created              0\n",
       "date_recorded        100415\n",
       "duration                  0\n",
       "favorites                 0\n",
       "genre_top             56976\n",
       "genres                    0\n",
       "genres_all                0\n",
       "interest                  0\n",
       "language_code         91550\n",
       "license                  87\n",
       "listens                   0\n",
       "lyricist             106263\n",
       "number                    0\n",
       "publisher            105311\n",
       "tags                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target feature is 'genre_top'. There are roughly 50,000 null values. \n",
    "# I want to focus on the observations where we have a top genre available. \n",
    "# If I had more time, I would try to fill the primary genre with the other genre columns. \n",
    "\n",
    "df = df.loc[df['genre_top'].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hip-Hop', 'Pop', 'Rock', 'Experimental', 'Folk', 'Jazz',\n",
       "       'Electronic', 'Spoken', 'International', 'Soul-RnB', 'Blues',\n",
       "       'Country', 'Classical', 'Old-Time / Historic', 'Instrumental',\n",
       "       'Easy Listening'], dtype=object)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are a list of all the genres in the target feature. \n",
    "\n",
    "genres = df['genre_top'].unique()\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling categorical feature NAN with a dummy value. Next step is one-hot encoding. \n",
    "\n",
    "autofill_none = ['engineer','producer','bio','publisher']\n",
    "autofill_other = ['type','license','language_code','location']\n",
    "\n",
    "for column in autofill_none: \n",
    "    df[column] = df[column].fillna('None')\n",
    "    \n",
    "for column in autofill_other:\n",
    "    df[column] = df[column].fillna('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding Categorical Variables with large NAN values. \n",
    "\n",
    "for_dummies = ['type','language_code',]\n",
    " \n",
    "df = pd.get_dummies(df, columns = for_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual modification of the genre list.\n",
    "## For Tricky categories like Soul-Rnb\n",
    "### Also Tricky Hip-Hop vs Hip Hop... Annoying\n",
    "#### .replace() doesn't work because of something to do with lists of lists. \n",
    "\n",
    "\n",
    "tag_genre = ['Hip Hop', 'Hip-Hop', 'Pop', 'Rock', 'Experimental', 'Folk', 'Jazz',\n",
    "             'Electronic', 'Spoken', 'International', 'Soul', 'Rhythm' , 'Blues',\n",
    "             'Country', 'Classical', 'Old-Time', 'Historic', 'Instrumental',\n",
    "             'Easy Listening']\n",
    "\n",
    "tag_genre_lower = [s.lower() for s in tag_genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer me some lists \n",
    "\n",
    "for s in tag_genre_lower: \n",
    "    df[s + '_mentioned'] = df['tags'].str.contains(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engineer', 'producer', 'location', 'date_created', 'publisher']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are my selected features. \n",
    "features = ['engineer','producer','location','bit_rate','comments',\n",
    "            'date_created','duration','favorites','listens','publisher',\n",
    "            'type_Album', 'type_Live Performance','type_Radio Program', \n",
    "            'type_Single Tracks', 'language_code_ar','language_code_bg',\n",
    "            'language_code_cs', 'language_code_de', 'language_code_el',\n",
    "            'language_code_en', 'language_code_es', \n",
    "            'language_code_fr','language_code_he', 'language_code_id', \n",
    "            'language_code_it','language_code_ja', 'language_code_nl', \n",
    "            'language_code_pt','language_code_ru', 'language_code_sr', \n",
    "            'language_code_sw','language_code_tr', 'language_code_zh', \n",
    "            'hip hop_mentioned','hip-hop_mentioned', 'pop_mentioned', \n",
    "            'rock_mentioned','experimental_mentioned', 'folk_mentioned', \n",
    "            'jazz_mentioned','electronic_mentioned', 'spoken_mentioned', \n",
    "            'international_mentioned','soul_mentioned', 'rhythm_mentioned', \n",
    "            'blues_mentioned','country_mentioned', 'classical_mentioned', \n",
    "            'old-time_mentioned','historic_mentioned', 'instrumental_mentioned',\n",
    "            'easy listening_mentioned']\n",
    "\n",
    "# Find all columns where values are objects. \n",
    "ob_columns = df[features].select_dtypes(include='object').columns.tolist()\n",
    "# Change those columns to categories, then use .cat.codes to encode them to int8\n",
    "for col in ob_columns:     # \n",
    "    df[col+'Cat'] = df[col].astype('category').cat.codes\n",
    "    \n",
    "ob_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39943, 52), (39943, 1), (4951, 52), (4951, 1), (4704, 52), (4704, 1))"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['engineerCat','producerCat','locationCat','bit_rate','comments',\n",
    "            'date_createdCat','duration','favorites','listens','publisherCat',\n",
    "            'type_Album', 'type_Live Performance','type_Radio Program', \n",
    "            'type_Single Tracks', 'language_code_ar','language_code_bg',\n",
    "            'language_code_cs', 'language_code_de', 'language_code_el',\n",
    "            'language_code_en', 'language_code_es', \n",
    "            'language_code_fr','language_code_he', 'language_code_id', \n",
    "            'language_code_it','language_code_ja', 'language_code_nl', \n",
    "            'language_code_pt','language_code_ru', 'language_code_sr', \n",
    "            'language_code_sw','language_code_tr', 'language_code_zh', \n",
    "            'hip hop_mentioned','hip-hop_mentioned', 'pop_mentioned', \n",
    "            'rock_mentioned','experimental_mentioned', 'folk_mentioned', \n",
    "            'jazz_mentioned','electronic_mentioned', 'spoken_mentioned', \n",
    "            'international_mentioned','soul_mentioned', 'rhythm_mentioned', \n",
    "            'blues_mentioned','country_mentioned', 'classical_mentioned', \n",
    "            'old-time_mentioned','historic_mentioned', 'instrumental_mentioned',\n",
    "            'easy listening_mentioned']\n",
    "\n",
    "target = ['genre_top']\n",
    "\n",
    "train = df[df['split'] == 'training']\n",
    "test = df[df['split'] == 'test']\n",
    "validate = df[df['split'] == 'validation']\n",
    "\n",
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "X_val = validate[features]\n",
    "y_train = train[target]\n",
    "y_test = test[target]\n",
    "y_val = validate[target]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "engineerCat                 0\n",
       "producerCat                 0\n",
       "locationCat                 0\n",
       "bit_rate                    0\n",
       "comments                    0\n",
       "date_createdCat             0\n",
       "duration                    0\n",
       "favorites                   0\n",
       "listens                     0\n",
       "publisherCat                0\n",
       "type_Album                  0\n",
       "type_Live Performance       0\n",
       "type_Radio Program          0\n",
       "type_Single Tracks          0\n",
       "language_code_ar            0\n",
       "language_code_bg            0\n",
       "language_code_cs            0\n",
       "language_code_de            0\n",
       "language_code_el            0\n",
       "language_code_en            0\n",
       "language_code_es            0\n",
       "language_code_fr            0\n",
       "language_code_he            0\n",
       "language_code_id            0\n",
       "language_code_it            0\n",
       "language_code_ja            0\n",
       "language_code_nl            0\n",
       "language_code_pt            0\n",
       "language_code_ru            0\n",
       "language_code_sr            0\n",
       "language_code_sw            0\n",
       "language_code_tr            0\n",
       "language_code_zh            0\n",
       "hip hop_mentioned           0\n",
       "hip-hop_mentioned           0\n",
       "pop_mentioned               0\n",
       "rock_mentioned              0\n",
       "experimental_mentioned      0\n",
       "folk_mentioned              0\n",
       "jazz_mentioned              0\n",
       "electronic_mentioned        0\n",
       "spoken_mentioned            0\n",
       "international_mentioned     0\n",
       "soul_mentioned              0\n",
       "rhythm_mentioned            0\n",
       "blues_mentioned             0\n",
       "country_mentioned           0\n",
       "classical_mentioned         0\n",
       "old-time_mentioned          0\n",
       "historic_mentioned          0\n",
       "instrumental_mentioned      0\n",
       "easy listening_mentioned    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying my work\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'lbfgs')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.1 %\n"
     ]
    }
   ],
   "source": [
    "print(round(model.score(X_test, y_test)*100, 2 ),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bit_rate','comments','date_createdCat','duration','favorites',\n",
    "            'listens','type_Album', 'type_Live Performance','type_Radio Program', \n",
    "            'type_Single Tracks','hip hop_mentioned','hip-hop_mentioned', 'pop_mentioned', \n",
    "            'rock_mentioned','experimental_mentioned', 'folk_mentioned', \n",
    "            'jazz_mentioned','electronic_mentioned', 'spoken_mentioned', \n",
    "            'international_mentioned','soul_mentioned', 'rhythm_mentioned', \n",
    "            'blues_mentioned','country_mentioned', 'classical_mentioned', \n",
    "            'old-time_mentioned','historic_mentioned', 'instrumental_mentioned',\n",
    "            'easy listening_mentioned']\n",
    "\n",
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "X_val = validate[features]\n",
    "y_train = train[target]\n",
    "y_test = test[target]\n",
    "y_val = validate[target]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.16 %\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(round(model.score(X_test, y_test)*100, 2 ),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQUVlUKQMPPW"
   },
   "source": [
    "This dataset is bigger than many you've worked with so far, and while it should fit in Colab, it can take awhile to run. That's part of the challenge!\n",
    "\n",
    "Your tasks:\n",
    "- Clean up the variable names in the dataframe\n",
    "- Use logistic regression to fit a model predicting (primary/top) genre\n",
    "- Inspect, iterate, and improve your model\n",
    "- Answer the following questions (written, ~paragraph each):\n",
    "  - What are the best predictors of genre?\n",
    "  - What information isn't very useful for predicting genre?\n",
    "  - What surprised you the most about your results?\n",
    "\n",
    "*Important caveats*:\n",
    "- This is going to be difficult data to work with - don't let the perfect be the enemy of the good!\n",
    "- Be creative in cleaning it up - if the best way you know how to do it is download it locally and edit as a spreadsheet, that's OK!\n",
    "- If the data size becomes problematic, consider sampling/subsetting, or [downcasting numeric datatypes](https://www.dataquest.io/blog/pandas-big-data/).\n",
    "- You do not need perfect or complete results - just something plausible that runs, and that supports the reasoning in your written answers\n",
    "\n",
    "If you find that fitting a model to classify *all* genres isn't very good, it's totally OK to limit to the most frequent genres, or perhaps trying to combine or cluster genres as a preprocessing step. Even then, there will be limits to how good a model can be with just this metadata - if you really want to train an effective genre classifier, you'll have to involve the other data (see stretch goals).\n",
    "\n",
    "This is real data - there is no \"one correct answer\", so you can take this in a variety of directions. Just make sure to support your findings, and feel free to share them as well! This is meant to be practice for dealing with other \"messy\" data, a common task in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlI5OXfSag9C"
   },
   "source": [
    "## Resources and stretch goals\n",
    "\n",
    "- Check out the other .csv files from the FMA dataset, and see if you can join them or otherwise fit interesting models with them\n",
    "- [Logistic regression from scratch in numpy](https://blog.goodaudience.com/logistic-regression-from-scratch-in-numpy-5841c09e425f) - if you want to dig in a bit more to both the code and math (also takes a gradient descent approach, introducing the logistic loss function)\n",
    "- Create a visualization to show predictions of your model - ideally show a confidence interval based on error!\n",
    "- Check out and compare classification models from scikit-learn, such as [SVM](https://scikit-learn.org/stable/modules/svm.html#classification), [decision trees](https://scikit-learn.org/stable/modules/tree.html#classification), and [naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html). The underlying math will vary significantly, but the API (how you write the code) and interpretation will actually be fairly similar.\n",
    "- Sign up for [Kaggle](https://kaggle.com), and find a competition to try logistic regression with\n",
    "- (Not logistic regression related) If you enjoyed the assignment, you may want to read up on [music informatics](https://en.wikipedia.org/wiki/Music_informatics), which is how those audio features were actually calculated. The FMA includes the actual raw audio, so (while this is more of a longterm project than a stretch goal, and won't fit in Colab) if you'd like you can check those out and see what sort of deeper analysis you can do."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_231_Logistic_Regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
