{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7SXF6jEBd5_"
   },
   "source": [
    "# Lambda School Data Science - Logistic Regression\n",
    "\n",
    "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7-AOngjadRN"
   },
   "source": [
    "## Lecture - Where Linear goes Wrong\n",
    "### Return of the Titanic ðŸš¢\n",
    "\n",
    "You've likely already explored the rich dataset that is the Titanic - let's use regression and try to predict survival with it. The data is [available from Kaggle](https://www.kaggle.com/c/titanic/data), so we'll also play a bit with [the Kaggle API](https://github.com/Kaggle/kaggle-api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data, option 1: Kaggle API\n",
    "\n",
    "#### Sign up for Kaggle and get an API token\n",
    "1. [Sign up for a Kaggle account](https://www.kaggle.com/), if you donâ€™t already have one. \n",
    "2. [Follow these instructions](https://github.com/Kaggle/kaggle-api#api-credentials) to create a Kaggle â€œAPI Tokenâ€ and download your `kaggle.json` file. If you are using Anaconda, put the file in the directory specified in the instructions.\n",
    "\n",
    "_This will enable you to download data directly from Kaggle. If you run into problems, donâ€™t worry â€” Iâ€™ll give you an easy alternative way to download todayâ€™s data, so you can still follow along with the lecture hands-on. And then weâ€™ll help you through the Kaggle process after the lecture._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put `kaggle.json` in the correct location\n",
    "\n",
    "- ***If you're using Anaconda,*** put the file in the directory specified in the [instructions](https://github.com/Kaggle/kaggle-api#api-credentials).\n",
    "\n",
    "- ***If you're using Google Colab,*** upload the file to your Google Drive, and run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %env KAGGLE_CONFIG_DIR=/content/drive/My Drive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the Kaggle API package and use it to get the data\n",
    "\n",
    "You also have to join the Titanic competition to have access to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "MnHLWPYDcyIe",
    "outputId": "1d0b1c18-7dc4-46e0-8d52-2e3693868670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /home/seek/anaconda3/lib/python3.7/site-packages (1.5.3)\n",
      "Requirement already satisfied: six>=1.10 in /home/seek/anaconda3/lib/python3.7/site-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: python-slugify in /home/seek/anaconda3/lib/python3.7/site-packages (from kaggle) (3.0.2)\n",
      "Requirement already satisfied: certifi in /home/seek/anaconda3/lib/python3.7/site-packages (from kaggle) (2019.3.9)\n",
      "Requirement already satisfied: python-dateutil in /home/seek/anaconda3/lib/python3.7/site-packages (from kaggle) (2.8.0)\n",
      "Requirement already satisfied: tqdm in /home/seek/anaconda3/lib/python3.7/site-packages (from kaggle) (4.31.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/seek/anaconda3/lib/python3.7/site-packages (from kaggle) (1.24.2)\n",
      "Requirement already satisfied: requests in /home/seek/anaconda3/lib/python3.7/site-packages (from kaggle) (2.21.0)\n",
      "Requirement already satisfied: text-unidecode==1.2 in /home/seek/anaconda3/lib/python3.7/site-packages (from python-slugify->kaggle) (1.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/seek/anaconda3/lib/python3.7/site-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/seek/anaconda3/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.csv to /home/seek/Documents/GitHub/DS-Unit-2-Sprint-3-Classification-Validation/module1-logistic-regression\n",
      "  0%|                                               | 0.00/59.8k [00:00<?, ?B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59.8k/59.8k [00:00<00:00, 1.40MB/s]\n",
      "Downloading test.csv to /home/seek/Documents/GitHub/DS-Unit-2-Sprint-3-Classification-Validation/module1-logistic-regression\n",
      "  0%|                                               | 0.00/28.0k [00:00<?, ?B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.0k/28.0k [00:00<00:00, 4.38MB/s]\n",
      "Downloading gender_submission.csv to /home/seek/Documents/GitHub/DS-Unit-2-Sprint-3-Classification-Validation/module1-logistic-regression\n",
      "  0%|                                               | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.18k/3.18k [00:00<00:00, 1.55MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data, option 2: Download from the competition page\n",
    "1. [Sign up for a Kaggle account](https://www.kaggle.com/), if you donâ€™t already have one. \n",
    "2. [Go to the Titanic competition page](https://www.kaggle.com/c/titanic) to download the [data](https://www.kaggle.com/c/titanic/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data, option 3: Use Seaborn\n",
    "\n",
    "```\n",
    "import seaborn as sns\n",
    "train = sns.load_dataset('titanic')\n",
    "```\n",
    "\n",
    "But Seaborn's version of the Titanic dataset is not identical to Kaggle's version, as we'll see during this lesson!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12), (418, 11))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>811</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alexander, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3474</td>\n",
       "      <td>7.8875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Lemore, Mrs. (Amelia Milley)</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 34260</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>F33</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Stranden, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101288</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pengelly, Mr. Frederick William</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28665</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                             Name     Sex  \\\n",
       "810          811         0       3           Alexander, Mr. William    male   \n",
       "516          517         1       2     Lemore, Mrs. (Amelia Milley)  female   \n",
       "744          745         1       3               Stranden, Mr. Juho    male   \n",
       "238          239         0       2  Pengelly, Mr. Frederick William    male   \n",
       "11            12         1       1         Bonnell, Miss. Elizabeth  female   \n",
       "\n",
       "      Age  SibSp  Parch             Ticket     Fare Cabin Embarked  \n",
       "810  26.0      0      0               3474   7.8875   NaN        S  \n",
       "516  34.0      0      0         C.A. 34260  10.5000   F33        S  \n",
       "744  31.0      0      0  STON/O 2. 3101288   7.9250   NaN        S  \n",
       "238  19.0      0      0              28665  10.5000   NaN        S  \n",
       "11   58.0      0      0             113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1118</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mr. Johan Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350054</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>West, Miss. Barbara J</td>\n",
       "      <td>female</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 34651</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1032</td>\n",
       "      <td>3</td>\n",
       "      <td>Goodwin, Miss. Jessie Allis</td>\n",
       "      <td>female</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 2144</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1268</td>\n",
       "      <td>3</td>\n",
       "      <td>Kink, Miss. Maria</td>\n",
       "      <td>female</td>\n",
       "      <td>22.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>315152</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1090</td>\n",
       "      <td>2</td>\n",
       "      <td>Baimbrigge, Mr. Charles Robert</td>\n",
       "      <td>male</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 31030</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                            Name     Sex    Age  \\\n",
       "226         1118       3      Asplund, Mr. Johan Charles    male  23.00   \n",
       "250         1142       2           West, Miss. Barbara J  female   0.92   \n",
       "140         1032       3     Goodwin, Miss. Jessie Allis  female  10.00   \n",
       "376         1268       3               Kink, Miss. Maria  female  22.00   \n",
       "198         1090       2  Baimbrigge, Mr. Charles Robert    male  23.00   \n",
       "\n",
       "     SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
       "226      0      0      350054   7.7958   NaN        S  \n",
       "250      1      2  C.A. 34651  27.7500   NaN        S  \n",
       "140      5      2     CA 2144  46.9000   NaN        S  \n",
       "376      2      0      315152   8.6625   NaN        S  \n",
       "198      0      0  C.A. 31030  10.5000   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'Survived'\n",
    "train[target].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name   Sex    Ticket Cabin Embarked\n",
       "count                    891   891       891   204      889\n",
       "unique                   891     2       681   147        3\n",
       "top     Petroff, Mr. Nedelio  male  CA. 2343    G6        S\n",
       "freq                       1   577         7     4      644"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would we try to do this with linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/impute.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fcxfpsjdFJwM",
    "outputId": "590a3bba-67fe-48b4-bf6e-91e67bd29bd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "features = ['Pclass', 'Age', 'Fare']\n",
    "target  = 'Survived'\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_test  = test[features]\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed  = imputer.transform(X_test)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 3), (891, 3), (418, 3), (418, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_imputed.shape, X_test.shape, X_test_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age     Fare\n",
       "0       3  22.0   7.2500\n",
       "1       1  38.0  71.2833\n",
       "2       3  26.0   7.9250\n",
       "3       1  35.0  53.1000\n",
       "4       3  35.0   8.0500\n",
       "5       3   NaN   8.4583"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        , 22.        ,  7.25      ],\n",
       "       [ 1.        , 38.        , 71.2833    ],\n",
       "       [ 3.        , 26.        ,  7.925     ],\n",
       "       [ 1.        , 35.        , 53.1       ],\n",
       "       [ 3.        , 35.        ,  8.05      ],\n",
       "       [ 3.        , 29.69911765,  8.4583    ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imputed[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>108.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.3583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age      Fare\n",
       "413       3   NaN    8.0500\n",
       "414       1  39.0  108.9000\n",
       "415       3  38.5    7.2500\n",
       "416       3   NaN    8.0500\n",
       "417       3   NaN   22.3583"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.        ,  29.69911765,   8.05      ],\n",
       "       [  1.        ,  39.        , 108.9       ],\n",
       "       [  3.        ,  38.5       ,   7.25      ],\n",
       "       [  3.        ,  29.69911765,   8.05      ],\n",
       "       [  3.        ,  29.69911765,  22.3583    ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_imputed[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.272590361445783"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.881137667304014"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_train, X_test])['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.19207871])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_case = np.array([[1, 5, 500]]) # Rich 5-year old in first class\n",
    "lin_reg.predict(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    418.000000\n",
       "mean       0.392117\n",
       "std        0.181876\n",
       "min        0.011755\n",
       "25%        0.227341\n",
       "50%        0.339570\n",
       "75%        0.516439\n",
       "max        0.954827\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass   -0.210390\n",
       "Age      -0.007358\n",
       "Fare      0.000751\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lin_reg.coef_, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0638995000035445"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would we do this with Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "dpUm8Dl-u2aB",
    "outputId": "44bc9b92-52ac-4e13-ab03-e87cbfd5fea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for rich 5 year old: [1]\n",
      "Predicted probabilities for rich 5 year old: [[0.02778799 0.97221201]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Linear Regression\n",
    "# lin_reg = LinearRegression()\n",
    "# lin_reg.fit(X_train_imputed, y_train)\n",
    "# lin_reg.predict(test_case)\n",
    "\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "log_reg.fit(X_train_imputed, y_train)\n",
    "print('Prediction for rich 5 year old:', log_reg.predict(test_case))\n",
    "print('Predicted probabilities for rich 5 year old:', log_reg.predict_proba(test_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "(log_reg.predict_proba(X_test_imputed)[:, 1] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_predictions = (log_reg.predict_proba(X_test_imputed)[:,1] > threshold).astype(int)\n",
    "direct_predictions = log_reg.predict(X_test_imputed)\n",
    "\n",
    "all(manual_predictions == direct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How accurate is the Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score 0.7025813692480359\n"
     ]
    }
   ],
   "source": [
    "score = log_reg.score(X_train_imputed, y_train)\n",
    "print('Train Accuracy Score', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = log_reg.score(X_test_imputed, y_test)\n",
    "# print('Test Accuracy Score', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores [0.63333333 0.62222222 0.68539326 0.71910112 0.69662921 0.69662921\n",
      " 0.76404494 0.75280899 0.73033708 0.71590909]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, X_train_imputed, y_train, cv=10)\n",
    "print('Cross-Validation Accuracy Scores', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6222222222222222, 0.7016408466689366, 0.7640449438202247)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.Series(scores)\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 4\n",
    "total_predictions = 5\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train[:5], y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the math for the Logistic Regression?\n",
    "\n",
    "https://en.wikipedia.org/wiki/Logistic_function\n",
    "\n",
    "https://en.wikipedia.org/wiki/Logistic_regression#Probability_of_passing_an_exam_versus_hours_of_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Bq-54noR1uE",
    "outputId": "b2650236-5573-4f84-d1a8-ce8bc6d1de17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9345267 , -0.03569729,  0.00422069]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.55763985])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The logistic sigmoid \"squishing\" function, \n",
    "# implemented to work with numpy arrays\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e**(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97221201]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.dot(log_reg.coef_, test_case.T) + log_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97221201]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(log_reg.coef_ @ test_case.T + log_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02778799, 0.97221201]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict_proba(test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Get the [Category Encoder](http://contrib.scikit-learn.org/categorical-encoding/) library\n",
    "\n",
    "If you're running on Google Colab:\n",
    "\n",
    "```\n",
    "!pip install category_encoders\n",
    "```\n",
    "\n",
    "If you're running locally with Anaconda:\n",
    "\n",
    "```\n",
    "!conda install -c conda-forge category_encoders\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns_titanic = sns.load_dataset('titanic')\n",
    "print(sns_titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Titanic\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(X):\n",
    "    X = X.copy()\n",
    "    X['adult_male'] = (X['Sex'] == 'male') & (X['Age'] >= 16)\n",
    "    X['alone'] = (X['SibSp'] == 0) & (X['Parch'] == 0)\n",
    "    X['last_name'] = X['Name'].str.split(',').str[0]\n",
    "    X['title'] = X['Name'].str.split(',').str[1].str.split('.').str[0]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = make_features(train)\n",
    "test  = make_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    478\n",
       "True     413\n",
       "Name: adult_male, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['adult_male'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     537\n",
       "False    354\n",
       "Name: alone, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['alone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Mr              517\n",
       " Miss            182\n",
       " Mrs             125\n",
       " Master           40\n",
       " Dr                7\n",
       " Rev               6\n",
       " Col               2\n",
       " Mlle              2\n",
       " Major             2\n",
       " Ms                1\n",
       " Sir               1\n",
       " Mme               1\n",
       " Lady              1\n",
       " Capt              1\n",
       " Don               1\n",
       " Jonkheer          1\n",
       " the Countess      1\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iblW74C8afuR"
   },
   "source": [
    "## Assignment: real-world classification\n",
    "\n",
    "We're going to check out a larger dataset - the [FMA Free Music Archive data](https://github.com/mdeff/fma). It has a selection of CSVs with metadata and calculated audio features that you can load and try to use to classify genre of tracks. To get you started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and unzip the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "SsySnuKaKtQf",
    "outputId": "d2855f29-b12c-4c1d-b86e-5867510e797a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-06 17:46:07--  https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
      "Resolving os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)... 2001:620:5ca1:2ff::ce53, 86.119.28.13\n",
      "Connecting to os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)|2001:620:5ca1:2ff::ce53|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 358412441 (342M) [application/zip]\n",
      "Saving to: â€˜fma_metadata.zipâ€™\n",
      "\n",
      "fma_metadata.zip    100%[===================>] 341.81M  10.9MB/s    in 33s     \n",
      "\n",
      "2019-05-06 17:46:41 (10.2 MB/s) - â€˜fma_metadata.zipâ€™ saved [358412441/358412441]\n",
      "\n",
      "Archive:  fma_metadata.zip\n",
      "replace fma_metadata/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n",
      "/bin/sh: 1: o: not found\n"
     ]
    }
   ],
   "source": [
    "# !wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
    "# !unzip fma_metadata.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Windows\n",
    "- Download the [zip file](https://os.unil.cloud.switch.ch/fma/fma_metadata.zip)\n",
    "- You may need to use [7zip](https://www.7-zip.org/download.html) to unzip it\n",
    "\n",
    "\n",
    "#### Mac\n",
    "- Download the [zip file](https://os.unil.cloud.switch.ch/fma/fma_metadata.zip)\n",
    "- You may need to use [p7zip](https://superuser.com/a/626731) to unzip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at first 3 lines of raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",album,album,album,album,album,album,album,album,album,album,album,album,album,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,set,set,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track\n",
      ",comments,date_created,date_released,engineer,favorites,id,information,listens,producer,tags,title,tracks,type,active_year_begin,active_year_end,associated_labels,bio,comments,date_created,favorites,id,latitude,location,longitude,members,name,related_projects,tags,website,wikipedia_page,split,subset,bit_rate,comments,composer,date_created,date_recorded,duration,favorites,genre_top,genres,genres_all,information,interest,language_code,license,listens,lyricist,number,publisher,tags,title\n",
      "track_id,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "2,0,2008-11-26 01:44:45,2009-01-05 00:00:00,,4,1,<p></p>,6073,,[],AWOL - A Way Of Life,7,Album,2006-01-01 00:00:00,,,\"<p>A Way Of Life, A Collective of Hip-Hop from NJ...................</p>\",0,2008-11-26 01:42:32,9,1,40.0583238,New Jersey,-74.4056612,\"Sajje Morocco,Brownbum,ZawidaGod,Custodian of Records,Zooberelli the Don,F.A.H,MadSicka,Damien Omenicci..and a van load more...\",AWOL,The list of past projects is 2 long but every1 and every style from Tabby Bonet 2 M.O.P..Azillion Records Flagship trackmaster DJ BrownBum is a beat Wizard.....A-2-Z..illion....(right now working with JerseyBlock Ent),['awol'],http://www.AzillionRecords.blogspot.com,,training,small,256000,0,,2008-11-26 01:48:12,2008-11-26 00:00:00,168,2,Hip-Hop,[21],[21],,4656,en,Attribution-NonCommercial-ShareAlike 3.0 International,1293,,3,,[],Food\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 fma_metadata/tracks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read with pandas\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('fma_metadata/tracks.csv', header=[0,1], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"13\" halign=\"left\">album</th>\n",
       "      <th colspan=\"17\" halign=\"left\">artist</th>\n",
       "      <th colspan=\"2\" halign=\"left\">set</th>\n",
       "      <th colspan=\"20\" halign=\"left\">track</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>name</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>tags</th>\n",
       "      <th>website</th>\n",
       "      <th>wikipedia_page</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>information</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206</td>\n",
       "      <td>6</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:08</td>\n",
       "      <td>2008-02-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>2</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexican Summer, Richie Records, Woodsist, Skul...</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family:Verdana, Geneva, A...</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-11-26 01:42:55</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Vile, the Violators</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['philly', 'kurt vile']</td>\n",
       "      <td>http://kurtvile.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>192000</td>\n",
       "      <td>0</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>2008-11-25 17:49:06</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>161</td>\n",
       "      <td>178</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54881</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Freeway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:05</td>\n",
       "      <td>2009-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;Â \"spiritual songs\" from Nicky Cook&lt;/p&gt;</td>\n",
       "      <td>2710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Niris</td>\n",
       "      <td>13</td>\n",
       "      <td>Album</td>\n",
       "      <td>1990-01-01 00:00:00</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Songs written by: Nicky Cook&lt;/p&gt;\\n&lt;p&gt;VOCALS...</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-11-26 01:42:52</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>51.895927</td>\n",
       "      <td>Colchester England</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>Nicky Cook\\n</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['instrumentals', 'experimental pop', 'post pu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:56</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[76, 103]</td>\n",
       "      <td>[17, 10, 76, 103]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Spiritual Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            album                                                     \\\n",
       "         comments         date_created        date_released engineer   \n",
       "track_id                                                               \n",
       "2               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "3               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "5               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "10              0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
       "20              0  2008-11-26 01:45:05  2009-01-06 00:00:00      NaN   \n",
       "\n",
       "                                                                          \\\n",
       "         favorites id                                information listens   \n",
       "track_id                                                                   \n",
       "2                4  1                                    <p></p>    6073   \n",
       "3                4  1                                    <p></p>    6073   \n",
       "5                4  1                                    <p></p>    6073   \n",
       "10               4  6                                        NaN   47632   \n",
       "20               2  4  <p>Â \"spiritual songs\" from Nicky Cook</p>    2710   \n",
       "\n",
       "                                                            \\\n",
       "         producer tags                 title tracks   type   \n",
       "track_id                                                     \n",
       "2             NaN   []  AWOL - A Way Of Life      7  Album   \n",
       "3             NaN   []  AWOL - A Way Of Life      7  Album   \n",
       "5             NaN   []  AWOL - A Way Of Life      7  Album   \n",
       "10            NaN   []     Constant Hitmaker      2  Album   \n",
       "20            NaN   []                 Niris     13  Album   \n",
       "\n",
       "                       artist                       \\\n",
       "            active_year_begin      active_year_end   \n",
       "track_id                                             \n",
       "2         2006-01-01 00:00:00                  NaN   \n",
       "3         2006-01-01 00:00:00                  NaN   \n",
       "5         2006-01-01 00:00:00                  NaN   \n",
       "10                        NaN                  NaN   \n",
       "20        1990-01-01 00:00:00  2011-01-01 00:00:00   \n",
       "\n",
       "                                                             \\\n",
       "                                          associated_labels   \n",
       "track_id                                                      \n",
       "2                                                       NaN   \n",
       "3                                                       NaN   \n",
       "5                                                       NaN   \n",
       "10        Mexican Summer, Richie Records, Woodsist, Skul...   \n",
       "20                                                      NaN   \n",
       "\n",
       "                                                                      \\\n",
       "                                                        bio comments   \n",
       "track_id                                                               \n",
       "2         <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "3         <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "5         <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "10        <p><span style=\"font-family:Verdana, Geneva, A...        3   \n",
       "20        <p>Songs written by: Nicky Cook</p>\\n<p>VOCALS...        2   \n",
       "\n",
       "                                                                           \\\n",
       "                 date_created favorites id   latitude            location   \n",
       "track_id                                                                    \n",
       "2         2008-11-26 01:42:32         9  1  40.058324          New Jersey   \n",
       "3         2008-11-26 01:42:32         9  1  40.058324          New Jersey   \n",
       "5         2008-11-26 01:42:32         9  1  40.058324          New Jersey   \n",
       "10        2008-11-26 01:42:55        74  6        NaN                 NaN   \n",
       "20        2008-11-26 01:42:52        10  4  51.895927  Colchester England   \n",
       "\n",
       "                                                                        \\\n",
       "          longitude                                            members   \n",
       "track_id                                                                 \n",
       "2        -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...   \n",
       "3        -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...   \n",
       "5        -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...   \n",
       "10              NaN                           Kurt Vile, the Violators   \n",
       "20         0.891874                                       Nicky Cook\\n   \n",
       "\n",
       "                                                                         \\\n",
       "                name                                   related_projects   \n",
       "track_id                                                                  \n",
       "2               AWOL  The list of past projects is 2 long but every1...   \n",
       "3               AWOL  The list of past projects is 2 long but every1...   \n",
       "5               AWOL  The list of past projects is 2 long but every1...   \n",
       "10         Kurt Vile                                                NaN   \n",
       "20        Nicky Cook                                                NaN   \n",
       "\n",
       "                                                             \\\n",
       "                                                       tags   \n",
       "track_id                                                      \n",
       "2                                                  ['awol']   \n",
       "3                                                  ['awol']   \n",
       "5                                                  ['awol']   \n",
       "10                                  ['philly', 'kurt vile']   \n",
       "20        ['instrumentals', 'experimental pop', 'post pu...   \n",
       "\n",
       "                                                                       set  \\\n",
       "                                          website wikipedia_page     split   \n",
       "track_id                                                                     \n",
       "2         http://www.AzillionRecords.blogspot.com            NaN  training   \n",
       "3         http://www.AzillionRecords.blogspot.com            NaN  training   \n",
       "5         http://www.AzillionRecords.blogspot.com            NaN  training   \n",
       "10                            http://kurtvile.com            NaN  training   \n",
       "20                                            NaN            NaN  training   \n",
       "\n",
       "                    track                                           \\\n",
       "          subset bit_rate comments   composer         date_created   \n",
       "track_id                                                             \n",
       "2          small   256000        0        NaN  2008-11-26 01:48:12   \n",
       "3         medium   256000        0        NaN  2008-11-26 01:48:14   \n",
       "5          small   256000        0        NaN  2008-11-26 01:48:20   \n",
       "10         small   192000        0  Kurt Vile  2008-11-25 17:49:06   \n",
       "20         large   256000        0        NaN  2008-11-26 01:48:56   \n",
       "\n",
       "                                                                       \\\n",
       "                date_recorded duration favorites genre_top     genres   \n",
       "track_id                                                                \n",
       "2         2008-11-26 00:00:00      168         2   Hip-Hop       [21]   \n",
       "3         2008-11-26 00:00:00      237         1   Hip-Hop       [21]   \n",
       "5         2008-11-26 00:00:00      206         6   Hip-Hop       [21]   \n",
       "10        2008-11-26 00:00:00      161       178       Pop       [10]   \n",
       "20        2008-01-01 00:00:00      311         0       NaN  [76, 103]   \n",
       "\n",
       "                                                                \\\n",
       "                 genres_all information interest language_code   \n",
       "track_id                                                         \n",
       "2                      [21]         NaN     4656            en   \n",
       "3                      [21]         NaN     1470            en   \n",
       "5                      [21]         NaN     1933            en   \n",
       "10                     [10]         NaN    54881            en   \n",
       "20        [17, 10, 76, 103]         NaN      978            en   \n",
       "\n",
       "                                                                              \\\n",
       "                                                    license listens lyricist   \n",
       "track_id                                                                       \n",
       "2         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1293      NaN   \n",
       "3         Attribution-NonCommercial-ShareAlike 3.0 Inter...     514      NaN   \n",
       "5         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1151      NaN   \n",
       "10        Attribution-NonCommercial-NoDerivatives (aka M...   50135      NaN   \n",
       "20        Attribution-NonCommercial-NoDerivatives (aka M...     361      NaN   \n",
       "\n",
       "                                                 \n",
       "         number publisher tags            title  \n",
       "track_id                                         \n",
       "2             3       NaN   []             Food  \n",
       "3             4       NaN   []     Electric Ave  \n",
       "5             6       NaN   []       This World  \n",
       "10            1       NaN   []          Freeway  \n",
       "20            3       NaN   []  Spiritual Level  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 60)\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.columns = [' '.join(col).strip() for col in tracks.columns.values]\n",
    "\n",
    "tracks = tracks.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks.columns = tracks.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106574, 52)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tracks.head()\n",
    "print(tracks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('fma_metadata/features.csv', header=[0,2], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns = [' '.join(col).strip() for col in features.columns.values]\n",
    "\n",
    "features = features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>chroma_cens 01</th>\n",
       "      <th>chroma_cens 02</th>\n",
       "      <th>chroma_cens 03</th>\n",
       "      <th>chroma_cens 04</th>\n",
       "      <th>chroma_cens 05</th>\n",
       "      <th>chroma_cens 06</th>\n",
       "      <th>chroma_cens 07</th>\n",
       "      <th>chroma_cens 08</th>\n",
       "      <th>chroma_cens 09</th>\n",
       "      <th>chroma_cens 10</th>\n",
       "      <th>chroma_cens 11</th>\n",
       "      <th>chroma_cens 12</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 1 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 2 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 3 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 4 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 5 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 6 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 7 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 8 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 9 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 1 0 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 1 1 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 1 2 ' ) . 1</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 1 ' ) . 2</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 2 ' ) . 2</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 3 ' ) . 2</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 4 ' ) . 2</th>\n",
       "      <th>( ' c h r o m a _ c e n s ' ,   ' 0 5 ' ) . 2</th>\n",
       "      <th>...</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 2 ' ) . 3</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 3 ' ) . 3</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 4 ' ) . 3</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 5 ' ) . 3</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 6 ' ) . 3</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 1 ' ) . 4</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 2 ' ) . 4</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 3 ' ) . 4</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 4 ' ) . 4</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 5 ' ) . 4</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 6 ' ) . 4</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 1 ' ) . 5</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 2 ' ) . 5</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 3 ' ) . 5</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 4 ' ) . 5</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 5 ' ) . 5</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 6 ' ) . 5</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 1 ' ) . 6</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 2 ' ) . 6</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 3 ' ) . 6</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 4 ' ) . 6</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 5 ' ) . 6</th>\n",
       "      <th>( ' t o n n e t z ' ,   ' 0 6 ' ) . 6</th>\n",
       "      <th>zcr 01</th>\n",
       "      <th>( ' z c r ' ,   ' 0 1 ' ) . 1</th>\n",
       "      <th>( ' z c r ' ,   ' 0 1 ' ) . 2</th>\n",
       "      <th>( ' z c r ' ,   ' 0 1 ' ) . 3</th>\n",
       "      <th>( ' z c r ' ,   ' 0 1 ' ) . 4</th>\n",
       "      <th>( ' z c r ' ,   ' 0 1 ' ) . 5</th>\n",
       "      <th>( ' z c r ' ,   ' 0 1 ' ) . 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>7.180653</td>\n",
       "      <td>5.230309</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>1.347620</td>\n",
       "      <td>1.482478</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>1.481593</td>\n",
       "      <td>2.691455</td>\n",
       "      <td>0.866868</td>\n",
       "      <td>1.341231</td>\n",
       "      <td>1.347792</td>\n",
       "      <td>1.237658</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.569344</td>\n",
       "      <td>0.597041</td>\n",
       "      <td>0.625864</td>\n",
       "      <td>0.567330</td>\n",
       "      <td>0.443949</td>\n",
       "      <td>0.487976</td>\n",
       "      <td>0.497327</td>\n",
       "      <td>0.574435</td>\n",
       "      <td>0.579241</td>\n",
       "      <td>0.620102</td>\n",
       "      <td>0.586945</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.369816</td>\n",
       "      <td>0.236119</td>\n",
       "      <td>0.228068</td>\n",
       "      <td>0.222830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.067945</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.016876</td>\n",
       "      <td>-0.059769</td>\n",
       "      <td>-0.091745</td>\n",
       "      <td>-0.185687</td>\n",
       "      <td>-0.140306</td>\n",
       "      <td>-0.048525</td>\n",
       "      <td>-0.089286</td>\n",
       "      <td>0.752462</td>\n",
       "      <td>0.262607</td>\n",
       "      <td>0.200944</td>\n",
       "      <td>0.593595</td>\n",
       "      <td>-0.177665</td>\n",
       "      <td>-1.424201</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>0.029569</td>\n",
       "      <td>0.038974</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>5.758890</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089872</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.888963</td>\n",
       "      <td>0.760539</td>\n",
       "      <td>0.345297</td>\n",
       "      <td>2.295201</td>\n",
       "      <td>1.654031</td>\n",
       "      <td>0.067592</td>\n",
       "      <td>1.366848</td>\n",
       "      <td>1.054094</td>\n",
       "      <td>0.108103</td>\n",
       "      <td>0.619185</td>\n",
       "      <td>1.038253</td>\n",
       "      <td>1.292235</td>\n",
       "      <td>0.677641</td>\n",
       "      <td>0.584248</td>\n",
       "      <td>0.581271</td>\n",
       "      <td>0.581182</td>\n",
       "      <td>0.454241</td>\n",
       "      <td>0.464841</td>\n",
       "      <td>0.542833</td>\n",
       "      <td>0.664720</td>\n",
       "      <td>0.511329</td>\n",
       "      <td>0.530998</td>\n",
       "      <td>0.603398</td>\n",
       "      <td>0.547428</td>\n",
       "      <td>0.232784</td>\n",
       "      <td>0.229469</td>\n",
       "      <td>0.225674</td>\n",
       "      <td>0.216713</td>\n",
       "      <td>0.220512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>0.046912</td>\n",
       "      <td>-0.021149</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>-0.097199</td>\n",
       "      <td>-0.079651</td>\n",
       "      <td>-0.164613</td>\n",
       "      <td>-0.304375</td>\n",
       "      <td>-0.024958</td>\n",
       "      <td>-0.055667</td>\n",
       "      <td>0.265541</td>\n",
       "      <td>-0.131471</td>\n",
       "      <td>0.171930</td>\n",
       "      <td>-0.990710</td>\n",
       "      <td>0.574556</td>\n",
       "      <td>0.556494</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.051151</td>\n",
       "      <td>0.063831</td>\n",
       "      <td>0.014212</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>2.824694</td>\n",
       "      <td>0.466309</td>\n",
       "      <td>0.084578</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.716724</td>\n",
       "      <td>0.069330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.527563</td>\n",
       "      <td>-0.077654</td>\n",
       "      <td>-0.279610</td>\n",
       "      <td>0.685883</td>\n",
       "      <td>1.937570</td>\n",
       "      <td>0.880839</td>\n",
       "      <td>-0.923192</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.666617</td>\n",
       "      <td>1.038546</td>\n",
       "      <td>0.268932</td>\n",
       "      <td>1.125141</td>\n",
       "      <td>0.611014</td>\n",
       "      <td>0.651471</td>\n",
       "      <td>0.494528</td>\n",
       "      <td>0.448799</td>\n",
       "      <td>0.468624</td>\n",
       "      <td>0.454021</td>\n",
       "      <td>0.497172</td>\n",
       "      <td>0.559755</td>\n",
       "      <td>0.671287</td>\n",
       "      <td>0.610565</td>\n",
       "      <td>0.551663</td>\n",
       "      <td>0.603413</td>\n",
       "      <td>0.258420</td>\n",
       "      <td>0.303385</td>\n",
       "      <td>0.250737</td>\n",
       "      <td>0.218562</td>\n",
       "      <td>0.245743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018953</td>\n",
       "      <td>-0.020358</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.003899</td>\n",
       "      <td>-0.128391</td>\n",
       "      <td>-0.125289</td>\n",
       "      <td>-0.359463</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.038546</td>\n",
       "      <td>-0.146136</td>\n",
       "      <td>1.212025</td>\n",
       "      <td>0.218381</td>\n",
       "      <td>-0.419971</td>\n",
       "      <td>-0.014541</td>\n",
       "      <td>-0.199314</td>\n",
       "      <td>-0.925733</td>\n",
       "      <td>0.025550</td>\n",
       "      <td>0.021106</td>\n",
       "      <td>0.084997</td>\n",
       "      <td>0.040730</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>6.808415</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.193303</td>\n",
       "      <td>0.044861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3.702245</td>\n",
       "      <td>-0.291193</td>\n",
       "      <td>2.196742</td>\n",
       "      <td>-0.234449</td>\n",
       "      <td>1.367364</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>1.770694</td>\n",
       "      <td>1.604566</td>\n",
       "      <td>0.521217</td>\n",
       "      <td>1.982386</td>\n",
       "      <td>4.326824</td>\n",
       "      <td>1.300406</td>\n",
       "      <td>0.461840</td>\n",
       "      <td>0.540411</td>\n",
       "      <td>0.446708</td>\n",
       "      <td>0.647553</td>\n",
       "      <td>0.591908</td>\n",
       "      <td>0.513306</td>\n",
       "      <td>0.651501</td>\n",
       "      <td>0.516887</td>\n",
       "      <td>0.511479</td>\n",
       "      <td>0.478263</td>\n",
       "      <td>0.638766</td>\n",
       "      <td>0.638495</td>\n",
       "      <td>0.229882</td>\n",
       "      <td>0.286978</td>\n",
       "      <td>0.240096</td>\n",
       "      <td>0.226792</td>\n",
       "      <td>0.192443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019117</td>\n",
       "      <td>-0.007409</td>\n",
       "      <td>-0.067350</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>-0.107889</td>\n",
       "      <td>-0.194957</td>\n",
       "      <td>-0.273549</td>\n",
       "      <td>-0.343055</td>\n",
       "      <td>-0.052284</td>\n",
       "      <td>-0.029836</td>\n",
       "      <td>-0.135219</td>\n",
       "      <td>-0.275780</td>\n",
       "      <td>0.015767</td>\n",
       "      <td>-1.094873</td>\n",
       "      <td>1.164041</td>\n",
       "      <td>0.246746</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.031989</td>\n",
       "      <td>0.088197</td>\n",
       "      <td>0.074358</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>21.434212</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.542325</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.193837</td>\n",
       "      <td>-0.198527</td>\n",
       "      <td>0.201546</td>\n",
       "      <td>0.258556</td>\n",
       "      <td>0.775204</td>\n",
       "      <td>0.084794</td>\n",
       "      <td>-0.289294</td>\n",
       "      <td>-0.816410</td>\n",
       "      <td>0.043851</td>\n",
       "      <td>-0.804761</td>\n",
       "      <td>-0.990958</td>\n",
       "      <td>-0.430381</td>\n",
       "      <td>0.652864</td>\n",
       "      <td>0.676290</td>\n",
       "      <td>0.670288</td>\n",
       "      <td>0.598666</td>\n",
       "      <td>0.653607</td>\n",
       "      <td>0.697645</td>\n",
       "      <td>0.664929</td>\n",
       "      <td>0.686563</td>\n",
       "      <td>0.635117</td>\n",
       "      <td>0.667393</td>\n",
       "      <td>0.689589</td>\n",
       "      <td>0.683196</td>\n",
       "      <td>0.202806</td>\n",
       "      <td>0.245125</td>\n",
       "      <td>0.262997</td>\n",
       "      <td>0.187961</td>\n",
       "      <td>0.182397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>-0.025059</td>\n",
       "      <td>-0.072732</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>-0.006812</td>\n",
       "      <td>-0.147339</td>\n",
       "      <td>-0.210110</td>\n",
       "      <td>-0.342446</td>\n",
       "      <td>-0.388083</td>\n",
       "      <td>-0.075566</td>\n",
       "      <td>-0.091831</td>\n",
       "      <td>0.192395</td>\n",
       "      <td>-0.215337</td>\n",
       "      <td>0.081732</td>\n",
       "      <td>0.040777</td>\n",
       "      <td>0.232350</td>\n",
       "      <td>-0.207831</td>\n",
       "      <td>0.033342</td>\n",
       "      <td>0.035174</td>\n",
       "      <td>0.105521</td>\n",
       "      <td>0.095003</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>0.021355</td>\n",
       "      <td>16.669037</td>\n",
       "      <td>0.469727</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>3.189831</td>\n",
       "      <td>0.030993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  chroma_cens 01  chroma_cens 02  chroma_cens 03  chroma_cens 04  \\\n",
       "0         2        7.180653        5.230309        0.249321        1.347620   \n",
       "1         3        1.888963        0.760539        0.345297        2.295201   \n",
       "2         5        0.527563       -0.077654       -0.279610        0.685883   \n",
       "3        10        3.702245       -0.291193        2.196742       -0.234449   \n",
       "4        20       -0.193837       -0.198527        0.201546        0.258556   \n",
       "\n",
       "   chroma_cens 05  chroma_cens 06  chroma_cens 07  chroma_cens 08  \\\n",
       "0        1.482478        0.531371        1.481593        2.691455   \n",
       "1        1.654031        0.067592        1.366848        1.054094   \n",
       "2        1.937570        0.880839       -0.923192       -0.927232   \n",
       "3        1.367364        0.998411        1.770694        1.604566   \n",
       "4        0.775204        0.084794       -0.289294       -0.816410   \n",
       "\n",
       "   chroma_cens 09  chroma_cens 10  chroma_cens 11  chroma_cens 12  \\\n",
       "0        0.866868        1.341231        1.347792        1.237658   \n",
       "1        0.108103        0.619185        1.038253        1.292235   \n",
       "2        0.666617        1.038546        0.268932        1.125141   \n",
       "3        0.521217        1.982386        4.326824        1.300406   \n",
       "4        0.043851       -0.804761       -0.990958       -0.430381   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 1 ' ) . 1  \\\n",
       "0                                       0.692500   \n",
       "1                                       0.677641   \n",
       "2                                       0.611014   \n",
       "3                                       0.461840   \n",
       "4                                       0.652864   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 2 ' ) . 1  \\\n",
       "0                                       0.569344   \n",
       "1                                       0.584248   \n",
       "2                                       0.651471   \n",
       "3                                       0.540411   \n",
       "4                                       0.676290   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 3 ' ) . 1  \\\n",
       "0                                       0.597041   \n",
       "1                                       0.581271   \n",
       "2                                       0.494528   \n",
       "3                                       0.446708   \n",
       "4                                       0.670288   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 4 ' ) . 1  \\\n",
       "0                                       0.625864   \n",
       "1                                       0.581182   \n",
       "2                                       0.448799   \n",
       "3                                       0.647553   \n",
       "4                                       0.598666   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 5 ' ) . 1  \\\n",
       "0                                       0.567330   \n",
       "1                                       0.454241   \n",
       "2                                       0.468624   \n",
       "3                                       0.591908   \n",
       "4                                       0.653607   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 6 ' ) . 1  \\\n",
       "0                                       0.443949   \n",
       "1                                       0.464841   \n",
       "2                                       0.454021   \n",
       "3                                       0.513306   \n",
       "4                                       0.697645   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 7 ' ) . 1  \\\n",
       "0                                       0.487976   \n",
       "1                                       0.542833   \n",
       "2                                       0.497172   \n",
       "3                                       0.651501   \n",
       "4                                       0.664929   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 8 ' ) . 1  \\\n",
       "0                                       0.497327   \n",
       "1                                       0.664720   \n",
       "2                                       0.559755   \n",
       "3                                       0.516887   \n",
       "4                                       0.686563   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 9 ' ) . 1  \\\n",
       "0                                       0.574435   \n",
       "1                                       0.511329   \n",
       "2                                       0.671287   \n",
       "3                                       0.511479   \n",
       "4                                       0.635117   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 1 0 ' ) . 1  \\\n",
       "0                                       0.579241   \n",
       "1                                       0.530998   \n",
       "2                                       0.610565   \n",
       "3                                       0.478263   \n",
       "4                                       0.667393   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 1 1 ' ) . 1  \\\n",
       "0                                       0.620102   \n",
       "1                                       0.603398   \n",
       "2                                       0.551663   \n",
       "3                                       0.638766   \n",
       "4                                       0.689589   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 1 2 ' ) . 1  \\\n",
       "0                                       0.586945   \n",
       "1                                       0.547428   \n",
       "2                                       0.603413   \n",
       "3                                       0.638495   \n",
       "4                                       0.683196   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 1 ' ) . 2  \\\n",
       "0                                       0.474300   \n",
       "1                                       0.232784   \n",
       "2                                       0.258420   \n",
       "3                                       0.229882   \n",
       "4                                       0.202806   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 2 ' ) . 2  \\\n",
       "0                                       0.369816   \n",
       "1                                       0.229469   \n",
       "2                                       0.303385   \n",
       "3                                       0.286978   \n",
       "4                                       0.245125   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 3 ' ) . 2  \\\n",
       "0                                       0.236119   \n",
       "1                                       0.225674   \n",
       "2                                       0.250737   \n",
       "3                                       0.240096   \n",
       "4                                       0.262997   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 4 ' ) . 2  \\\n",
       "0                                       0.228068   \n",
       "1                                       0.216713   \n",
       "2                                       0.218562   \n",
       "3                                       0.226792   \n",
       "4                                       0.187961   \n",
       "\n",
       "   ( ' c h r o m a _ c e n s ' ,   ' 0 5 ' ) . 2  ...  \\\n",
       "0                                       0.222830  ...   \n",
       "1                                       0.220512  ...   \n",
       "2                                       0.245743  ...   \n",
       "3                                       0.192443  ...   \n",
       "4                                       0.182397  ...   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 2 ' ) . 3  \\\n",
       "0                               0.017786   \n",
       "1                               0.007161   \n",
       "2                              -0.018953   \n",
       "3                              -0.019117   \n",
       "4                               0.012416   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 3 ' ) . 3  \\\n",
       "0                               0.007311   \n",
       "1                               0.046912   \n",
       "2                              -0.020358   \n",
       "3                              -0.007409   \n",
       "4                              -0.025059   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 4 ' ) . 3  \\\n",
       "0                               0.067945   \n",
       "1                              -0.021149   \n",
       "2                               0.024615   \n",
       "3                              -0.067350   \n",
       "4                              -0.072732   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 5 ' ) . 3  \\\n",
       "0                               0.009488   \n",
       "1                               0.016299   \n",
       "2                               0.004868   \n",
       "3                               0.007036   \n",
       "4                               0.005057   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 6 ' ) . 3  \\\n",
       "0                               0.016876   \n",
       "1                              -0.002657   \n",
       "2                              -0.003899   \n",
       "3                               0.006788   \n",
       "4                              -0.006812   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 1 ' ) . 4  \\\n",
       "0                              -0.059769   \n",
       "1                              -0.097199   \n",
       "2                              -0.128391   \n",
       "3                              -0.107889   \n",
       "4                              -0.147339   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 2 ' ) . 4  \\\n",
       "0                              -0.091745   \n",
       "1                              -0.079651   \n",
       "2                              -0.125289   \n",
       "3                              -0.194957   \n",
       "4                              -0.210110   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 3 ' ) . 4  \\\n",
       "0                              -0.185687   \n",
       "1                              -0.164613   \n",
       "2                              -0.359463   \n",
       "3                              -0.273549   \n",
       "4                              -0.342446   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 4 ' ) . 4  \\\n",
       "0                              -0.140306   \n",
       "1                              -0.304375   \n",
       "2                              -0.166667   \n",
       "3                              -0.343055   \n",
       "4                              -0.388083   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 5 ' ) . 4  \\\n",
       "0                              -0.048525   \n",
       "1                              -0.024958   \n",
       "2                              -0.038546   \n",
       "3                              -0.052284   \n",
       "4                              -0.075566   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 6 ' ) . 4  \\\n",
       "0                              -0.089286   \n",
       "1                              -0.055667   \n",
       "2                              -0.146136   \n",
       "3                              -0.029836   \n",
       "4                              -0.091831   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 1 ' ) . 5  \\\n",
       "0                               0.752462   \n",
       "1                               0.265541   \n",
       "2                               1.212025   \n",
       "3                              -0.135219   \n",
       "4                               0.192395   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 2 ' ) . 5  \\\n",
       "0                               0.262607   \n",
       "1                              -0.131471   \n",
       "2                               0.218381   \n",
       "3                              -0.275780   \n",
       "4                              -0.215337   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 3 ' ) . 5  \\\n",
       "0                               0.200944   \n",
       "1                               0.171930   \n",
       "2                              -0.419971   \n",
       "3                               0.015767   \n",
       "4                               0.081732   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 4 ' ) . 5  \\\n",
       "0                               0.593595   \n",
       "1                              -0.990710   \n",
       "2                              -0.014541   \n",
       "3                              -1.094873   \n",
       "4                               0.040777   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 5 ' ) . 5  \\\n",
       "0                              -0.177665   \n",
       "1                               0.574556   \n",
       "2                              -0.199314   \n",
       "3                               1.164041   \n",
       "4                               0.232350   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 6 ' ) . 5  \\\n",
       "0                              -1.424201   \n",
       "1                               0.556494   \n",
       "2                              -0.925733   \n",
       "3                               0.246746   \n",
       "4                              -0.207831   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 1 ' ) . 6  \\\n",
       "0                               0.019809   \n",
       "1                               0.026316   \n",
       "2                               0.025550   \n",
       "3                               0.021413   \n",
       "4                               0.033342   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 2 ' ) . 6  \\\n",
       "0                               0.029569   \n",
       "1                               0.018708   \n",
       "2                               0.021106   \n",
       "3                               0.031989   \n",
       "4                               0.035174   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 3 ' ) . 6  \\\n",
       "0                               0.038974   \n",
       "1                               0.051151   \n",
       "2                               0.084997   \n",
       "3                               0.088197   \n",
       "4                               0.105521   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 4 ' ) . 6  \\\n",
       "0                               0.054125   \n",
       "1                               0.063831   \n",
       "2                               0.040730   \n",
       "3                               0.074358   \n",
       "4                               0.095003   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 5 ' ) . 6  \\\n",
       "0                               0.012226   \n",
       "1                               0.014212   \n",
       "2                               0.012691   \n",
       "3                               0.017952   \n",
       "4                               0.022492   \n",
       "\n",
       "   ( ' t o n n e t z ' ,   ' 0 6 ' ) . 6     zcr 01  \\\n",
       "0                               0.012111   5.758890   \n",
       "1                               0.017740   2.824694   \n",
       "2                               0.014759   6.808415   \n",
       "3                               0.013921  21.434212   \n",
       "4                               0.021355  16.669037   \n",
       "\n",
       "   ( ' z c r ' ,   ' 0 1 ' ) . 1  ( ' z c r ' ,   ' 0 1 ' ) . 2  \\\n",
       "0                       0.459473                       0.085629   \n",
       "1                       0.466309                       0.084578   \n",
       "2                       0.375000                       0.053114   \n",
       "3                       0.452148                       0.077515   \n",
       "4                       0.469727                       0.047225   \n",
       "\n",
       "   ( ' z c r ' ,   ' 0 1 ' ) . 3  ( ' z c r ' ,   ' 0 1 ' ) . 4  \\\n",
       "0                       0.071289                       0.000000   \n",
       "1                       0.063965                       0.000000   \n",
       "2                       0.041504                       0.000000   \n",
       "3                       0.071777                       0.000000   \n",
       "4                       0.040039                       0.000977   \n",
       "\n",
       "   ( ' z c r ' ,   ' 0 1 ' ) . 5  ( ' z c r ' ,   ' 0 1 ' ) . 6  \n",
       "0                       2.089872                       0.061448  \n",
       "1                       1.716724                       0.069330  \n",
       "2                       2.193303                       0.044861  \n",
       "3                       3.542325                       0.040800  \n",
       "4                       3.189831                       0.030993  \n",
       "\n",
       "[5 rows x 519 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Logistic Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQUVlUKQMPPW"
   },
   "source": [
    "This dataset is bigger than many you've worked with so far, and while it should fit in Colab, it can take awhile to run. That's part of the challenge!\n",
    "\n",
    "Your tasks:\n",
    "- Clean up the variable names in the dataframe\n",
    "- Use logistic regression to fit a model predicting (primary/top) genre\n",
    "- Inspect, iterate, and improve your model\n",
    "- Answer the following questions (written, ~paragraph each):\n",
    "  - What are the best predictors of genre?\n",
    "  - What information isn't very useful for predicting genre?\n",
    "  - What surprised you the most about your results?\n",
    "\n",
    "*Important caveats*:\n",
    "- This is going to be difficult data to work with - don't let the perfect be the enemy of the good!\n",
    "- Be creative in cleaning it up - if the best way you know how to do it is download it locally and edit as a spreadsheet, that's OK!\n",
    "- If the data size becomes problematic, consider sampling/subsetting, or [downcasting numeric datatypes](https://www.dataquest.io/blog/pandas-big-data/).\n",
    "- You do not need perfect or complete results - just something plausible that runs, and that supports the reasoning in your written answers\n",
    "\n",
    "If you find that fitting a model to classify *all* genres isn't very good, it's totally OK to limit to the most frequent genres, or perhaps trying to combine or cluster genres as a preprocessing step. Even then, there will be limits to how good a model can be with just this metadata - if you really want to train an effective genre classifier, you'll have to involve the other data (see stretch goals).\n",
    "\n",
    "This is real data - there is no \"one correct answer\", so you can take this in a variety of directions. Just make sure to support your findings, and feel free to share them as well! This is meant to be practice for dealing with other \"messy\" data, a common task in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlI5OXfSag9C"
   },
   "source": [
    "## Resources and stretch goals\n",
    "\n",
    "- Check out the other .csv files from the FMA dataset, and see if you can join them or otherwise fit interesting models with them\n",
    "- [Logistic regression from scratch in numpy](https://blog.goodaudience.com/logistic-regression-from-scratch-in-numpy-5841c09e425f) - if you want to dig in a bit more to both the code and math (also takes a gradient descent approach, introducing the logistic loss function)\n",
    "- Create a visualization to show predictions of your model - ideally show a confidence interval based on error!\n",
    "- Check out and compare classification models from scikit-learn, such as [SVM](https://scikit-learn.org/stable/modules/svm.html#classification), [decision trees](https://scikit-learn.org/stable/modules/tree.html#classification), and [naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html). The underlying math will vary significantly, but the API (how you write the code) and interpretation will actually be fairly similar.\n",
    "- Sign up for [Kaggle](https://kaggle.com), and find a competition to try logistic regression with\n",
    "- (Not logistic regression related) If you enjoyed the assignment, you may want to read up on [music informatics](https://en.wikipedia.org/wiki/Music_informatics), which is how those audio features were actually calculated. The FMA includes the actual raw audio, so (while this is more of a longterm project than a stretch goal, and won't fit in Colab) if you'd like you can check those out and see what sort of deeper analysis you can do."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_231_Logistic_Regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
