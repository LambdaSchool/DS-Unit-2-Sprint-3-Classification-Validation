{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PC9RfopIWrc9"
   },
   "source": [
    " _Lambda School Data Science Unit 2_\n",
    " \n",
    " # Classification & Validation Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UV7ArLFQN84W"
   },
   "source": [
    "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAZcbTtiUlkI"
   },
   "source": [
    "#### For this Sprint Challenge, you'll predict whether a person's income exceeds $50k/yr, based on census data.\n",
    "\n",
    "You can read more about the Adult Census Income dataset at the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvV9VORbxyvu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['age', \n",
    "           'workclass', \n",
    "           'fnlwgt', \n",
    "           'education', \n",
    "           'education-num', \n",
    "           'marital-status', \n",
    "           'occupation', \n",
    "           'relationship', \n",
    "           'race', \n",
    "           'sex', \n",
    "           'capital-gain', \n",
    "           'capital-loss', \n",
    "           'hours-per-week', \n",
    "           'native-country', \n",
    "           'income']\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', \n",
    "                 header=None, names=columns)\n",
    "\n",
    "df['income'] = df['income'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 — Begin with baselines\n",
    "\n",
    "Split the data into an **X matrix** (all the features) and **y vector** (the target).\n",
    "\n",
    "(You _don't_ need to split the data into train and test sets here. You'll be asked to do that at the _end_ of Part 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='income')\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxKfgx4ycb3c"
   },
   "source": [
    "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
    " \n",
    "(You can answer this question either with a scikit-learn function or with a pandas function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    0.75919\n",
       ">50K     0.24081\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['income'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oo31Remcq-x"
   },
   "outputs": [],
   "source": [
    "\n",
    "majority_class = df['income'].mode()[0]\n",
    "y_pred = [majority_class] * len(y)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KdxE1TrcriI"
   },
   "source": [
    "What **ROC AUC score** would you get here with a **majority class baseline?**\n",
    "\n",
    "(You can answer this question either with a scikit-learn function or with no code, just your understanding of ROC AUC.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILS0fN0Cctyc"
   },
   "source": [
    "0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqYNDtwKYhji"
   },
   "source": [
    "In this Sprint Challenge, you will use **\"Cross-Validation with Independent Test Set\"** for your model validaton method.\n",
    "\n",
    "First, **split the data into `X_train, X_test, y_train, y_test`**. You can include 80% of the data in the train set, and hold out 20% for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPKf86yDYf0t"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rand_seed = 314\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_seed, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 — Modeling with Logistic Regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_ATNJdqTCuZ"
   },
   "source": [
    "- You may do exploratory data analysis and visualization, but it is not required.\n",
    "- You may **use all the features, or select any features** of your choice, as long as you select at least one numeric feature and one categorical feature.\n",
    "- **Scale your numeric features**, using any scikit-learn [Scaler](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) of your choice.\n",
    "- **Encode your categorical features**. You may use any encoding (One-Hot, Ordinal, etc) and any library (category_encoders, scikit-learn, pandas, etc) of your choice.\n",
    "- You may choose to use a pipeline, but it is not required.\n",
    "- Use a **Logistic Regression** model.\n",
    "- Use scikit-learn's [**cross_val_score**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function. For [scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules), use **accuracy**.\n",
    "- **Print your model's cross-validation accuracy score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    32561.000000  \n",
       "mean        40.437456  \n",
       "std         12.347429  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>22696</td>\n",
       "      <td>10501</td>\n",
       "      <td>14976</td>\n",
       "      <td>4140</td>\n",
       "      <td>13193</td>\n",
       "      <td>27816</td>\n",
       "      <td>21790</td>\n",
       "      <td>29170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass education       marital-status       occupation relationship  \\\n",
       "count      32561     32561                32561            32561        32561   \n",
       "unique         9        16                    7               15            6   \n",
       "top      Private   HS-grad   Married-civ-spouse   Prof-specialty      Husband   \n",
       "freq       22696     10501                14976             4140        13193   \n",
       "\n",
       "          race    sex  native-country  \n",
       "count    32561  32561           32561  \n",
       "unique       5      2              42  \n",
       "top      White   Male   United-States  \n",
       "freq     27816  21790           29170  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ok, quick and dirty logistic regression to establish a baseline\n",
    "\n",
    "features = df.drop(columns='income').columns.tolist()\n",
    "target = 'income' #df['income'] == '>50K'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target] == '>50K'\n",
    "\n",
    "# pipeline for preprocessing\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), \n",
    "                            SimpleImputer(),\n",
    "                            MinMaxScaler()\n",
    "                            )\n",
    "\n",
    "# preprocess feature data\n",
    "X = preprocessor.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns = features)\n",
    "\n",
    "# Split Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=rand_seed)\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=10,\n",
    "                       n_jobs=-1, verbose = True)\n",
    "model.fit(X_train,y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print('Cross Val Accuracy Scores: ', scores)\n",
    "print('Mean CV Accuracy Score: ', scores.mean())\n",
    "print('Test Accuracy Score: ', test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 — Modeling with Tree Ensembles!\n",
    "\n",
    "Part 3 is the same as Part 2, except this time, use a **Random Forest** or **Gradient Boosting** classifier. You may use scikit-learn, xgboost, or any other library. Then, print your model's cross-validation accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val accuracy Scores:  [0.80237913 0.79662318 0.80621642 0.80614203 0.80422265 0.80645161\n",
      " 0.80261137 0.79761905 0.79646697 0.80645161]\n",
      "Mean CV accuracy Score:  0.8025184023757552\n",
      "Test accuracy Score:  0.8050053738676494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# again, a quick and dirty one\n",
    "\n",
    "features = df.drop(columns='income').columns.tolist()\n",
    "target = 'income' #df['income'] == '>50K'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target] == '>50K'\n",
    "\n",
    "# pipeline for preprocessing\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), \n",
    "                            SimpleImputer(),\n",
    "                            MinMaxScaler()\n",
    "                            )\n",
    "\n",
    "# preprocess feature data\n",
    "X = preprocessor.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns = features)\n",
    "\n",
    "# Split Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# define model\n",
    "model = RandomForestClassifier(max_depth=3, n_estimators=6, random_state=rand_seed)\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=10,\n",
    "               n_jobs=-1, verbose = False)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print('Cross Val accuracy Scores: ', scores)\n",
    "print('Mean CV accuracy Score: ', scores.mean())\n",
    "print('Test accuracy Score: ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkyHoRIbEgRR"
   },
   "source": [
    "## Part 4 — Calculate classification metrics from a confusion matrix\n",
    "\n",
    "Suppose this is the confusion matrix for your binary classification model:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "    <td colspan=\"2\">Predicted</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Negative</td>\n",
    "    <td>Positive</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">Actual</td>\n",
    "    <td>Negative</td>\n",
    "    <td style=\"border: solid\">85</td>\n",
    "    <td style=\"border: solid\">58</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Positive</td>\n",
    "    <td style=\"border: solid\">8</td>\n",
    "    <td style=\"border: solid\"> 36</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = 36\n",
    "true_negative = 85\n",
    "false_positive = 58\n",
    "false_negative = 8\n",
    "\n",
    "pred_positive = true_positive + false_positive\n",
    "pred_negative = true_negative + false_negative\n",
    "\n",
    "actual_positive = false_negative + true_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhyMM5H-JpVB"
   },
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZPwqdh2KUcB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "accuracy = (true_positive + true_negative) / (pred_negative + pred_positive)\n",
    "\n",
    "print('Accuracy ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWLfGcGKeQw"
   },
   "source": [
    "Calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-FEZ4i_Kf_n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.3829787234042553\n"
     ]
    }
   ],
   "source": [
    "precision = true_positive / pred_positive\n",
    "\n",
    "print('Precision ', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_mH2NYDKi2C"
   },
   "source": [
    "Calculate recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4_wJGyjKkXJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "recall = true_positive / actual_positive\n",
    "\n",
    "print('Recall ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KEaWsk5Kk9W"
   },
   "source": [
    "## BONUS — How you can earn a score of 3\n",
    "\n",
    "### Part 1\n",
    "Do feature engineering, to try improving your cross-validation score.\n",
    "\n",
    "### Part 2\n",
    "Experiment with feature selection, preprocessing, categorical encoding, and hyperparameter optimization, to try improving your cross-validation score.\n",
    "\n",
    "### Part 3\n",
    "Which model had the best cross-validation score? Refit this model on the train set and do a final evaluation on the held out test set — what is the test score? \n",
    "\n",
    "### Part 4\n",
    "Calculate F1 score and False Positive Rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Do feature engineering, to try improving your cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195211097583623"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X_train,y_train)\n",
    "y_pred_proba = tree.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1202pt\" height=\"373pt\"\n",
       " viewBox=\"0.00 0.00 1202.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 1198,-369 1198,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.682353\" stroke=\"#000000\" points=\"655,-365 515,-365 515,-297 655,-297 655,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"585\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">capital&#45;gain &lt;= 0.051</text>\n",
       "<text text-anchor=\"middle\" x=\"585\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"585\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.759, 0.241]</text>\n",
       "<text text-anchor=\"middle\" x=\"585\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.741176\" stroke=\"#000000\" points=\"576,-261 430,-261 430,-193 576,-193 576,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">marital&#45;status &lt;= 0.083</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 95.2%</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.795, 0.205]</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M558.1501,-296.9465C551.1417,-288.0578 543.5045,-278.3716 536.209,-269.1188\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"538.8502,-266.8157 529.9102,-261.13 533.3533,-271.1498 538.8502,-266.8157\"/>\n",
       "<text text-anchor=\"middle\" x=\"526.9737\" y=\"-282.2569\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.945098\" stroke=\"#000000\" points=\"800,-261 660,-261 660,-193 800,-193 800,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">capital&#45;gain &lt;= 0.071</text>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4.8%</text>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.053, 0.947]</text>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M632.4784,-296.9465C645.7477,-287.4293 660.2915,-276.9978 674.0035,-267.163\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"676.3288,-269.8024 682.4149,-261.13 672.249,-264.1142 676.3288,-269.8024\"/>\n",
       "<text text-anchor=\"middle\" x=\"678.3531\" y=\"-282.0978\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.964706\" stroke=\"#000000\" points=\"304.5,-157 151.5,-157 151.5,-89 304.5,-89 304.5,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">education&#45;num &lt;= 0.833</text>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 32.1%</text>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.965, 0.035]</text>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M429.6663,-199.2665C394.3201,-185.8992 351.6815,-169.7741 314.7326,-155.8007\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"315.5644,-152.3734 304.9728,-152.1097 313.0882,-158.9208 315.5644,-152.3734\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.588235\" stroke=\"#000000\" points=\"579.5,-157 426.5,-157 426.5,-89 579.5,-89 579.5,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">education&#45;num &lt;= 0.767</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 63.1%</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.708, 0.292]</text>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M503,-192.9465C503,-184.776 503,-175.9318 503,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"506.5001,-167.13 503,-157.13 499.5001,-167.13 506.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.976471\" stroke=\"#000000\" points=\"140,-53 0,-53 0,0 140,0 140,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 30.5%</text>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.976, 0.024]</text>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M172.2951,-88.9777C156.028,-79.0424 138.3136,-68.2232 122.2674,-58.4228\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"123.9027,-55.3204 113.5442,-53.095 120.254,-61.2943 123.9027,-55.3204\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.690196\" stroke=\"#000000\" points=\"298,-53 158,-53 158,0 298,0 298,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1.6%</text>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.762, 0.238]</text>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M228,-88.9777C228,-80.7364 228,-71.887 228,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"231.5001,-63.2484 228,-53.2485 224.5001,-63.2485 231.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.741176\" stroke=\"#000000\" points=\"456,-53 316,-53 316,0 456,0 456,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"386\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 47.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"386\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.795, 0.205]</text>\n",
       "<text text-anchor=\"middle\" x=\"386\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M461.7502,-88.9777C450.2039,-79.4545 437.6729,-69.1191 426.189,-59.6473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"428.3724,-56.9113 418.4308,-53.2485 423.9184,-62.3115 428.3724,-56.9113\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.239216\" stroke=\"#000000\" points=\"614,-53 474,-53 474,0 614,0 614,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"544\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15.2%</text>\n",
       "<text text-anchor=\"middle\" x=\"544\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.432, 0.568]</text>\n",
       "<text text-anchor=\"middle\" x=\"544\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M517.4551,-88.9777C521.0733,-80.4617 524.9674,-71.2963 528.6283,-62.6798\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"531.9462,-63.8209 532.6354,-53.2485 525.5036,-61.0836 531.9462,-63.8209\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.454902\" stroke=\"#000000\" points=\"800,-157 660,-157 660,-89 800,-89 800,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">capital&#45;gain &lt;= 0.053</text>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 0.5%</text>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.353, 0.647]</text>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M730,-192.9465C730,-184.776 730,-175.9318 730,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"733.5001,-167.13 730,-157.13 726.5001,-167.13 733.5001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.984314\" stroke=\"#000000\" points=\"1049,-157 909,-157 909,-89 1049,-89 1049,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"979\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">age &lt;= 0.048</text>\n",
       "<text text-anchor=\"middle\" x=\"979\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4.3%</text>\n",
       "<text text-anchor=\"middle\" x=\"979\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.015, 0.985]</text>\n",
       "<text text-anchor=\"middle\" x=\"979\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M800.023,-197.7534C830.9202,-184.8486 867.3933,-169.6149 899.3259,-156.2776\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"900.7613,-159.4711 908.6398,-152.3874 898.0634,-153.0119 900.7613,-159.4711\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"#399de5\" stroke=\"#000000\" points=\"745.5,-53 632.5,-53 632.5,0 745.5,0 745.5,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"689\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 0.3%</text>\n",
       "<text text-anchor=\"middle\" x=\"689\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.0, 1.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"689\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M715.5449,-88.9777C711.9267,-80.4617 708.0326,-71.2963 704.3717,-62.6798\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"707.4964,-61.0836 700.3646,-53.2485 701.0538,-63.8209 707.4964,-61.0836\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.694118\" stroke=\"#000000\" points=\"904,-53 764,-53 764,0 904,0 904,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"834\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 0.2%</text>\n",
       "<text text-anchor=\"middle\" x=\"834\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.766, 0.234]</text>\n",
       "<text text-anchor=\"middle\" x=\"834\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M766.6665,-88.9777C776.7325,-79.6376 787.6404,-69.5163 797.6865,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"800.2228,-62.616 805.1726,-53.2485 795.4615,-57.4847 800.2228,-62.616\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.749020\" stroke=\"#000000\" points=\"1035.5,-53 922.5,-53 922.5,0 1035.5,0 1035.5,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"979\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 0.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"979\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.8, 0.2]</text>\n",
       "<text text-anchor=\"middle\" x=\"979\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = No</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M979,-88.9777C979,-80.7364 979,-71.887 979,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"982.5001,-63.2484 979,-53.2485 975.5001,-63.2485 982.5001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.988235\" stroke=\"#000000\" points=\"1194,-53 1054,-53 1054,0 1194,0 1194,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"1124\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4.2%</text>\n",
       "<text text-anchor=\"middle\" x=\"1124\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.012, 0.988]</text>\n",
       "<text text-anchor=\"middle\" x=\"1124\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = Yes</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1030.1216,-88.9777C1044.8439,-79.1798 1060.8579,-68.5222 1075.4215,-58.8298\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1077.4222,-61.7026 1083.808,-53.2485 1073.5439,-55.8752 1077.4222,-61.7026\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f298aacf898>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(tree, out_file=None, feature_names=X_train.columns, \n",
    "                           class_names=['No', 'Yes'], filled=True, impurity=False, proportion=True)\n",
    "\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above decision stump shows that marital-status and capital gains are important features, I'm going to dig into them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Married-civ-spouse       0.459937\n",
       " Never-married            0.328092\n",
       " Divorced                 0.136452\n",
       " Separated                0.031479\n",
       " Widowed                  0.030497\n",
       " Married-spouse-absent    0.012837\n",
       " Married-AF-spouse        0.000706\n",
       "Name: marital-status, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['marital-status'].value_counts(normalize='True')\n",
    "# reading the literature makes me believe I can combine civ spouse, AF spouse, and spouse absent\n",
    "\n",
    "X['marital-status'] = df['marital-status'].map({'Married-civ-spouse': 'Married',\n",
    "                                                'Married-AF-spouse': 'Married',\n",
    "                                               'Married-spouse-absent': 'Married'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cap-gain-binned'] = pd.cut(df['capital-gain'], 10)\n",
    "# I'll try binning this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " United-States                 0.895857\n",
       " Mexico                        0.019748\n",
       " ?                             0.017905\n",
       " Philippines                   0.006081\n",
       " Germany                       0.004207\n",
       " Canada                        0.003716\n",
       " Puerto-Rico                   0.003501\n",
       " El-Salvador                   0.003255\n",
       " India                         0.003071\n",
       " Cuba                          0.002918\n",
       " England                       0.002764\n",
       " Jamaica                       0.002488\n",
       " South                         0.002457\n",
       " China                         0.002303\n",
       " Italy                         0.002242\n",
       " Dominican-Republic            0.002150\n",
       " Vietnam                       0.002058\n",
       " Guatemala                     0.001966\n",
       " Japan                         0.001904\n",
       " Poland                        0.001843\n",
       " Columbia                      0.001812\n",
       " Taiwan                        0.001566\n",
       " Haiti                         0.001351\n",
       " Iran                          0.001321\n",
       " Portugal                      0.001136\n",
       " Nicaragua                     0.001044\n",
       " Peru                          0.000952\n",
       " France                        0.000891\n",
       " Greece                        0.000891\n",
       " Ecuador                       0.000860\n",
       " Ireland                       0.000737\n",
       " Hong                          0.000614\n",
       " Trinadad&Tobago               0.000584\n",
       " Cambodia                      0.000584\n",
       " Thailand                      0.000553\n",
       " Laos                          0.000553\n",
       " Yugoslavia                    0.000491\n",
       " Outlying-US(Guam-USVI-etc)    0.000430\n",
       " Honduras                      0.000399\n",
       " Hungary                       0.000399\n",
       " Scotland                      0.000369\n",
       " Holand-Netherlands            0.000031\n",
       "Name: native-country, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['native-country'].value_counts(normalize='True')\n",
    "# this is so broad, I'd like to map to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['native-country'] = df['native-country'].map({' United-States' : 'NA',\n",
    " ' Cuba':'SA',\n",
    " ' Jamaica': 'SA',\n",
    " ' India':'A',\n",
    " ' ?':'Unknown',\n",
    " ' Mexico':'SA',\n",
    " ' South':'SA',\n",
    " ' Puerto-Rico':'SA',\n",
    " ' Honduras':'SA',\n",
    " ' England':'E',\n",
    " ' Canada':'NA',\n",
    " ' Germany':'E',\n",
    " ' Iran':'ME',\n",
    " ' Philippines':'SEA',\n",
    " ' Italy':\"E\",\n",
    " ' Poland':'EE',\n",
    " ' Columbia':'SA',\n",
    " ' Cambodia':'SEA',\n",
    " ' Thailand':'SEA',\n",
    " ' Ecuador':'SA',\n",
    " ' Laos':'SEA',\n",
    " ' Taiwan':'A',\n",
    " ' Haiti':'SA',\n",
    " ' Portugal':'E',\n",
    " ' Dominican-Republic':'SA',\n",
    " ' El-Salvador':'SA',\n",
    " ' France':'E',\n",
    " ' Guatemala':'SA',\n",
    " ' China':'A',\n",
    " ' Japan':'A',\n",
    " ' Yugoslavia':'EE',\n",
    " ' Peru':'SA',\n",
    " ' Outlying-US(Guam-USVI-etc)':'SEA',\n",
    " ' Scotland':'E',\n",
    " ' Trinadad&Tobago':'SA',\n",
    " ' Greece':'E',\n",
    " ' Nicaragua':'SA',\n",
    " ' Vietnam':'SEA',\n",
    " ' Hong':'A',\n",
    " ' Ireland':'E',\n",
    " ' Hungary':'EE',\n",
    " ' Holand-Netherlands':'E'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Experiment with feature selection, preprocessing, categorical encoding, and hyperparameter optimization, to try improving your cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# I'm going to attempt to run several regressions to optimize parameters\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# reload data\n",
    "columns = ['age', \n",
    "           'workclass', \n",
    "           'fnlwgt', \n",
    "           'education', \n",
    "           'education-num', \n",
    "           'marital-status', \n",
    "           'occupation', \n",
    "           'relationship', \n",
    "           'race', \n",
    "           'sex', \n",
    "           'capital-gain', \n",
    "           'capital-loss', \n",
    "           'hours-per-week', \n",
    "           'native-country', \n",
    "           'income']\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', \n",
    "                 header=None, names=columns)\n",
    "\n",
    "df['income'] = df['income'].str.strip()\n",
    "\n",
    "# again, a quick and dirty one\n",
    "\n",
    "features = df.drop(columns='income').columns.tolist()\n",
    "target = 'income' #df['income'] == '>50K'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target] == '>50K'\n",
    "\n",
    "# add aditional features\n",
    "\n",
    "# X['cap-gain-binned'] = pd.cut(df['capital-gain'], 5)\n",
    "# X['cap-gain-binned'] = pd.Categorical(X['cap-gain-binned'])\n",
    "\n",
    "X['marital-status'] = df['marital-status'].map({'Married-civ-spouse': 'Married',\n",
    "                                                'Married-AF-spouse': 'Married',\n",
    "                                               'Married-spouse-absent': 'Married'})\n",
    "\n",
    "X['native-country'] = df['native-country'].map({' United-States' : 'NA',\n",
    " ' Cuba':'SA',\n",
    " ' Jamaica': 'SA',\n",
    " ' India':'A',\n",
    " ' ?':'Unknown',\n",
    " ' Mexico':'SA',\n",
    " ' South':'SA',\n",
    " ' Puerto-Rico':'SA',\n",
    " ' Honduras':'SA',\n",
    " ' England':'E',\n",
    " ' Canada':'NA',\n",
    " ' Germany':'E',\n",
    " ' Iran':'ME',\n",
    " ' Philippines':'SEA',\n",
    " ' Italy':\"E\",\n",
    " ' Poland':'EE',\n",
    " ' Columbia':'SA',\n",
    " ' Cambodia':'SEA',\n",
    " ' Thailand':'SEA',\n",
    " ' Ecuador':'SA',\n",
    " ' Laos':'SEA',\n",
    " ' Taiwan':'A',\n",
    " ' Haiti':'SA',\n",
    " ' Portugal':'E',\n",
    " ' Dominican-Republic':'SA',\n",
    " ' El-Salvador':'SA',\n",
    " ' France':'E',\n",
    " ' Guatemala':'SA',\n",
    " ' China':'A',\n",
    " ' Japan':'A',\n",
    " ' Yugoslavia':'EE',\n",
    " ' Peru':'SA',\n",
    " ' Outlying-US(Guam-USVI-etc)':'SEA',\n",
    " ' Scotland':'E',\n",
    " ' Trinadad&Tobago':'SA',\n",
    " ' Greece':'E',\n",
    " ' Nicaragua':'SA',\n",
    " ' Vietnam':'SEA',\n",
    " ' Hong':'A',\n",
    " ' Ireland':'E',\n",
    " ' Hungary':'EE',\n",
    " ' Holand-Netherlands':'E'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for preprocessing\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), \n",
    "                            SimpleImputer(),\n",
    "                            MinMaxScaler()\n",
    "                            )\n",
    "\n",
    "# preprocess feature data\n",
    "X = preprocessor.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# parameters to fine tune model\n",
    "max_depth = 6\n",
    "\n",
    "n_estimators = 5\n",
    "\n",
    "weights = [{0: 1, 1: 1}, #(equivalent to None)\n",
    "{0: 1, 1: 2},\n",
    "{0: 1, 1: 10}, #(roughly equivalent to 'balanced' for this dataset)\n",
    "{0: 1, 1: 100},\n",
    "{0: 1, 1: 10000}]\n",
    "\n",
    "\n",
    "\n",
    "# dataframe to hold all values\n",
    "results = pd.DataFrame(columns = ['Model', 'CV Mean ROC_AUC Score', \n",
    "            'Test ROC_AUC Score', 'max_depth', 'n_estimators', 'class_weight'])\n",
    "for weight in weights:\n",
    "    for depth in range(1, max_depth):\n",
    "        for n in range(1, n_estimators):\n",
    "        \n",
    "            models = [LogisticRegression(solver='lbfgs', max_iter=100, class_weight=weight,\n",
    "                                 random_state=rand_seed),\n",
    "              DecisionTreeClassifier(max_depth=depth, class_weight=weight,\n",
    "                                     random_state=rand_seed),\n",
    "              RandomForestClassifier(max_depth=depth, class_weight=weight,\n",
    "                                     random_state=rand_seed),\n",
    "              XGBClassifier(max_depth=depth, n_estimators = n,\n",
    "                            n_jobs=-1, random_state=rand_seed)\n",
    "             ]\n",
    "            \n",
    "            for model in models:\n",
    "                # define model\n",
    "                scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=10,\n",
    "                           n_jobs=-1, verbose = False)\n",
    "                model.fit(X_train, y_train)\n",
    "                test_score = model.score(X_test, y_test)\n",
    "\n",
    "                # append to dataframe\n",
    "                results = results.append({'Model': model, 'CV Mean ROC_AUC Score': scores.mean(), \n",
    "                    'Test ROC_AUC Score': test_score, 'max_depth':depth, 'n_estimators':n, \n",
    "                                          'class_weight':weight}, \n",
    "                                    ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Mean ROC_AUC Score</th>\n",
       "      <th>Test ROC_AUC Score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.854138</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.854138</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.854138</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.854138</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.854138</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.891031</td>\n",
       "      <td>0.852142</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.891031</td>\n",
       "      <td>0.852142</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.891031</td>\n",
       "      <td>0.852142</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.891031</td>\n",
       "      <td>0.852142</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.891031</td>\n",
       "      <td>0.852142</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.884377</td>\n",
       "      <td>0.851835</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.884377</td>\n",
       "      <td>0.851835</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.884377</td>\n",
       "      <td>0.851835</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.884377</td>\n",
       "      <td>0.851835</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.879903</td>\n",
       "      <td>0.850760</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.879903</td>\n",
       "      <td>0.850760</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.879903</td>\n",
       "      <td>0.850760</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.879903</td>\n",
       "      <td>0.850760</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.867042</td>\n",
       "      <td>0.848457</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.867042</td>\n",
       "      <td>0.848457</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.867042</td>\n",
       "      <td>0.848457</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.867042</td>\n",
       "      <td>0.848457</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.867042</td>\n",
       "      <td>0.848457</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.861756</td>\n",
       "      <td>0.847843</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.861756</td>\n",
       "      <td>0.847843</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.861756</td>\n",
       "      <td>0.847843</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.858637</td>\n",
       "      <td>0.847843</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.858637</td>\n",
       "      <td>0.847843</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.858637</td>\n",
       "      <td>0.847843</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.858637</td>\n",
       "      <td>0.847843</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.689380</td>\n",
       "      <td>0.242285</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.689380</td>\n",
       "      <td>0.242285</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.672935</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.759910</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.759910</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.759910</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.672935</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.672935</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.672935</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.759910</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight={0: 1, ...</td>\n",
       "      <td>0.831367</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Model  CV Mean ROC_AUC Score  \\\n",
       "391  XGBClassifier(base_score=0.5, booster='gbtree'...               0.883146   \n",
       "151  XGBClassifier(base_score=0.5, booster='gbtree'...               0.883146   \n",
       "71   XGBClassifier(base_score=0.5, booster='gbtree'...               0.883146   \n",
       "231  XGBClassifier(base_score=0.5, booster='gbtree'...               0.883146   \n",
       "311  XGBClassifier(base_score=0.5, booster='gbtree'...               0.883146   \n",
       "399  XGBClassifier(base_score=0.5, booster='gbtree'...               0.891031   \n",
       "319  XGBClassifier(base_score=0.5, booster='gbtree'...               0.891031   \n",
       "79   XGBClassifier(base_score=0.5, booster='gbtree'...               0.891031   \n",
       "239  XGBClassifier(base_score=0.5, booster='gbtree'...               0.891031   \n",
       "159  XGBClassifier(base_score=0.5, booster='gbtree'...               0.891031   \n",
       "154  (DecisionTreeClassifier(class_weight=None, cri...               0.884377   \n",
       "146  (DecisionTreeClassifier(class_weight=None, cri...               0.884377   \n",
       "158  (DecisionTreeClassifier(class_weight=None, cri...               0.884377   \n",
       "150  (DecisionTreeClassifier(class_weight=None, cri...               0.884377   \n",
       "66   (DecisionTreeClassifier(class_weight=None, cri...               0.879903   \n",
       "74   (DecisionTreeClassifier(class_weight=None, cri...               0.879903   \n",
       "78   (DecisionTreeClassifier(class_weight=None, cri...               0.879903   \n",
       "70   (DecisionTreeClassifier(class_weight=None, cri...               0.879903   \n",
       "219  XGBClassifier(base_score=0.5, booster='gbtree'...               0.867042   \n",
       "59   XGBClassifier(base_score=0.5, booster='gbtree'...               0.867042   \n",
       "139  XGBClassifier(base_score=0.5, booster='gbtree'...               0.867042   \n",
       "299  XGBClassifier(base_score=0.5, booster='gbtree'...               0.867042   \n",
       "379  XGBClassifier(base_score=0.5, booster='gbtree'...               0.867042   \n",
       "47   XGBClassifier(base_score=0.5, booster='gbtree'...               0.861756   \n",
       "207  XGBClassifier(base_score=0.5, booster='gbtree'...               0.861756   \n",
       "127  XGBClassifier(base_score=0.5, booster='gbtree'...               0.861756   \n",
       "123  XGBClassifier(base_score=0.5, booster='gbtree'...               0.858637   \n",
       "203  XGBClassifier(base_score=0.5, booster='gbtree'...               0.858637   \n",
       "43   XGBClassifier(base_score=0.5, booster='gbtree'...               0.858637   \n",
       "283  XGBClassifier(base_score=0.5, booster='gbtree'...               0.858637   \n",
       "..                                                 ...                    ...   \n",
       "346  (DecisionTreeClassifier(class_weight=None, cri...               0.689380   \n",
       "342  (DecisionTreeClassifier(class_weight=None, cri...               0.689380   \n",
       "396  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "322  (DecisionTreeClassifier(class_weight=None, cri...               0.672935   \n",
       "388  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "250  (DecisionTreeClassifier(class_weight=None, cri...               0.759910   \n",
       "332  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "392  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "324  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "242  (DecisionTreeClassifier(class_weight=None, cri...               0.759910   \n",
       "246  (DecisionTreeClassifier(class_weight=None, cri...               0.759910   \n",
       "336  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "330  (DecisionTreeClassifier(class_weight=None, cri...               0.672935   \n",
       "328  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "334  (DecisionTreeClassifier(class_weight=None, cri...               0.672935   \n",
       "326  (DecisionTreeClassifier(class_weight=None, cri...               0.672935   \n",
       "254  (DecisionTreeClassifier(class_weight=None, cri...               0.759910   \n",
       "384  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "340  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "360  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "380  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "344  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "376  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "348  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "372  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "352  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "368  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "356  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "364  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "320  LogisticRegression(C=1.0, class_weight={0: 1, ...               0.831367   \n",
       "\n",
       "     Test ROC_AUC Score max_depth n_estimators      class_weight  \n",
       "391            0.854138         5            2  {0: 1, 1: 10000}  \n",
       "151            0.854138         5            2      {0: 1, 1: 2}  \n",
       "71             0.854138         5            2      {0: 1, 1: 1}  \n",
       "231            0.854138         5            2     {0: 1, 1: 10}  \n",
       "311            0.854138         5            2    {0: 1, 1: 100}  \n",
       "399            0.852142         5            4  {0: 1, 1: 10000}  \n",
       "319            0.852142         5            4    {0: 1, 1: 100}  \n",
       "79             0.852142         5            4      {0: 1, 1: 1}  \n",
       "239            0.852142         5            4     {0: 1, 1: 10}  \n",
       "159            0.852142         5            4      {0: 1, 1: 2}  \n",
       "154            0.851835         5            3      {0: 1, 1: 2}  \n",
       "146            0.851835         5            1      {0: 1, 1: 2}  \n",
       "158            0.851835         5            4      {0: 1, 1: 2}  \n",
       "150            0.851835         5            2      {0: 1, 1: 2}  \n",
       "66             0.850760         5            1      {0: 1, 1: 1}  \n",
       "74             0.850760         5            3      {0: 1, 1: 1}  \n",
       "78             0.850760         5            4      {0: 1, 1: 1}  \n",
       "70             0.850760         5            2      {0: 1, 1: 1}  \n",
       "219            0.848457         4            3     {0: 1, 1: 10}  \n",
       "59             0.848457         4            3      {0: 1, 1: 1}  \n",
       "139            0.848457         4            3      {0: 1, 1: 2}  \n",
       "299            0.848457         4            3    {0: 1, 1: 100}  \n",
       "379            0.848457         4            3  {0: 1, 1: 10000}  \n",
       "47             0.847843         3            4      {0: 1, 1: 1}  \n",
       "207            0.847843         3            4     {0: 1, 1: 10}  \n",
       "127            0.847843         3            4      {0: 1, 1: 2}  \n",
       "123            0.847843         3            3      {0: 1, 1: 2}  \n",
       "203            0.847843         3            3     {0: 1, 1: 10}  \n",
       "43             0.847843         3            3      {0: 1, 1: 1}  \n",
       "283            0.847843         3            3    {0: 1, 1: 100}  \n",
       "..                  ...       ...          ...               ...  \n",
       "346            0.242285         2            3  {0: 1, 1: 10000}  \n",
       "342            0.242285         2            2  {0: 1, 1: 10000}  \n",
       "396            0.240749         5            4  {0: 1, 1: 10000}  \n",
       "322            0.240749         1            1  {0: 1, 1: 10000}  \n",
       "388            0.240749         5            2  {0: 1, 1: 10000}  \n",
       "250            0.240749         1            3    {0: 1, 1: 100}  \n",
       "332            0.240749         1            4  {0: 1, 1: 10000}  \n",
       "392            0.240749         5            3  {0: 1, 1: 10000}  \n",
       "324            0.240749         1            2  {0: 1, 1: 10000}  \n",
       "242            0.240749         1            1    {0: 1, 1: 100}  \n",
       "246            0.240749         1            2    {0: 1, 1: 100}  \n",
       "336            0.240749         2            1  {0: 1, 1: 10000}  \n",
       "330            0.240749         1            3  {0: 1, 1: 10000}  \n",
       "328            0.240749         1            3  {0: 1, 1: 10000}  \n",
       "334            0.240749         1            4  {0: 1, 1: 10000}  \n",
       "326            0.240749         1            2  {0: 1, 1: 10000}  \n",
       "254            0.240749         1            4    {0: 1, 1: 100}  \n",
       "384            0.240749         5            1  {0: 1, 1: 10000}  \n",
       "340            0.240749         2            2  {0: 1, 1: 10000}  \n",
       "360            0.240749         3            3  {0: 1, 1: 10000}  \n",
       "380            0.240749         4            4  {0: 1, 1: 10000}  \n",
       "344            0.240749         2            3  {0: 1, 1: 10000}  \n",
       "376            0.240749         4            3  {0: 1, 1: 10000}  \n",
       "348            0.240749         2            4  {0: 1, 1: 10000}  \n",
       "372            0.240749         4            2  {0: 1, 1: 10000}  \n",
       "352            0.240749         3            1  {0: 1, 1: 10000}  \n",
       "368            0.240749         4            1  {0: 1, 1: 10000}  \n",
       "356            0.240749         3            2  {0: 1, 1: 10000}  \n",
       "364            0.240749         3            4  {0: 1, 1: 10000}  \n",
       "320            0.240749         1            1  {0: 1, 1: 10000}  \n",
       "\n",
       "[400 rows x 6 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='Test ROC_AUC Score', ascending=False)\n",
    "\n",
    "# results['Model'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "Which model had the best cross-validation score? Refit this model on the train set and do a final evaluation on the held out test set — what is the test score? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                    XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "CV Mean ROC_AUC Score                                             0.883146\n",
       "Test ROC_AUC Score                                                0.854138\n",
       "max_depth                                                                5\n",
       "n_estimators                                                             2\n",
       "class_weight                                                 {0: 1, 1: 10}\n",
       "Name: 231, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[231]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB with depth 5, 2 estimators seems to have done very well, I'm going to re-calibrate this algorithm with more estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                 80\n",
       "age               260488\n",
       "workclass         260488\n",
       "fnlwgt            260488\n",
       "education         260488\n",
       "education-num     260488\n",
       "marital-status    260488\n",
       "occupation        260488\n",
       "relationship      260488\n",
       "race              260488\n",
       "sex               260488\n",
       "capital-gain      260488\n",
       "capital-loss      260488\n",
       "hours-per-week    260488\n",
       "native-country    260488\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.memory_usage(index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# to fix kernel restart\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# reload data\n",
    "columns = ['age', \n",
    "           'workclass', \n",
    "           'fnlwgt', \n",
    "           'education', \n",
    "           'education-num', \n",
    "           'marital-status', \n",
    "           'occupation', \n",
    "           'relationship', \n",
    "           'race', \n",
    "           'sex', \n",
    "           'capital-gain', \n",
    "           'capital-loss', \n",
    "           'hours-per-week', \n",
    "           'native-country', \n",
    "           'income']\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', \n",
    "                 header=None, names=columns)\n",
    "\n",
    "df['income'] = df['income'].str.strip()\n",
    "\n",
    "# again, a quick and dirty one\n",
    "\n",
    "features = df.drop(columns='income').columns.tolist()\n",
    "target = 'income' #df['income'] == '>50K'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target] == '>50K'\n",
    "\n",
    "# add aditional features\n",
    "\n",
    "# X['cap-gain-binned'] = pd.cut(df['capital-gain'], 5)\n",
    "# X['cap-gain-binned'] = pd.Categorical(X['cap-gain-binned'])\n",
    "\n",
    "X['marital-status'] = df['marital-status'].map({'Married-civ-spouse': 'Married',\n",
    "                                                'Married-AF-spouse': 'Married',\n",
    "                                               'Married-spouse-absent': 'Married'})\n",
    "\n",
    "X['native-country'] = df['native-country'].map({' United-States' : 'NA',\n",
    " ' Cuba':'SA',\n",
    " ' Jamaica': 'SA',\n",
    " ' India':'A',\n",
    " ' ?':'Unknown',\n",
    " ' Mexico':'SA',\n",
    " ' South':'SA',\n",
    " ' Puerto-Rico':'SA',\n",
    " ' Honduras':'SA',\n",
    " ' England':'E',\n",
    " ' Canada':'NA',\n",
    " ' Germany':'E',\n",
    " ' Iran':'ME',\n",
    " ' Philippines':'SEA',\n",
    " ' Italy':\"E\",\n",
    " ' Poland':'EE',\n",
    " ' Columbia':'SA',\n",
    " ' Cambodia':'SEA',\n",
    " ' Thailand':'SEA',\n",
    " ' Ecuador':'SA',\n",
    " ' Laos':'SEA',\n",
    " ' Taiwan':'A',\n",
    " ' Haiti':'SA',\n",
    " ' Portugal':'E',\n",
    " ' Dominican-Republic':'SA',\n",
    " ' El-Salvador':'SA',\n",
    " ' France':'E',\n",
    " ' Guatemala':'SA',\n",
    " ' China':'A',\n",
    " ' Japan':'A',\n",
    " ' Yugoslavia':'EE',\n",
    " ' Peru':'SA',\n",
    " ' Outlying-US(Guam-USVI-etc)':'SEA',\n",
    " ' Scotland':'E',\n",
    " ' Trinadad&Tobago':'SA',\n",
    " ' Greece':'E',\n",
    " ' Nicaragua':'SA',\n",
    " ' Vietnam':'SEA',\n",
    " ' Hong':'A',\n",
    " ' Ireland':'E',\n",
    " ' Hungary':'EE',\n",
    " ' Holand-Netherlands':'E'})\n",
    "\n",
    "# pipeline for preprocessing\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), \n",
    "                            SimpleImputer(),\n",
    "                            MinMaxScaler()\n",
    "                            )\n",
    "\n",
    "# preprocess feature data\n",
    "X = preprocessor.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns = features)\n",
    "\n",
    "# Split Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# parameters to fine tune model\n",
    "max_depth = [3, 4, 5, 6]\n",
    "\n",
    "n_estimators = [2, 4, 10, 20, 100]\n",
    "\n",
    "weights = [{0: 1, 1: 1}, #(equivalent to None)\n",
    "# {0: 1, 1: 2},\n",
    "{0: 1, 1: 10}, #(roughly equivalent to 'balanced' for this dataset)\n",
    "# {0: 1, 1: 100},\n",
    "# {0: 1, 1: 10000}\n",
    "          ]\n",
    "rand_seed = 42\n",
    "\n",
    "\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def test_XG(weights, max_depth, n_estimators):\n",
    "    # columns to hold all values\n",
    "    cols = ['Model', 'CV Mean ROC_AUC Score', \n",
    "            'Test ROC_AUC Score', 'max_depth', 'n_estimators', 'class_weight']\n",
    "    results = []\n",
    "    for weight in weights:\n",
    "        for depth in max_depth:\n",
    "            for n in n_estimators:\n",
    "                \n",
    "                params = {\"n_estimators\":n, \"class_weight\":weight, \"max_depth\":depth,\n",
    "                         # 'tree_method':'gpu_hist'\n",
    "                         }\n",
    "\n",
    "                models = [#LogisticRegression(solver='lbfgs', max_iter=100, \n",
    "                    #class_weight=weight,\n",
    "                           #          random_state=rand_seed),\n",
    "                  #DecisionTreeClassifier(max_depth=depth, class_weight=weight,\n",
    "                   #                      random_state=rand_seed),\n",
    "                  #RandomForestClassifier(max_depth=depth, class_weight=weight,\n",
    "                   #                      random_state=rand_seed),\n",
    "                  XGBClassifier(**params)]\n",
    "\n",
    "                for model in models:\n",
    "                    # define model\n",
    "                    scores = cross_val_score(model, X_train, y_train, \n",
    "                    scoring='roc_auc', cv=3, verbose = True, n_jobs=-1, \n",
    "                                            )\n",
    "                    model.fit(X_train, y_train)\n",
    "                    test_score = model.score(X_test, y_test)\n",
    "                    \n",
    "                    row = [model, scores.mean(), test_score, depth, n, weight]\n",
    "                    results.append(row)\n",
    "\n",
    "    return pd.DataFrame(data = results, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "results = test_XG(weights, max_depth, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Mean ROC_AUC Score</th>\n",
       "      <th>Test ROC_AUC Score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.871948</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.871948</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922233</td>\n",
       "      <td>0.871334</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  CV Mean ROC_AUC Score  \\\n",
       "39  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924348   \n",
       "19  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924348   \n",
       "34  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923453   \n",
       "14  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923453   \n",
       "29  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922233   \n",
       "\n",
       "    Test ROC_AUC Score  max_depth  n_estimators   class_weight  \n",
       "39            0.874251          6           100  {0: 1, 1: 10}  \n",
       "19            0.874251          6           100   {0: 1, 1: 1}  \n",
       "34            0.871948          5           100  {0: 1, 1: 10}  \n",
       "14            0.871948          5           100   {0: 1, 1: 1}  \n",
       "29            0.871334          4           100  {0: 1, 1: 10}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='Test ROC_AUC Score', ascending=False)[:5]\n",
    "# looks like equal weighting with a max depth of 5/6 gives solid results, \n",
    "# I will iterate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "# parameters to fine tune model\n",
    "max_depth = [4, 5, 6, 7]\n",
    "\n",
    "n_estimators = [90, 100, 200]\n",
    "\n",
    "weights = [{0: 1, 1: 1}, #(equivalent to None)\n",
    "{0: 1, 1: 2},\n",
    "{0: 1, 1: 10}, #(roughly equivalent to 'balanced' for this dataset)\n",
    "{0: 1, 1: 100},\n",
    "{0: 1, 1: 10000}]\n",
    "\n",
    "new_results = test_XG(weights, max_depth, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Mean ROC_AUC Score</th>\n",
       "      <th>Test ROC_AUC Score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.877476</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.877476</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.877476</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.877476</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.877476</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924228</td>\n",
       "      <td>0.875326</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924228</td>\n",
       "      <td>0.875326</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924228</td>\n",
       "      <td>0.875326</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924228</td>\n",
       "      <td>0.875326</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924228</td>\n",
       "      <td>0.875326</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924885</td>\n",
       "      <td>0.875173</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924885</td>\n",
       "      <td>0.875173</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924885</td>\n",
       "      <td>0.875173</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924885</td>\n",
       "      <td>0.875173</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924885</td>\n",
       "      <td>0.875173</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923262</td>\n",
       "      <td>0.874559</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923262</td>\n",
       "      <td>0.874559</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923262</td>\n",
       "      <td>0.874559</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923262</td>\n",
       "      <td>0.874559</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923262</td>\n",
       "      <td>0.874559</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925548</td>\n",
       "      <td>0.873791</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925548</td>\n",
       "      <td>0.873791</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925548</td>\n",
       "      <td>0.873791</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925548</td>\n",
       "      <td>0.873791</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.925548</td>\n",
       "      <td>0.873791</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923819</td>\n",
       "      <td>0.873637</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923819</td>\n",
       "      <td>0.873637</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923819</td>\n",
       "      <td>0.873637</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923819</td>\n",
       "      <td>0.873637</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923819</td>\n",
       "      <td>0.873637</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923910</td>\n",
       "      <td>0.873330</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923910</td>\n",
       "      <td>0.873330</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923910</td>\n",
       "      <td>0.873330</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923910</td>\n",
       "      <td>0.873330</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923910</td>\n",
       "      <td>0.873330</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.871948</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.871948</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.871948</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.871948</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.871948</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922233</td>\n",
       "      <td>0.871334</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922233</td>\n",
       "      <td>0.871334</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922233</td>\n",
       "      <td>0.871334</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922233</td>\n",
       "      <td>0.871334</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922233</td>\n",
       "      <td>0.871334</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922811</td>\n",
       "      <td>0.871027</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922811</td>\n",
       "      <td>0.871027</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922811</td>\n",
       "      <td>0.871027</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922811</td>\n",
       "      <td>0.871027</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.922811</td>\n",
       "      <td>0.871027</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.921233</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.921233</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.921233</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.921233</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>0.921233</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  CV Mean ROC_AUC Score  \\\n",
       "53  XGBClassifier(base_score=0.5, booster='gbtree'...               0.925490   \n",
       "5   XGBClassifier(base_score=0.5, booster='gbtree'...               0.925490   \n",
       "29  XGBClassifier(base_score=0.5, booster='gbtree'...               0.925490   \n",
       "17  XGBClassifier(base_score=0.5, booster='gbtree'...               0.925490   \n",
       "41  XGBClassifier(base_score=0.5, booster='gbtree'...               0.925490   \n",
       "46  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924228   \n",
       "34  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924228   \n",
       "58  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924228   \n",
       "10  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924228   \n",
       "22  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924228   \n",
       "44  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924885   \n",
       "20  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924885   \n",
       "8   XGBClassifier(base_score=0.5, booster='gbtree'...               0.924885   \n",
       "56  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924885   \n",
       "32  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924885   \n",
       "23  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923262   \n",
       "35  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923262   \n",
       "59  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923262   \n",
       "47  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923262   \n",
       "11  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923262   \n",
       "19  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924348   \n",
       "43  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924348   \n",
       "7   XGBClassifier(base_score=0.5, booster='gbtree'...               0.924348   \n",
       "55  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924348   \n",
       "31  XGBClassifier(base_score=0.5, booster='gbtree'...               0.924348   \n",
       "14  XGBClassifier(base_score=0.5, booster='gbtree'...               0.925548   \n",
       "50  XGBClassifier(base_score=0.5, booster='gbtree'...               0.925548   \n",
       "26  XGBClassifier(base_score=0.5, booster='gbtree'...               0.925548   \n",
       "38  XGBClassifier(base_score=0.5, booster='gbtree'...               0.925548   \n",
       "2   XGBClassifier(base_score=0.5, booster='gbtree'...               0.925548   \n",
       "42  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923819   \n",
       "54  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923819   \n",
       "30  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923819   \n",
       "6   XGBClassifier(base_score=0.5, booster='gbtree'...               0.923819   \n",
       "18  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923819   \n",
       "33  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923910   \n",
       "21  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923910   \n",
       "57  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923910   \n",
       "9   XGBClassifier(base_score=0.5, booster='gbtree'...               0.923910   \n",
       "45  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923910   \n",
       "4   XGBClassifier(base_score=0.5, booster='gbtree'...               0.923453   \n",
       "52  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923453   \n",
       "16  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923453   \n",
       "40  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923453   \n",
       "28  XGBClassifier(base_score=0.5, booster='gbtree'...               0.923453   \n",
       "1   XGBClassifier(base_score=0.5, booster='gbtree'...               0.922233   \n",
       "49  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922233   \n",
       "13  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922233   \n",
       "25  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922233   \n",
       "37  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922233   \n",
       "51  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922811   \n",
       "15  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922811   \n",
       "3   XGBClassifier(base_score=0.5, booster='gbtree'...               0.922811   \n",
       "39  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922811   \n",
       "27  XGBClassifier(base_score=0.5, booster='gbtree'...               0.922811   \n",
       "36  XGBClassifier(base_score=0.5, booster='gbtree'...               0.921233   \n",
       "24  XGBClassifier(base_score=0.5, booster='gbtree'...               0.921233   \n",
       "12  XGBClassifier(base_score=0.5, booster='gbtree'...               0.921233   \n",
       "48  XGBClassifier(base_score=0.5, booster='gbtree'...               0.921233   \n",
       "0   XGBClassifier(base_score=0.5, booster='gbtree'...               0.921233   \n",
       "\n",
       "    Test ROC_AUC Score  max_depth  n_estimators      class_weight  \n",
       "53            0.877476          5           200  {0: 1, 1: 10000}  \n",
       "5             0.877476          5           200      {0: 1, 1: 1}  \n",
       "29            0.877476          5           200     {0: 1, 1: 10}  \n",
       "17            0.877476          5           200      {0: 1, 1: 2}  \n",
       "41            0.877476          5           200    {0: 1, 1: 100}  \n",
       "46            0.875326          7           100    {0: 1, 1: 100}  \n",
       "34            0.875326          7           100     {0: 1, 1: 10}  \n",
       "58            0.875326          7           100  {0: 1, 1: 10000}  \n",
       "10            0.875326          7           100      {0: 1, 1: 1}  \n",
       "22            0.875326          7           100      {0: 1, 1: 2}  \n",
       "44            0.875173          6           200    {0: 1, 1: 100}  \n",
       "20            0.875173          6           200      {0: 1, 1: 2}  \n",
       "8             0.875173          6           200      {0: 1, 1: 1}  \n",
       "56            0.875173          6           200  {0: 1, 1: 10000}  \n",
       "32            0.875173          6           200     {0: 1, 1: 10}  \n",
       "23            0.874559          7           200      {0: 1, 1: 2}  \n",
       "35            0.874559          7           200     {0: 1, 1: 10}  \n",
       "59            0.874559          7           200  {0: 1, 1: 10000}  \n",
       "47            0.874559          7           200    {0: 1, 1: 100}  \n",
       "11            0.874559          7           200      {0: 1, 1: 1}  \n",
       "19            0.874251          6           100      {0: 1, 1: 2}  \n",
       "43            0.874251          6           100    {0: 1, 1: 100}  \n",
       "7             0.874251          6           100      {0: 1, 1: 1}  \n",
       "55            0.874251          6           100  {0: 1, 1: 10000}  \n",
       "31            0.874251          6           100     {0: 1, 1: 10}  \n",
       "14            0.873791          4           200      {0: 1, 1: 2}  \n",
       "50            0.873791          4           200  {0: 1, 1: 10000}  \n",
       "26            0.873791          4           200     {0: 1, 1: 10}  \n",
       "38            0.873791          4           200    {0: 1, 1: 100}  \n",
       "2             0.873791          4           200      {0: 1, 1: 1}  \n",
       "42            0.873637          6            90    {0: 1, 1: 100}  \n",
       "54            0.873637          6            90  {0: 1, 1: 10000}  \n",
       "30            0.873637          6            90     {0: 1, 1: 10}  \n",
       "6             0.873637          6            90      {0: 1, 1: 1}  \n",
       "18            0.873637          6            90      {0: 1, 1: 2}  \n",
       "33            0.873330          7            90     {0: 1, 1: 10}  \n",
       "21            0.873330          7            90      {0: 1, 1: 2}  \n",
       "57            0.873330          7            90  {0: 1, 1: 10000}  \n",
       "9             0.873330          7            90      {0: 1, 1: 1}  \n",
       "45            0.873330          7            90    {0: 1, 1: 100}  \n",
       "4             0.871948          5           100      {0: 1, 1: 1}  \n",
       "52            0.871948          5           100  {0: 1, 1: 10000}  \n",
       "16            0.871948          5           100      {0: 1, 1: 2}  \n",
       "40            0.871948          5           100    {0: 1, 1: 100}  \n",
       "28            0.871948          5           100     {0: 1, 1: 10}  \n",
       "1             0.871334          4           100      {0: 1, 1: 1}  \n",
       "49            0.871334          4           100  {0: 1, 1: 10000}  \n",
       "13            0.871334          4           100      {0: 1, 1: 2}  \n",
       "25            0.871334          4           100     {0: 1, 1: 10}  \n",
       "37            0.871334          4           100    {0: 1, 1: 100}  \n",
       "51            0.871027          5            90  {0: 1, 1: 10000}  \n",
       "15            0.871027          5            90      {0: 1, 1: 2}  \n",
       "3             0.871027          5            90      {0: 1, 1: 1}  \n",
       "39            0.871027          5            90    {0: 1, 1: 100}  \n",
       "27            0.871027          5            90     {0: 1, 1: 10}  \n",
       "36            0.869492          4            90    {0: 1, 1: 100}  \n",
       "24            0.869492          4            90     {0: 1, 1: 10}  \n",
       "12            0.869492          4            90      {0: 1, 1: 2}  \n",
       "48            0.869492          4            90  {0: 1, 1: 10000}  \n",
       "0             0.869492          4            90      {0: 1, 1: 1}  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results.sort_values(by='Test ROC_AUC Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like classweight doesn't matter because it fluxuates widly witthin the top model parameters, my wining model params are:\n",
    "params = {\"n_estimators\":200, \"class_weight\":None, \"max_depth\":5\n",
    "XGBClassifier(**params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "Calculate F1 score and False Positive Rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.94      0.91      4945\n",
      "        True       0.77      0.63      0.69      1568\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      6513\n",
      "   macro avg       0.83      0.78      0.80      6513\n",
      "weighted avg       0.86      0.86      0.86      6513\n",
      "\n",
      "False Positive Rate:  0.06086956521739131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "params = {\"n_estimators\":200, \"class_weight\":None, \"max_depth\":5}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "y_pred_proba = cross_val_predict(model, X_test, y_test, cv=3, n_jobs=-1, \n",
    "                                 method='predict_proba')[:,1]\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "y_pred = y_pred_proba >= threshold\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "             columns=['Predicted Negative', 'Predicted Positive'], \n",
    "             index=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "# FPR = FP / (FP + TN)\n",
    "\n",
    "FPR = 301 / (301+4644)\n",
    "\n",
    "print('False Positive Rate: ', FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an attempt to use numba to cast my regression optimization function to gpu, didn't work, will figure out why eventually\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jit Optomized Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# reload data\n",
    "columns = ['age', \n",
    "           'workclass', \n",
    "           'fnlwgt', \n",
    "           'education', \n",
    "           'education-num', \n",
    "           'marital-status', \n",
    "           'occupation', \n",
    "           'relationship', \n",
    "           'race', \n",
    "           'sex', \n",
    "           'capital-gain', \n",
    "           'capital-loss', \n",
    "           'hours-per-week', \n",
    "           'native-country', \n",
    "           'income']\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', \n",
    "                 header=None, names=columns)\n",
    "\n",
    "df['income'] = df['income'].str.strip()\n",
    "\n",
    "# again, a quick and dirty one\n",
    "\n",
    "features = df.drop(columns='income').columns.tolist()\n",
    "target = 'income' #df['income'] == '>50K'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target] == '>50K'\n",
    "\n",
    "# add aditional features\n",
    "\n",
    "# X['cap-gain-binned'] = pd.cut(df['capital-gain'], 5)\n",
    "# X['cap-gain-binned'] = pd.Categorical(X['cap-gain-binned'])\n",
    "\n",
    "X['marital-status'] = df['marital-status'].map({'Married-civ-spouse': 'Married',\n",
    "                                                'Married-AF-spouse': 'Married',\n",
    "                                               'Married-spouse-absent': 'Married'})\n",
    "\n",
    "X['native-country'] = df['native-country'].map({' United-States' : 'NA',\n",
    " ' Cuba':'SA',\n",
    " ' Jamaica': 'SA',\n",
    " ' India':'A',\n",
    " ' ?':'Unknown',\n",
    " ' Mexico':'SA',\n",
    " ' South':'SA',\n",
    " ' Puerto-Rico':'SA',\n",
    " ' Honduras':'SA',\n",
    " ' England':'E',\n",
    " ' Canada':'NA',\n",
    " ' Germany':'E',\n",
    " ' Iran':'ME',\n",
    " ' Philippines':'SEA',\n",
    " ' Italy':\"E\",\n",
    " ' Poland':'EE',\n",
    " ' Columbia':'SA',\n",
    " ' Cambodia':'SEA',\n",
    " ' Thailand':'SEA',\n",
    " ' Ecuador':'SA',\n",
    " ' Laos':'SEA',\n",
    " ' Taiwan':'A',\n",
    " ' Haiti':'SA',\n",
    " ' Portugal':'E',\n",
    " ' Dominican-Republic':'SA',\n",
    " ' El-Salvador':'SA',\n",
    " ' France':'E',\n",
    " ' Guatemala':'SA',\n",
    " ' China':'A',\n",
    " ' Japan':'A',\n",
    " ' Yugoslavia':'EE',\n",
    " ' Peru':'SA',\n",
    " ' Outlying-US(Guam-USVI-etc)':'SEA',\n",
    " ' Scotland':'E',\n",
    " ' Trinadad&Tobago':'SA',\n",
    " ' Greece':'E',\n",
    " ' Nicaragua':'SA',\n",
    " ' Vietnam':'SEA',\n",
    " ' Hong':'A',\n",
    " ' Ireland':'E',\n",
    " ' Hungary':'EE',\n",
    " ' Holand-Netherlands':'E'})\n",
    "\n",
    "# pipeline for preprocessing\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), \n",
    "                            SimpleImputer(),\n",
    "                            MinMaxScaler()\n",
    "                            )\n",
    "\n",
    "# preprocess feature data\n",
    "X = preprocessor.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns = features)\n",
    "\n",
    "# Split Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# parameters to fine tune model\n",
    "max_depth = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "n_estimators = [10, 40, 100, 200, 300]\n",
    "\n",
    "weights = [{0: 1, 1: 1}, #(equivalent to None)\n",
    "# {0: 1, 1: 2},\n",
    "{0: 1, 1: 10}, #(roughly equivalent to 'balanced' for this dataset)\n",
    "{0: 1, 1: 100},\n",
    "# {0: 1, 1: 10000}\n",
    "          ]\n",
    "\n",
    "\n",
    "\n",
    "# dataframe to hold all values\n",
    "results = pd.DataFrame(columns = ['Model', 'CV Mean ROC_AUC Score', \n",
    "            'Test ROC_AUC Score', 'max_depth', 'n_estimators', 'class_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_XGB_opt(weights, max_depth, n_estimators):\n",
    "    # dataframe to hold all values\n",
    "    results = pd.DataFrame(columns = ['Model', 'CV Mean ROC_AUC Score', \n",
    "            'Test ROC_AUC Score', 'max_depth', 'n_estimators', 'class_weight'])\n",
    "\n",
    "    for weight in weights:\n",
    "        for depth in max_depth:\n",
    "            for n in n_estimators:\n",
    "\n",
    "                models = [#LogisticRegression(solver='lbfgs', max_iter=100, class_weight=weight,\n",
    "                           #          random_state=rand_seed),\n",
    "                  #DecisionTreeClassifier(max_depth=depth, class_weight=weight,\n",
    "                   #                      random_state=rand_seed),\n",
    "                  #RandomForestClassifier(max_depth=depth, class_weight=weight,\n",
    "                   #                      random_state=rand_seed),\n",
    "                  XGBClassifier(max_depth=depth, n_estimators = n,\n",
    "                                n_jobs=-1, random_state=rand_seed)\n",
    "                 ]\n",
    "\n",
    "                for model in models:\n",
    "                    # define model\n",
    "                    scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=5,\n",
    "                               n_jobs=-1, verbose = True)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    test_score = model.score(X_test, y_test)\n",
    "\n",
    "                    # append to dataframe\n",
    "                    results = results.append({'Model': model, 'CV Mean ROC_AUC Score': scores.mean(), \n",
    "                        'Test ROC_AUC Score': test_score, 'max_depth':depth, 'n_estimators':n, \n",
    "                                              'class_weight':weight}, \n",
    "                                        ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=False)\n",
    "def fast_XGB_opt(weights, max_depth, n_estimators):\n",
    "    # dataframe to hold all values\n",
    "    results = pd.DataFrame(columns = ['Model', 'CV Mean ROC_AUC Score', \n",
    "            'Test ROC_AUC Score', 'max_depth', 'n_estimators', 'class_weight'])\n",
    "\n",
    "    for weight in weights:\n",
    "        for depth in max_depth:\n",
    "            for n in n_estimators:\n",
    "\n",
    "                models = [#LogisticRegression(solver='lbfgs', max_iter=100, class_weight=weight,\n",
    "                           #          random_state=rand_seed),\n",
    "                  #DecisionTreeClassifier(max_depth=depth, class_weight=weight,\n",
    "                   #                      random_state=rand_seed),\n",
    "                  #RandomForestClassifier(max_depth=depth, class_weight=weight,\n",
    "                   #                      random_state=rand_seed),\n",
    "                  XGBClassifier(max_depth=depth, n_estimators = n,\n",
    "                                n_jobs=-1, tree_method='gpu_hist', random_state=rand_seed)\n",
    "                 ]\n",
    "\n",
    "                for model in models:\n",
    "                    # define model\n",
    "                    scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=5,\n",
    "                               n_jobs=-1, verbose = True)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    test_score = model.score(X_test, y_test)\n",
    "\n",
    "                    # append to dataframe\n",
    "                    results = results.append({'Model': model, 'CV Mean ROC_AUC Score': scores.mean(), \n",
    "                        'Test ROC_AUC Score': test_score, 'max_depth':depth, 'n_estimators':n, \n",
    "                                              'class_weight':weight}, \n",
    "                                        ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGABRT(-6)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-bf4dadd79be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_XGB_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGABRT(-6)}"
     ]
    }
   ],
   "source": [
    "results = fast_XGB_opt(weights, max_depth, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Mean ROC_AUC Score</th>\n",
       "      <th>Test ROC_AUC Score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, CV Mean ROC_AUC Score, Test ROC_AUC Score, max_depth, n_estimators, class_weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='Test ROC_AUC Score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
