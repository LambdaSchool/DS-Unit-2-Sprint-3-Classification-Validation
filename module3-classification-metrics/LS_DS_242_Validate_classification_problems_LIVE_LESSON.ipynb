{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_242_Validate_classification_problems_LIVE_LESSON.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dustiny5/DS-Unit-2-Sprint-3-Classification-Validation/blob/master/module3-classification-metrics/LS_DS_242_Validate_classification_problems_LIVE_LESSON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KMI2k-oBsS08"
      },
      "source": [
        "_Lambda School Data Science — Model Validation_ \n",
        "\n",
        "# Classification Metrics & Imbalanced Classes\n",
        "\n",
        "#### Objectives\n",
        "- Classification Metrics: Accuracy, Precision, Recall, F1, ROC AUC\n",
        "- Confusion Matrix\n",
        "- Imbalanced Classes\n",
        "\n",
        "#### Pre-reads\n",
        "- [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
        "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
        "- [ROC curves and Area Under the Curve explained](https://www.dataschool.io/roc-curves-and-auc-explained/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rU7RuVcjWdcp"
      },
      "source": [
        "## Preliminary setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WIqp4yzdUsf2"
      },
      "source": [
        "#### Install [category_encoders](https://github.com/scikit-learn-contrib/categorical-encoding)\n",
        "- Google Colab: `pip install category_encoders`\n",
        "- Local, Anaconda: `conda install -c conda-forge category_encoders`\n",
        "\n",
        "#### Install  [mlxtend](http://rasbt.github.io/mlxtend/) to plot decision regions\n",
        "- Google Colab: Already installed\n",
        "- Local, Anaconda: `conda install -c conda-forge mlxtend`\n",
        "\n",
        "#### Get the Bank Marketing dataset\n",
        "- Download from [UCI](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)\n",
        "- Or run this cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-APggeyL-zZ",
        "colab_type": "code",
        "outputId": "75d7dd9b-3553-43b2-e277-af9cdca82e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.9.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.20.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ut7wm5_xUqvz",
        "outputId": "85782307-2754-4183-a735-a6b50c7c0264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
        "!unzip bank-additional.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-08 21:18:11--  https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 444572 (434K) [application/x-httpd-php]\n",
            "Saving to: ‘bank-additional.zip.1’\n",
            "\n",
            "bank-additional.zip 100%[===================>] 434.15K  1.28MB/s    in 0.3s    \n",
            "\n",
            "2019-05-08 21:18:12 (1.28 MB/s) - ‘bank-additional.zip.1’ saved [444572/444572]\n",
            "\n",
            "Archive:  bank-additional.zip\n",
            "replace bank-additional/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace bank-additional/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/bank-additional/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/.Rhistory? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional-full.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional-names.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/._bank-additional? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exZrRRC2WObS"
      },
      "source": [
        "# Classification Metrics & Confusion Matrix — with Bank Marketing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1FnLW0DjWKaW",
        "colab": {}
      },
      "source": [
        "# This code comes from our previous notebook\n",
        "\n",
        "# Imports\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "import category_encoders as ce\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "\n",
        "# Load data\n",
        "bank = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\n",
        "\n",
        "# Assign to X, y\n",
        "X = bank.drop(columns='y')\n",
        "y = bank['y'] == 'yes'\n",
        "\n",
        "# Drop leaky feature\n",
        "X = X.drop(columns='duration')\n",
        "\n",
        "# Split Train, Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Make pipeline\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True), \n",
        "    StandardScaler(), \n",
        "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ktgWzULWW2Z0"
      },
      "source": [
        "#### scikit-learn documentation\n",
        "- [sklearn.linear_model.LogisticRegression.predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba)\n",
        "- [sklearn.metrics.classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
        "- [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
        "- [sklearn.model_selection.cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bXN_sDXYWkj4",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_pred_proba = cross_val_predict(pipeline, X_train, y_train, cv=3, n_jobs=-1, \n",
        "                                 method='predict_proba')[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-aDDXBEJsQy",
        "colab_type": "text"
      },
      "source": [
        "#### Change the threshold and re-run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW8q4V67JsQz",
        "colab_type": "code",
        "outputId": "9f4fb5db-0270-4b45-a49d-a74058bdb52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "threshold = 0.5\n",
        "y_pred = y_pred_proba >= threshold\n",
        "correct = y_pred == y_train\n",
        "\n",
        "labels = pd.DataFrame({'Ground Truth': y_train, \n",
        "                       'Predicted Probability': y_pred_proba, \n",
        "                       'Discrete Prediction': y_pred, \n",
        "                       'Correct Prediction?': correct})\n",
        "\n",
        "labels.head(20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ground Truth</th>\n",
              "      <th>Predicted Probability</th>\n",
              "      <th>Discrete Prediction</th>\n",
              "      <th>Correct Prediction?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25611</th>\n",
              "      <td>False</td>\n",
              "      <td>0.047259</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26010</th>\n",
              "      <td>False</td>\n",
              "      <td>0.025392</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40194</th>\n",
              "      <td>True</td>\n",
              "      <td>0.600246</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>False</td>\n",
              "      <td>0.031742</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36344</th>\n",
              "      <td>False</td>\n",
              "      <td>0.440106</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21806</th>\n",
              "      <td>False</td>\n",
              "      <td>0.065051</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37395</th>\n",
              "      <td>True</td>\n",
              "      <td>0.225595</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25863</th>\n",
              "      <td>False</td>\n",
              "      <td>0.065761</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7393</th>\n",
              "      <td>False</td>\n",
              "      <td>0.026482</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14697</th>\n",
              "      <td>False</td>\n",
              "      <td>0.069068</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17537</th>\n",
              "      <td>False</td>\n",
              "      <td>0.044403</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>False</td>\n",
              "      <td>0.035158</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13720</th>\n",
              "      <td>False</td>\n",
              "      <td>0.070268</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12258</th>\n",
              "      <td>False</td>\n",
              "      <td>0.043146</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32042</th>\n",
              "      <td>False</td>\n",
              "      <td>0.098642</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31118</th>\n",
              "      <td>True</td>\n",
              "      <td>0.105448</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20444</th>\n",
              "      <td>False</td>\n",
              "      <td>0.054744</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4216</th>\n",
              "      <td>False</td>\n",
              "      <td>0.026534</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6347</th>\n",
              "      <td>False</td>\n",
              "      <td>0.024661</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39226</th>\n",
              "      <td>True</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Ground Truth  Predicted Probability  Discrete Prediction  \\\n",
              "25611         False               0.047259                False   \n",
              "26010         False               0.025392                False   \n",
              "40194          True               0.600246                 True   \n",
              "297           False               0.031742                False   \n",
              "36344         False               0.440106                False   \n",
              "21806         False               0.065051                False   \n",
              "37395          True               0.225595                False   \n",
              "25863         False               0.065761                False   \n",
              "7393          False               0.026482                False   \n",
              "14697         False               0.069068                False   \n",
              "17537         False               0.044403                False   \n",
              "1595          False               0.035158                False   \n",
              "13720         False               0.070268                False   \n",
              "12258         False               0.043146                False   \n",
              "32042         False               0.098642                False   \n",
              "31118          True               0.105448                False   \n",
              "20444         False               0.054744                False   \n",
              "4216          False               0.026534                False   \n",
              "6347          False               0.024661                False   \n",
              "39226          True               0.864744                 True   \n",
              "\n",
              "       Correct Prediction?  \n",
              "25611                 True  \n",
              "26010                 True  \n",
              "40194                 True  \n",
              "297                   True  \n",
              "36344                 True  \n",
              "21806                 True  \n",
              "37395                False  \n",
              "25863                 True  \n",
              "7393                  True  \n",
              "14697                 True  \n",
              "17537                 True  \n",
              "1595                  True  \n",
              "13720                 True  \n",
              "12258                 True  \n",
              "32042                 True  \n",
              "31118                False  \n",
              "20444                 True  \n",
              "4216                  True  \n",
              "6347                  True  \n",
              "39226                 True  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h01_ZZxcX0hf"
      },
      "source": [
        "#### Change the threshold and re-run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4xRbAMxmXrXw",
        "outputId": "1193396d-5ade-49eb-b73b-5c84deaaaca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "threshold = 0.5\n",
        "y_pred = y_pred_proba >= threshold\n",
        "\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "pd.DataFrame(confusion_matrix(y_train, y_pred), \n",
        "             columns=['Predicted Negative', 'Predicted Positive'], \n",
        "             index=['Actual Negative', 'Actual Positive'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.98      0.95     29238\n",
            "        True       0.66      0.23      0.34      3712\n",
            "\n",
            "   micro avg       0.90      0.90      0.90     32950\n",
            "   macro avg       0.78      0.61      0.64     32950\n",
            "weighted avg       0.88      0.90      0.88     32950\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>28786</td>\n",
              "      <td>452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>2852</td>\n",
              "      <td>860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative               28786                 452\n",
              "Actual Positive                2852                 860"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aDjSVgRUD99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63b5a461-e866-4f08-fa1a-a6a9b1cfb93c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8997268588770865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "InBb016HcSef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "31044c06-770c-45d3-a58a-c26ba6149199"
      },
      "source": [
        "#TODO \n",
        "\n",
        "true_negative  = 28786\n",
        "false_positive = 452\n",
        "false_negative = 2852\n",
        "true_positive  = 860\n",
        "\n",
        "actual_negative = 28786 + 452\n",
        "actual_positive = 2852 + 860\n",
        "\n",
        "predicted_negative = 28786 + 2852\n",
        "predicted_positive = 452 + 860\n",
        "\n",
        "accuracy = (true_positive + true_negative) / (predicted_negative + predicted_positive)\n",
        "precision = true_positive / predicted_positive\n",
        "recall = true_positive / actual_positive\n",
        "f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8997268588770865\n",
            "Precision: 0.6554878048780488\n",
            "Recall: 0.23168103448275862\n",
            "F1: 0.34235668789808915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3_OogSbJsQ9",
        "colab_type": "text"
      },
      "source": [
        "#### F1 Score\n",
        "\"[The F1 score](https://en.wikipedia.org/wiki/F1_score) is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d50kghfPYk1D"
      },
      "source": [
        "### ROC AUC (Receiver Operating Characteristic, Area Under the Curve)\n",
        "\n",
        "#### Scikit-Learn docs\n",
        "- [User Guide: Receiver operating characteristic (ROC)](https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc)\n",
        "- [sklearn.metrics.roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
        "- [sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
        "\n",
        "#### More links\n",
        "- [ROC curves and Area Under the Curve explained](https://www.dataschool.io/roc-curves-and-auc-explained/)\n",
        "- [The philosophical argument for using ROC curves](https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/)\n",
        "\n",
        "[Wikipedia explains,](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) \"A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\"\n",
        "\n",
        "ROC AUC is the area under the ROC curve. [It can be interpreted](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it) as \"the expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\" \n",
        "\n",
        "ROC AUC measures how well a classifier ranks predicted probabilities. It ranges from 0 to 1. A naive majority class baseline will have an ROC AUC score of 0.5. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yx5WEweMYBYY",
        "outputId": "84efe268-cf51-45b7-aa74-42d4d0f1fa60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_train, y_pred_proba)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "print('Area under the Receiver Operating Characteristic curve:', \n",
        "      roc_auc_score(y_train, y_pred_proba))\n",
        "    \n",
        "# When threshold = 0.5\n",
        "false_positives = 452\n",
        "true_positives = 860\n",
        "false_positive_rate = false_positives/actual_negative\n",
        "true_positive_rate = true_positives/actual_positive\n",
        "plt.scatter(false_positive_rate, true_positive_rate)\n",
        "\n",
        "# When threshold = 0.1\n",
        "false_positives = 5267\n",
        "true_positives = 2418\n",
        "false_positive_rate = false_positives/actual_negative\n",
        "true_positive_rate = true_positives/actual_positive\n",
        "plt.scatter(false_positive_rate, true_positive_rate);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under the Receiver Operating Characteristic curve: 0.7885656855096462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG4tKDkjg7Ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1949
        },
        "outputId": "a0f15ae8-052f-4715-934f-7092657364c4"
      },
      "source": [
        "#False Positive Rate, True Positive Rate, Thresholds\n",
        "pd.DataFrame(dict(fpr=fpr, tpr=tpr, thresholds=thresholds))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fpr</th>\n",
              "      <th>tpr</th>\n",
              "      <th>thresholds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.903011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>0.903011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004849</td>\n",
              "      <td>0.880439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.004849</td>\n",
              "      <td>0.879162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.008890</td>\n",
              "      <td>0.872156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.008890</td>\n",
              "      <td>0.871648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.009429</td>\n",
              "      <td>0.870454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.009429</td>\n",
              "      <td>0.869912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.011584</td>\n",
              "      <td>0.864618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.011584</td>\n",
              "      <td>0.864278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.011853</td>\n",
              "      <td>0.864162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.011853</td>\n",
              "      <td>0.863380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.013470</td>\n",
              "      <td>0.859477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.000274</td>\n",
              "      <td>0.013470</td>\n",
              "      <td>0.859123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000274</td>\n",
              "      <td>0.014278</td>\n",
              "      <td>0.858618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.014278</td>\n",
              "      <td>0.857997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.016433</td>\n",
              "      <td>0.855685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.016433</td>\n",
              "      <td>0.855667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>0.853289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>0.853093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.017511</td>\n",
              "      <td>0.853080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.000445</td>\n",
              "      <td>0.017511</td>\n",
              "      <td>0.852837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.000445</td>\n",
              "      <td>0.018319</td>\n",
              "      <td>0.851754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.000479</td>\n",
              "      <td>0.018319</td>\n",
              "      <td>0.850708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.000479</td>\n",
              "      <td>0.023976</td>\n",
              "      <td>0.839698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.000547</td>\n",
              "      <td>0.023976</td>\n",
              "      <td>0.839058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.000547</td>\n",
              "      <td>0.024246</td>\n",
              "      <td>0.837371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.000616</td>\n",
              "      <td>0.024246</td>\n",
              "      <td>0.836484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.000616</td>\n",
              "      <td>0.027478</td>\n",
              "      <td>0.830113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.000718</td>\n",
              "      <td>0.027478</td>\n",
              "      <td>0.828908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5861</th>\n",
              "      <td>0.991620</td>\n",
              "      <td>0.996498</td>\n",
              "      <td>0.019069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5862</th>\n",
              "      <td>0.992578</td>\n",
              "      <td>0.996498</td>\n",
              "      <td>0.018636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5863</th>\n",
              "      <td>0.992578</td>\n",
              "      <td>0.996767</td>\n",
              "      <td>0.018619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5864</th>\n",
              "      <td>0.992954</td>\n",
              "      <td>0.996767</td>\n",
              "      <td>0.018314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5865</th>\n",
              "      <td>0.993023</td>\n",
              "      <td>0.996767</td>\n",
              "      <td>0.018309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5866</th>\n",
              "      <td>0.994391</td>\n",
              "      <td>0.996767</td>\n",
              "      <td>0.017657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5867</th>\n",
              "      <td>0.994391</td>\n",
              "      <td>0.997037</td>\n",
              "      <td>0.017653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5868</th>\n",
              "      <td>0.995109</td>\n",
              "      <td>0.997037</td>\n",
              "      <td>0.017248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5869</th>\n",
              "      <td>0.995109</td>\n",
              "      <td>0.997306</td>\n",
              "      <td>0.017245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5870</th>\n",
              "      <td>0.995383</td>\n",
              "      <td>0.997306</td>\n",
              "      <td>0.016898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5871</th>\n",
              "      <td>0.995383</td>\n",
              "      <td>0.997575</td>\n",
              "      <td>0.016895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5872</th>\n",
              "      <td>0.996511</td>\n",
              "      <td>0.997575</td>\n",
              "      <td>0.015977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5873</th>\n",
              "      <td>0.996511</td>\n",
              "      <td>0.997845</td>\n",
              "      <td>0.015925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5874</th>\n",
              "      <td>0.997435</td>\n",
              "      <td>0.997845</td>\n",
              "      <td>0.015086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5875</th>\n",
              "      <td>0.997435</td>\n",
              "      <td>0.998114</td>\n",
              "      <td>0.015053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5876</th>\n",
              "      <td>0.997572</td>\n",
              "      <td>0.998114</td>\n",
              "      <td>0.014752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5877</th>\n",
              "      <td>0.997572</td>\n",
              "      <td>0.998384</td>\n",
              "      <td>0.014645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5878</th>\n",
              "      <td>0.998393</td>\n",
              "      <td>0.998384</td>\n",
              "      <td>0.013553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5879</th>\n",
              "      <td>0.998393</td>\n",
              "      <td>0.998653</td>\n",
              "      <td>0.013546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5880</th>\n",
              "      <td>0.998564</td>\n",
              "      <td>0.998653</td>\n",
              "      <td>0.012834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5881</th>\n",
              "      <td>0.998564</td>\n",
              "      <td>0.998922</td>\n",
              "      <td>0.012810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5882</th>\n",
              "      <td>0.999248</td>\n",
              "      <td>0.998922</td>\n",
              "      <td>0.009858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5883</th>\n",
              "      <td>0.999248</td>\n",
              "      <td>0.999192</td>\n",
              "      <td>0.009659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5884</th>\n",
              "      <td>0.999795</td>\n",
              "      <td>0.999192</td>\n",
              "      <td>0.002071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5885</th>\n",
              "      <td>0.999795</td>\n",
              "      <td>0.999461</td>\n",
              "      <td>0.001114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5886</th>\n",
              "      <td>0.999829</td>\n",
              "      <td>0.999461</td>\n",
              "      <td>0.001028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5887</th>\n",
              "      <td>0.999829</td>\n",
              "      <td>0.999731</td>\n",
              "      <td>0.000876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5888</th>\n",
              "      <td>0.999897</td>\n",
              "      <td>0.999731</td>\n",
              "      <td>0.000409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5889</th>\n",
              "      <td>0.999897</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5890</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5891 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           fpr       tpr  thresholds\n",
              "0     0.000000  0.000000    1.903011\n",
              "1     0.000000  0.000269    0.903011\n",
              "2     0.000000  0.004849    0.880439\n",
              "3     0.000034  0.004849    0.879162\n",
              "4     0.000034  0.008890    0.872156\n",
              "5     0.000103  0.008890    0.871648\n",
              "6     0.000103  0.009429    0.870454\n",
              "7     0.000137  0.009429    0.869912\n",
              "8     0.000137  0.011584    0.864618\n",
              "9     0.000171  0.011584    0.864278\n",
              "10    0.000171  0.011853    0.864162\n",
              "11    0.000239  0.011853    0.863380\n",
              "12    0.000239  0.013470    0.859477\n",
              "13    0.000274  0.013470    0.859123\n",
              "14    0.000274  0.014278    0.858618\n",
              "15    0.000342  0.014278    0.857997\n",
              "16    0.000342  0.016433    0.855685\n",
              "17    0.000376  0.016433    0.855667\n",
              "18    0.000376  0.017241    0.853289\n",
              "19    0.000410  0.017241    0.853093\n",
              "20    0.000410  0.017511    0.853080\n",
              "21    0.000445  0.017511    0.852837\n",
              "22    0.000445  0.018319    0.851754\n",
              "23    0.000479  0.018319    0.850708\n",
              "24    0.000479  0.023976    0.839698\n",
              "25    0.000547  0.023976    0.839058\n",
              "26    0.000547  0.024246    0.837371\n",
              "27    0.000616  0.024246    0.836484\n",
              "28    0.000616  0.027478    0.830113\n",
              "29    0.000718  0.027478    0.828908\n",
              "...        ...       ...         ...\n",
              "5861  0.991620  0.996498    0.019069\n",
              "5862  0.992578  0.996498    0.018636\n",
              "5863  0.992578  0.996767    0.018619\n",
              "5864  0.992954  0.996767    0.018314\n",
              "5865  0.993023  0.996767    0.018309\n",
              "5866  0.994391  0.996767    0.017657\n",
              "5867  0.994391  0.997037    0.017653\n",
              "5868  0.995109  0.997037    0.017248\n",
              "5869  0.995109  0.997306    0.017245\n",
              "5870  0.995383  0.997306    0.016898\n",
              "5871  0.995383  0.997575    0.016895\n",
              "5872  0.996511  0.997575    0.015977\n",
              "5873  0.996511  0.997845    0.015925\n",
              "5874  0.997435  0.997845    0.015086\n",
              "5875  0.997435  0.998114    0.015053\n",
              "5876  0.997572  0.998114    0.014752\n",
              "5877  0.997572  0.998384    0.014645\n",
              "5878  0.998393  0.998384    0.013553\n",
              "5879  0.998393  0.998653    0.013546\n",
              "5880  0.998564  0.998653    0.012834\n",
              "5881  0.998564  0.998922    0.012810\n",
              "5882  0.999248  0.998922    0.009858\n",
              "5883  0.999248  0.999192    0.009659\n",
              "5884  0.999795  0.999192    0.002071\n",
              "5885  0.999795  0.999461    0.001114\n",
              "5886  0.999829  0.999461    0.001028\n",
              "5887  0.999829  0.999731    0.000876\n",
              "5888  0.999897  0.999731    0.000409\n",
              "5889  0.999897  1.000000    0.000254\n",
              "5890  1.000000  1.000000    0.000104\n",
              "\n",
              "[5891 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DMiqiAB_WVPK"
      },
      "source": [
        "# Imbalanced Classes — with synthetic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OWLBlu5K5kJR"
      },
      "source": [
        "## Fun demo!\n",
        "\n",
        "The next code cell does five things:\n",
        "\n",
        "#### 1. Generate data\n",
        "\n",
        "We use scikit-learn's [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function to generate fake data for a binary classification problem, based on several parameters, including:\n",
        "- Number of samples\n",
        "- Weights, meaning \"the proportions of samples assigned to each class.\"\n",
        "- Class separation: \"Larger values spread out the clusters/classes and make the classification task easier.\"\n",
        "\n",
        "(We are generating fake data so it is easy to visualize.)\n",
        "\n",
        "#### 2. Split data\n",
        "\n",
        "We split the data three ways, into train, validation, and test sets. (For this toy example, it's not really necessary to do a three-way split. A two-way split, or even no split, would be ok. But I'm trying to demonstrate good habits, even in toy examples, to avoid confusion.)\n",
        "\n",
        "#### 3. Fit model\n",
        "\n",
        "We use scikit-learn to fit a [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the training data.\n",
        "\n",
        "We use this model parameter:\n",
        "\n",
        "> **class_weight : _dict or ‘balanced’, default: None_**\n",
        "\n",
        "> Weights associated with classes in the form `{class_label: weight}`. If not given, all classes are supposed to have weight one.\n",
        "\n",
        "> The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n_samples / (n_classes * np.bincount(y))`.\n",
        "\n",
        "\n",
        "#### 4. Evaluate model\n",
        "\n",
        "We use our Logistic Regression model, which was fit on the training data, to generate predictions for the validation data.\n",
        "\n",
        "Then we print [scikit-learn's Classification Report](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), with many metrics, and also the accuracy score. We are comparing the correct labels to the Logistic Regression's predicted labels, for the validation set. \n",
        "\n",
        "#### 5. Visualize decision function\n",
        "\n",
        "Based on these examples\n",
        "- https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/combine/plot_comparison_combine.html\n",
        "- http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/#example-1-decision-regions-in-2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PMTjC3vQ7ZNV",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_validation_test_split(\n",
        "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, \n",
        "    random_state=None, shuffle=True):\n",
        "        \n",
        "    assert train_size + val_size + test_size == 1\n",
        "    \n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, shuffle=shuffle)\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val, y_train_val, test_size=val_size/(train_size+val_size), \n",
        "        random_state=random_state, shuffle=shuffle)\n",
        "    \n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TcpoWCUq5xNV",
        "outputId": "c33a3d88-eaf0-4d5f-a036-7758cfc3f443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "#1. Generate data\n",
        "\n",
        "# Try re-running the cell with different values for these parameters\n",
        "n_samples = 1000\n",
        "weights = (0.95, 0.05)\n",
        "class_sep = 0.8\n",
        "\n",
        "X, y = make_classification(n_samples=n_samples, n_features=2, n_informative=2, \n",
        "                           n_redundant=0, n_repeated=0, n_classes=2, \n",
        "                           n_clusters_per_class=1, weights=weights, \n",
        "                           class_sep=class_sep, random_state=0)\n",
        "\n",
        "\n",
        "# 2. Split data\n",
        "\n",
        "# Uses our custom train_validation_test_split function\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
        "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=1)\n",
        "\n",
        "\n",
        "# 3. Fit model\n",
        "\n",
        "# Try re-running the cell with different values for this parameter\n",
        "class_weight = None\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs', class_weight=class_weight)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 4. Evaluate model\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "print('accuracy', accuracy_score(y_val, y_pred))\n",
        "display(pd.DataFrame(\n",
        "    confusion_matrix(y_val, y_pred), \n",
        "    columns=['Predicted Negative', 'Predicted Positive'], \n",
        "    index=['Actual Negative', 'Actual Positive']))\n",
        "\n",
        "\n",
        "# 5. Visualize decision regions\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_decision_regions(X_val, y_val, model, legend=0);"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96        96\n",
            "           1       0.36      1.00      0.53         4\n",
            "\n",
            "   micro avg       0.93      0.93      0.93       100\n",
            "   macro avg       0.68      0.96      0.75       100\n",
            "weighted avg       0.97      0.93      0.95       100\n",
            "\n",
            "accuracy 0.93\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>89</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative                  89                   7\n",
              "Actual Positive                   0                   4"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAFpCAYAAAC1Vt35AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zrllN3yECsEN"
      },
      "source": [
        "Try re-running the cell above with different values for these four parameters:\n",
        "- `n_samples`\n",
        "- `weights`\n",
        "- `class_sep`\n",
        "- `class_balance`\n",
        "\n",
        "For example, with a 50% / 50% class distribution:\n",
        "```\n",
        "n_samples = 1000\n",
        "weights = (0.50, 0.50)\n",
        "class_sep = 0.8\n",
        "class_balance = None\n",
        "```\n",
        "\n",
        "With a 95% / 5% class distribution:\n",
        "```\n",
        "n_samples = 1000\n",
        "weights = (0.95, 0.05)\n",
        "class_sep = 0.8\n",
        "class_balance = None\n",
        "```\n",
        "\n",
        "With the same 95% / 5% class distribution, but changing the Logistic Regression's `class_balance` parameter to `'balanced'` (instead of its default `None`)\n",
        "```\n",
        "n_samples = 1000\n",
        "weights = (0.95, 0.05)\n",
        "class_sep = 0.8\n",
        "class_balance = 'balanced'\n",
        "```\n",
        "\n",
        "With the same 95% / 5% class distribution, but with different values for `class_balance`:\n",
        "- `{0: 1, 1: 1}` _(equivalent to `None`)_\n",
        "- `{0: 1, 1: 2}`\n",
        "- `{0: 1, 1: 10}` _(roughly equivalent to `'balanced'` for this dataset)_\n",
        "- `{0: 1, 1: 100}`\n",
        "- `{0: 1, 1: 10000}`\n",
        "\n",
        "How do the evaluation metrics and decision region plots change?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5-3MS-jANssN"
      },
      "source": [
        "## What you can do about imbalanced classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2KwgStd-yUUr"
      },
      "source": [
        "[Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/) gives \"a rough outline of useful approaches\" : \n",
        "\n",
        "- Do nothing. Sometimes you get lucky and nothing needs to be done. You can train on the so-called natural (or stratified) distribution and sometimes it works without need for modification.\n",
        "- Balance the training set in some way:\n",
        "  - Oversample the minority class.\n",
        "  - Undersample the majority class.\n",
        "  - Synthesize new minority classes.\n",
        "- Throw away minority examples and switch to an anomaly detection framework.\n",
        "- At the algorithm level, or after it:\n",
        "  - Adjust the class weight (misclassification costs).\n",
        "  - Adjust the decision threshold.\n",
        "  - Modify an existing algorithm to be more sensitive to rare classes.\n",
        "- Construct an entirely new algorithm to perform well on imbalanced data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iO7kOZ2HN0EA"
      },
      "source": [
        "#### We demonstrated two of these options: \n",
        "\n",
        "- \"Adjust the class weight (misclassification costs)\" — many scikit-learn classifiers have a `class_balance` parameter\n",
        "- \"Adjust the decision threshold\" — you can lean more about this in a great blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415).\n",
        "\n",
        "#### Another option to be aware of:\n",
        "- The [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library can be used to \"oversample the minority class, undersample the majority class, or synthesize new minority classes.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P_XjBTW5SBwZ"
      },
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "#### Bank Marketing\n",
        "- Try the `class_weight` parameter.\n",
        "- Explore and visualize your data. \n",
        "- Wrangle [bad data](https://github.com/Quartz/bad-data-guide), outliers, and missing values.\n",
        "- Try engineering more features. You can transform, bin, and combine features. \n",
        "- Try selecting fewer features.\n",
        "\n",
        "\n",
        "#### Imbalanced Classes demo with synthetic data\n",
        "- Play around with the demo. Change parameter values.\n",
        "- Be able to calculate precision, recall, F1, and accuracy \"by hand\", given a confusion matrix and access to Wikipedia.\n",
        "\n",
        "# STRETCH\n",
        "- Read the blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415). You can replicate the code as-is,  [\"the hard way\"](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit). Or you can apply it to the Bank Marketing dataset.\n",
        "- Try the [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library.\n",
        "- Try other [scikit-learn classifiers](https://scikit-learn.org/stable/supervised_learning.html), beyond Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqXZbkZTJ6sE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "635f76f8-ef71-404d-c4e8-c52561926763"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.20.3)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.2.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9ijl0_yJ--N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "ba7de807-3acf-4dba-db04-b9813b7a2f99"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
        "!unzip bank-additional.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-08 21:25:31--  https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 444572 (434K) [application/x-httpd-php]\n",
            "Saving to: ‘bank-additional.zip.2’\n",
            "\n",
            "bank-additional.zip 100%[===================>] 434.15K  1.29MB/s    in 0.3s    \n",
            "\n",
            "2019-05-08 21:25:32 (1.29 MB/s) - ‘bank-additional.zip.2’ saved [444572/444572]\n",
            "\n",
            "Archive:  bank-additional.zip\n",
            "replace bank-additional/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/bank-additional/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/.Rhistory? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional-full.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional-names.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/._bank-additional? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw7NiexVCLB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code comes from our previous notebook\n",
        "\n",
        "# Imports\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "import category_encoders as ce\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "\n",
        "pd.set_option('display.max_columns',500)\n",
        "\n",
        "# Load data\n",
        "bank = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\n",
        "\n",
        "# Bin age by interval of 10\n",
        "# age_bins = [age for age in range(10, 110, 10)]\n",
        "# bank['age_bins'] = pd.cut(bank['age'], age_bins)\n",
        "\n",
        "#Encode categorical - 0:no, 1:yes\n",
        "#bank['housing'] = (bank['housing'] == 'yes').astype(int)\n",
        "\n",
        "# Assign to X, y\n",
        "X = bank.drop(columns='y')\n",
        "y = bank['y'] == 'yes'\n",
        "\n",
        "# Drop leaky feature\n",
        "X = X.drop(columns='duration')\n",
        "\n",
        "# Split Train, Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Make pipeline\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True), \n",
        "    StandardScaler(), \n",
        "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Fe0DztCoIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "db68da97-33a9-4dfa-a33f-38dd35f34c25"
      },
      "source": [
        "# Predict Probability of y\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_pred_proba = cross_val_predict(pipeline, X_train, y_train, cv=3, n_jobs=-1,\n",
        "                                method='predict_proba')[:,1]\n",
        "\n",
        "# Slice out probability of predicting wrong and returns predicted probabilty\n",
        "y_pred_proba"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04725944, 0.02539201, 0.60024588, ..., 0.04855253, 0.04414289,\n",
              "       0.06331942])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPVwT5R-MrQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "bb765752-6477-41c0-e3f2-674595e016b6"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "threshold = 0.5\n",
        "y_pred = y_pred_proba >= threshold\n",
        "\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "confusion_matrix(y_train,y_pred)\n",
        "\n",
        "pd.DataFrame(confusion_matrix(y_train, y_pred),\n",
        "            columns=['Predicted Neagtive', 'Predicted Positive'],\n",
        "            index=['Acutal Negative', 'Actual Positive'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.98      0.95     29238\n",
            "        True       0.66      0.23      0.34      3712\n",
            "\n",
            "   micro avg       0.90      0.90      0.90     32950\n",
            "   macro avg       0.78      0.61      0.64     32950\n",
            "weighted avg       0.88      0.90      0.88     32950\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Neagtive</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Acutal Negative</th>\n",
              "      <td>28786</td>\n",
              "      <td>452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>2852</td>\n",
              "      <td>860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Neagtive  Predicted Positive\n",
              "Acutal Negative               28786                 452\n",
              "Actual Positive                2852                 860"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLp7iyGzav8M",
        "colab_type": "text"
      },
      "source": [
        "#Graph it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsLhrnwXavIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "bank = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\n",
        "\n",
        "# Assign to X, y\n",
        "X = bank.drop(columns='y')\n",
        "y = bank['y'] == 'yes'\n",
        "\n",
        "# Drop leaky feature\n",
        "X = X.drop(columns='duration').select_dtypes(include='number')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfgA2bd3aI6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "eb41772b-155d-4c8a-d341-73d208188f00"
      },
      "source": [
        "# 2. Split data\n",
        "\n",
        "# Uses our custom train_validation_test_split function\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
        "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=1)\n",
        "\n",
        "# 3. Fit model\n",
        "\n",
        "# Try re-running the cell with different values for this parameter\n",
        "class_weight = 'None'\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs', class_weight=class_weight)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 4. Evaluate model\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "print('accuracy', accuracy_score(y_val, y_pred))\n",
        "display(pd.DataFrame(\n",
        "    confusion_matrix(y_val, y_pred), \n",
        "    columns=['Predicted Negative', 'Predicted Positive'], \n",
        "    index=['Actual Negative', 'Actual Positive']))\n",
        "\n",
        "y_pred_proba = model.predict_proba(X_val)[:,1]\n",
        "print('ROC AUC', roc_auc_score(y_val, y_pred_proba))\n",
        "\n",
        "# 5. Visualize decision regions\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plot_decision_regions(X_val['emp.var.rate'].values, y_val.values.astype(int), model, legend=0);"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.99      0.95      3694\n",
            "        True       0.67      0.18      0.28       425\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      4119\n",
            "   macro avg       0.79      0.58      0.62      4119\n",
            "weighted avg       0.89      0.91      0.88      4119\n",
            "\n",
            "accuracy 0.9060451565914057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>3656</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>349</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative                3656                  38\n",
              "Actual Positive                 349                  76"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ROC AUC 0.738540080894296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f03HXljTLlzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "240fc44e-bca5-4b80-9494-df4ad92118ab"
      },
      "source": [
        "bank.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>307</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age        job  marital    education  default housing loan    contact  \\\n",
              "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
              "1   57   services  married  high.school  unknown      no   no  telephone   \n",
              "2   37   services  married  high.school       no     yes   no  telephone   \n",
              "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
              "4   56   services  married  high.school       no      no  yes  telephone   \n",
              "\n",
              "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
              "0   may         mon       261         1    999         0  nonexistent   \n",
              "1   may         mon       149         1    999         0  nonexistent   \n",
              "2   may         mon       226         1    999         0  nonexistent   \n",
              "3   may         mon       151         1    999         0  nonexistent   \n",
              "4   may         mon       307         1    999         0  nonexistent   \n",
              "\n",
              "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
              "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
              "1           1.1          93.994          -36.4      4.857       5191.0  no  \n",
              "2           1.1          93.994          -36.4      4.857       5191.0  no  \n",
              "3           1.1          93.994          -36.4      4.857       5191.0  no  \n",
              "4           1.1          93.994          -36.4      4.857       5191.0  no  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opodfz_CDUes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "7a1ea84d-5314-4d3c-bbf8-12f8a21fc401"
      },
      "source": [
        "bank.nunique()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                 78\n",
              "job                 12\n",
              "marital              4\n",
              "education            8\n",
              "default              3\n",
              "housing              3\n",
              "loan                 3\n",
              "contact              2\n",
              "month               10\n",
              "day_of_week          5\n",
              "duration          1544\n",
              "campaign            42\n",
              "pdays               27\n",
              "previous             8\n",
              "poutcome             3\n",
              "emp.var.rate        10\n",
              "cons.price.idx      26\n",
              "cons.conf.idx       26\n",
              "euribor3m          316\n",
              "nr.employed         11\n",
              "y                    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjeaU3kXDxiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6f6f6dba-b041-4cec-e9e6-57e6c005df29"
      },
      "source": [
        "bank['education'].unique()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['basic.4y', 'high.school', 'basic.6y', 'basic.9y',\n",
              "       'professional.course', 'unknown', 'university.degree',\n",
              "       'illiterate'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq2j_Ptkj5E1",
        "colab_type": "text"
      },
      "source": [
        "#Redo Bank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPufHdPsEOFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "ed26dc65-ac82-4157-c9be-e001ba572802"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import category_encoders as ce #Encode strings only not panda objects\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "bank1 = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\n",
        "\n",
        "# Bin age by interval of 10\n",
        "age_bins = [age for age in range(10, 110, 10)]\n",
        "age_by_decade = [10,20,30,40,50,60,70,80,90]\n",
        "bank1['age_range'] = pd.cut(x=bank1['age'], bins=age_bins)\n",
        "\n",
        "\n",
        "#Round age to nearest 10\n",
        "bank1['age_round_10'] = bank1['age'].round(-1)\n",
        "#bank1['age_by_decade'] = pd.cut(x=bank1['age'],bins=len(age_by_decade), labels=age_by_decade)\n",
        "\n",
        "\n",
        "#Encode categorical - 0:no, 1:yes\n",
        "#bank1['housing'] = (bank1['housing'] == 'yes').astype(int)\n",
        "\n",
        "X = bank1.drop(columns=['age','duration','age_range'])\n",
        "y = bank1['y'] == 'yes'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.3, random_state=42, stratify=y)\n",
        "\n",
        "#pd.crosstab(index=bank1['age_bins'],columns=[bank1['marital'],bank1['education']])\n",
        "\n",
        "##Groupby with all columns except age and duration\n",
        "#bank1.groupby(['age_bins'])[bank1.select_dtypes(exclude='number').columns].counts()\n",
        "X.head()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "      <th>age_round_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         job  marital    education  default housing loan    contact month  \\\n",
              "0  housemaid  married     basic.4y       no      no   no  telephone   may   \n",
              "1   services  married  high.school  unknown      no   no  telephone   may   \n",
              "2   services  married  high.school       no     yes   no  telephone   may   \n",
              "3     admin.  married     basic.6y       no      no   no  telephone   may   \n",
              "4   services  married  high.school       no      no  yes  telephone   may   \n",
              "\n",
              "  day_of_week  campaign  pdays  previous     poutcome  emp.var.rate  \\\n",
              "0         mon         1    999         0  nonexistent           1.1   \n",
              "1         mon         1    999         0  nonexistent           1.1   \n",
              "2         mon         1    999         0  nonexistent           1.1   \n",
              "3         mon         1    999         0  nonexistent           1.1   \n",
              "4         mon         1    999         0  nonexistent           1.1   \n",
              "\n",
              "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  age_round_10  \n",
              "0          93.994          -36.4      4.857       5191.0  no            60  \n",
              "1          93.994          -36.4      4.857       5191.0  no            60  \n",
              "2          93.994          -36.4      4.857       5191.0  no            40  \n",
              "3          93.994          -36.4      4.857       5191.0  no            40  \n",
              "4          93.994          -36.4      4.857       5191.0  no            60  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgnJQB4QKJkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "805e6375-a6ea-47c6-e9c0-5483ae23e47d"
      },
      "source": [
        "#Make pipeline\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(solver='lbfgs',max_iter=1000)\n",
        ")\n",
        "\n",
        "#Fit Model and predict\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "#Check report and display confusion matrix\n",
        "print(classification_report(y_val, y_pred))\n",
        "print('accuracy', accuracy_score(y_val, y_pred))\n",
        "display(pd.DataFrame(\n",
        "    confusion_matrix(y_val, y_pred), \n",
        "    columns=['Predicted Negative', 'Predicted Positive'], \n",
        "    index=['Actual Negative', 'Actual Positive']))\n",
        "\n",
        "#ROC score\n",
        "y_pred_proba = pipeline.predict_proba(X_val)[:,1]\n",
        "print('ROC AUC', roc_auc_score(y_val, y_pred_proba))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00     10965\n",
            "        True       1.00      1.00      1.00      1392\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     12357\n",
            "   macro avg       1.00      1.00      1.00     12357\n",
            "weighted avg       1.00      1.00      1.00     12357\n",
            "\n",
            "accuracy 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>10965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>0</td>\n",
              "      <td>1392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative               10965                   0\n",
              "Actual Positive                   0                1392"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ROC AUC 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pFhdYa_lSgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1092
        },
        "outputId": "02b704ea-2c98-4540-b58e-399881f0ecb0"
      },
      "source": [
        "bank1['age'].round(-1)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        60\n",
              "1        60\n",
              "2        40\n",
              "3        40\n",
              "4        60\n",
              "5        40\n",
              "6        60\n",
              "7        40\n",
              "8        20\n",
              "9        20\n",
              "10       40\n",
              "11       20\n",
              "12       30\n",
              "13       60\n",
              "14       40\n",
              "15       50\n",
              "16       40\n",
              "17       50\n",
              "18       50\n",
              "19       40\n",
              "20       30\n",
              "21       60\n",
              "22       60\n",
              "23       40\n",
              "24       40\n",
              "25       40\n",
              "26       60\n",
              "27       40\n",
              "28       50\n",
              "29       60\n",
              "         ..\n",
              "41158    40\n",
              "41159    40\n",
              "41160    30\n",
              "41161    30\n",
              "41162    60\n",
              "41163    40\n",
              "41164    50\n",
              "41165    40\n",
              "41166    30\n",
              "41167    30\n",
              "41168    40\n",
              "41169    60\n",
              "41170    40\n",
              "41171    30\n",
              "41172    30\n",
              "41173    60\n",
              "41174    60\n",
              "41175    30\n",
              "41176    40\n",
              "41177    60\n",
              "41178    60\n",
              "41179    60\n",
              "41180    40\n",
              "41181    40\n",
              "41182    30\n",
              "41183    70\n",
              "41184    50\n",
              "41185    60\n",
              "41186    40\n",
              "41187    70\n",
              "Name: age, Length: 41188, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuwcWDpRPI7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loGUTpkRlxVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}