{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_242_Validate_classification_problems.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KMI2k-oBsS08"
      },
      "source": [
        "_Lambda School Data Science — Model Validation_ \n",
        "\n",
        "# Classification Metrics & Imbalanced Classes\n",
        "\n",
        "#### Objectives\n",
        "- Classification Metrics: Accuracy, Precision, Recall, F1, ROC AUC\n",
        "- Confusion Matrix\n",
        "- Imbalanced Classes\n",
        "\n",
        "#### Pre-reads\n",
        "- [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
        "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
        "- [ROC curves and Area Under the Curve explained](https://www.dataschool.io/roc-curves-and-auc-explained/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rU7RuVcjWdcp"
      },
      "source": [
        "## Preliminary setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WIqp4yzdUsf2"
      },
      "source": [
        "#### Install [category_encoders](https://github.com/scikit-learn-contrib/categorical-encoding)\n",
        "- Google Colab: `pip install category_encoders`\n",
        "- Local, Anaconda: `conda install -c conda-forge category_encoders`\n",
        "\n",
        "#### Install  [mlxtend](http://rasbt.github.io/mlxtend/) to plot decision regions\n",
        "- Google Colab: Already installed\n",
        "- Local, Anaconda: `conda install -c conda-forge mlxtend`\n",
        "\n",
        "#### Get the Bank Marketing dataset\n",
        "- Download from [UCI](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)\n",
        "- Or run this cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO3hTDiGMH06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "699974f0-9663-445d-c192-cd64cd16fa8c"
      },
      "source": [
        "pip install category_encoders"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.20.3)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.2.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ut7wm5_xUqvz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "83babe3b-6deb-46e4-de11-9b46d8b580c3"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
        "!unzip bank-additional.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-08 20:13:25--  https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 444572 (434K) [application/x-httpd-php]\n",
            "Saving to: ‘bank-additional.zip.1’\n",
            "\n",
            "\rbank-additional.zip   0%[                    ]       0  --.-KB/s               \rbank-additional.zip 100%[===================>] 434.15K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-08 20:13:25 (2.91 MB/s) - ‘bank-additional.zip.1’ saved [444572/444572]\n",
            "\n",
            "Archive:  bank-additional.zip\n",
            "replace bank-additional/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/bank-additional/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/.Rhistory? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional-full.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional-names.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace bank-additional/bank-additional.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/._bank-additional? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exZrRRC2WObS"
      },
      "source": [
        "# Classification Metrics & Confusion Matrix — with Bank Marketing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1FnLW0DjWKaW",
        "colab": {}
      },
      "source": [
        "# This code comes from our previous notebook\n",
        "\n",
        "# Imports\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "import category_encoders as ce\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "\n",
        "# Load data\n",
        "bank = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\n",
        "\n",
        "# Assign to X, y\n",
        "X = bank.drop(columns='y')\n",
        "y = bank['y'] == 'yes'\n",
        "\n",
        "# Drop leaky feature\n",
        "X = X.drop(columns='duration')\n",
        "\n",
        "# Split Train, Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Make pipeline\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True), \n",
        "    StandardScaler(), \n",
        "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ktgWzULWW2Z0"
      },
      "source": [
        "#### scikit-learn documentation\n",
        "- [sklearn.linear_model.LogisticRegression.predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba)\n",
        "- [sklearn.metrics.classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
        "- [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
        "- [sklearn.model_selection.cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bXN_sDXYWkj4",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_pred_proba = cross_val_predict(pipeline, X_train, y_train, cv=3, n_jobs=-1, \n",
        "                                 method='predict_proba')[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieSHwqpFKvd9",
        "colab_type": "text"
      },
      "source": [
        "#### Change the threshold and re-run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW8zTb8_Kvd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "a3c00831-6d1b-4f76-91bf-ad65e96efc01"
      },
      "source": [
        "threshold = 0.5\n",
        "y_pred = y_pred_proba >= threshold\n",
        "correct = y_pred == y_train\n",
        "\n",
        "labels = pd.DataFrame({'Ground Truth': y_train, \n",
        "                       'Predicted Probability': y_pred_proba, \n",
        "                       'Discrete Prediction': y_pred, \n",
        "                       'Correct Prediction?': correct})\n",
        "\n",
        "labels.head(20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ground Truth</th>\n",
              "      <th>Predicted Probability</th>\n",
              "      <th>Discrete Prediction</th>\n",
              "      <th>Correct Prediction?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25611</th>\n",
              "      <td>False</td>\n",
              "      <td>0.047259</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26010</th>\n",
              "      <td>False</td>\n",
              "      <td>0.025392</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40194</th>\n",
              "      <td>True</td>\n",
              "      <td>0.600246</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>False</td>\n",
              "      <td>0.031742</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36344</th>\n",
              "      <td>False</td>\n",
              "      <td>0.440106</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21806</th>\n",
              "      <td>False</td>\n",
              "      <td>0.065051</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37395</th>\n",
              "      <td>True</td>\n",
              "      <td>0.225595</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25863</th>\n",
              "      <td>False</td>\n",
              "      <td>0.065761</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7393</th>\n",
              "      <td>False</td>\n",
              "      <td>0.026482</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14697</th>\n",
              "      <td>False</td>\n",
              "      <td>0.069068</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17537</th>\n",
              "      <td>False</td>\n",
              "      <td>0.044403</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>False</td>\n",
              "      <td>0.035158</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13720</th>\n",
              "      <td>False</td>\n",
              "      <td>0.070268</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12258</th>\n",
              "      <td>False</td>\n",
              "      <td>0.043146</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32042</th>\n",
              "      <td>False</td>\n",
              "      <td>0.098642</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31118</th>\n",
              "      <td>True</td>\n",
              "      <td>0.105448</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20444</th>\n",
              "      <td>False</td>\n",
              "      <td>0.054744</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4216</th>\n",
              "      <td>False</td>\n",
              "      <td>0.026534</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6347</th>\n",
              "      <td>False</td>\n",
              "      <td>0.024661</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39226</th>\n",
              "      <td>True</td>\n",
              "      <td>0.864744</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Ground Truth  Predicted Probability  Discrete Prediction  \\\n",
              "25611         False               0.047259                False   \n",
              "26010         False               0.025392                False   \n",
              "40194          True               0.600246                 True   \n",
              "297           False               0.031742                False   \n",
              "36344         False               0.440106                False   \n",
              "21806         False               0.065051                False   \n",
              "37395          True               0.225595                False   \n",
              "25863         False               0.065761                False   \n",
              "7393          False               0.026482                False   \n",
              "14697         False               0.069068                False   \n",
              "17537         False               0.044403                False   \n",
              "1595          False               0.035158                False   \n",
              "13720         False               0.070268                False   \n",
              "12258         False               0.043146                False   \n",
              "32042         False               0.098642                False   \n",
              "31118          True               0.105448                False   \n",
              "20444         False               0.054744                False   \n",
              "4216          False               0.026534                False   \n",
              "6347          False               0.024661                False   \n",
              "39226          True               0.864744                 True   \n",
              "\n",
              "       Correct Prediction?  \n",
              "25611                 True  \n",
              "26010                 True  \n",
              "40194                 True  \n",
              "297                   True  \n",
              "36344                 True  \n",
              "21806                 True  \n",
              "37395                False  \n",
              "25863                 True  \n",
              "7393                  True  \n",
              "14697                 True  \n",
              "17537                 True  \n",
              "1595                  True  \n",
              "13720                 True  \n",
              "12258                 True  \n",
              "32042                 True  \n",
              "31118                False  \n",
              "20444                 True  \n",
              "4216                  True  \n",
              "6347                  True  \n",
              "39226                 True  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h01_ZZxcX0hf"
      },
      "source": [
        "#### Change the threshold and re-run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4xRbAMxmXrXw",
        "outputId": "78292522-4fc3-4754-9513-26834ba6d88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "threshold = 0.2\n",
        "y_pred = y_pred_proba >= threshold\n",
        "\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "pd.DataFrame(confusion_matrix(y_train, y_pred), \n",
        "             columns=['Predicted Negative', 'Predicted Positive'], \n",
        "             index=['Actual Negative', 'Actual Positive'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      0.91      0.92     29238\n",
            "        True       0.43      0.55      0.48      3712\n",
            "\n",
            "   micro avg       0.87      0.87      0.87     32950\n",
            "   macro avg       0.68      0.73      0.70     32950\n",
            "weighted avg       0.88      0.87      0.87     32950\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>26476</td>\n",
              "      <td>2762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>1664</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative               26476                2762\n",
              "Actual Positive                1664                2048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "InBb016HcSef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e5161d84-0abb-4b8b-a1b7-fe2e75b0da03"
      },
      "source": [
        "#TODO \n",
        "\n",
        "true_negative  = 23971\n",
        "false_positive = 5267\n",
        "false_negative = 1294\n",
        "true_positive  = 2418\n",
        "\n",
        "predicted_negative = true_negative + false_negative\n",
        "predicted_positive = true_positive + false_positive\n",
        "actual_negative = true_negative + false_positive\n",
        "actual_positive = false_negative + true_positive\n",
        "\n",
        "\n",
        "accuracy = (true_positive + true_negative) / (predicted_negative + predicted_positive)\n",
        "precision = true_positive / predicted_positive\n",
        "recall = true_positive / actual_positive\n",
        "f1 =  2 * precision * recall / (precision + recall)\n",
        "\n",
        "print('Accuracy:',accuracy,'\\nPrecision:',precision,'\\nRecall:',recall,'\\nF1:',f1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8008801213960546 \n",
            "Precision: 0.3146389069616135 \n",
            "Recall: 0.6514008620689655 \n",
            "F1: 0.42432219005001315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0adzKxSHKiJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0c2734d-814b-4af8-d8ae-36c97300dcd7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score as a_s\n",
        "a_s(y_train, y_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8008801213960546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWdNl1BhKveM",
        "colab_type": "text"
      },
      "source": [
        "#### F1 Score\n",
        "\"[The F1 score](https://en.wikipedia.org/wiki/F1_score) is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d50kghfPYk1D"
      },
      "source": [
        "### ROC AUC (Receiver Operating Characteristic, Area Under the Curve)\n",
        "\n",
        "#### Scikit-Learn docs\n",
        "- [User Guide: Receiver operating characteristic (ROC)](https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc)\n",
        "- [sklearn.metrics.roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
        "- [sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
        "\n",
        "#### More links\n",
        "- [ROC curves and Area Under the Curve explained](https://www.dataschool.io/roc-curves-and-auc-explained/)\n",
        "- [The philosophical argument for using ROC curves](https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/)\n",
        "\n",
        "[Wikipedia explains,](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) \"A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\"\n",
        "\n",
        "ROC AUC is the area under the ROC curve. [It can be interpreted](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it) as \"the expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\" \n",
        "\n",
        "ROC AUC measures how well a classifier ranks predicted probabilities. It ranges from 0 to 1. A naive majority class baseline will have an ROC AUC score of 0.5. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yx5WEweMYBYY",
        "outputId": "04b6fe51-1a2a-4394-a2af-55b0cd75840a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_train, y_pred_proba)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "print('Area under the Receiver Operating Characteristic curve:', \n",
        "      roc_auc_score(y_train, y_pred_proba))\n",
        "    \n",
        "# When threshold = 0.5\n",
        "false_positives = 452\n",
        "true_positives = 860\n",
        "false_positive_rate = false_positives/actual_negative\n",
        "true_positive_rate = true_positives/actual_positive\n",
        "plt.scatter(false_positive_rate, true_positive_rate)\n",
        "\n",
        "# When threshold = 0.1\n",
        "false_positives = 5267\n",
        "true_positives = 2418\n",
        "false_positive_rate = false_positives/actual_negative\n",
        "true_positive_rate = true_positives/actual_positive\n",
        "plt.scatter(false_positive_rate, true_positive_rate);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under the Receiver Operating Characteristic curve: 0.7885656855096462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DMiqiAB_WVPK"
      },
      "source": [
        "# Imbalanced Classes — with synthetic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OWLBlu5K5kJR"
      },
      "source": [
        "## Fun demo!\n",
        "\n",
        "The next code cell does five things:\n",
        "\n",
        "#### 1. Generate data\n",
        "\n",
        "We use scikit-learn's [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function to generate fake data for a binary classification problem, based on several parameters, including:\n",
        "- Number of samples\n",
        "- Weights, meaning \"the proportions of samples assigned to each class.\"\n",
        "- Class separation: \"Larger values spread out the clusters/classes and make the classification task easier.\"\n",
        "\n",
        "(We are generating fake data so it is easy to visualize.)\n",
        "\n",
        "#### 2. Split data\n",
        "\n",
        "We split the data three ways, into train, validation, and test sets. (For this toy example, it's not really necessary to do a three-way split. A two-way split, or even no split, would be ok. But I'm trying to demonstrate good habits, even in toy examples, to avoid confusion.)\n",
        "\n",
        "#### 3. Fit model\n",
        "\n",
        "We use scikit-learn to fit a [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the training data.\n",
        "\n",
        "We use this model parameter:\n",
        "\n",
        "> **class_weight : _dict or ‘balanced’, default: None_**\n",
        "\n",
        "> Weights associated with classes in the form `{class_label: weight}`. If not given, all classes are supposed to have weight one.\n",
        "\n",
        "> The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n_samples / (n_classes * np.bincount(y))`.\n",
        "\n",
        "\n",
        "#### 4. Evaluate model\n",
        "\n",
        "We use our Logistic Regression model, which was fit on the training data, to generate predictions for the validation data.\n",
        "\n",
        "Then we print [scikit-learn's Classification Report](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), with many metrics, and also the accuracy score. We are comparing the correct labels to the Logistic Regression's predicted labels, for the validation set. \n",
        "\n",
        "#### 5. Visualize decision function\n",
        "\n",
        "Based on these examples\n",
        "- https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/combine/plot_comparison_combine.html\n",
        "- http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/#example-1-decision-regions-in-2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PMTjC3vQ7ZNV",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_validation_test_split(\n",
        "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, \n",
        "    random_state=None, shuffle=True):\n",
        "        \n",
        "    assert train_size + val_size + test_size == 1\n",
        "    \n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, shuffle=shuffle)\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val, y_train_val, test_size=val_size/(train_size+val_size), \n",
        "        random_state=random_state, shuffle=shuffle)\n",
        "    \n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TcpoWCUq5xNV",
        "outputId": "c827e6dc-bacf-49e1-95ff-3b57460bfaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "#1. Generate data\n",
        "\n",
        "# Try re-running the cell with different values for these parameters\n",
        "n_samples = 1000\n",
        "weights = (0.95, 0.05)\n",
        "class_sep = 0.8\n",
        "\n",
        "X, y = make_classification(n_samples=n_samples, n_features=2, n_informative=2, \n",
        "                           n_redundant=0, n_repeated=0, n_classes=2, \n",
        "                           n_clusters_per_class=1, weights=weights, \n",
        "                           class_sep=class_sep, random_state=0)\n",
        "\n",
        "\n",
        "# 2. Split data\n",
        "\n",
        "# Uses our custom train_validation_test_split function\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
        "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=1)\n",
        "\n",
        "\n",
        "# 3. Fit model\n",
        "\n",
        "# Try re-running the cell with different values for this parameter\n",
        "class_weight = None\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs', class_weight=class_weight)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 4. Evaluate model\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "print('accuracy', accuracy_score(y_val, y_pred))\n",
        "display(pd.DataFrame(\n",
        "    confusion_matrix(y_val, y_pred), \n",
        "    columns=['Predicted Negative', 'Predicted Positive'], \n",
        "    index=['Actual Negative', 'Actual Positive']))\n",
        "\n",
        "\n",
        "# 5. Visualize decision regions\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_decision_regions(X_val, y_val, model, legend=0);"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        96\n",
            "           1       1.00      0.50      0.67         4\n",
            "\n",
            "   micro avg       0.98      0.98      0.98       100\n",
            "   macro avg       0.99      0.75      0.83       100\n",
            "weighted avg       0.98      0.98      0.98       100\n",
            "\n",
            "accuracy 0.98\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Negative</th>\n",
              "      <th>Predicted Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual Negative</th>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Positive</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Predicted Negative  Predicted Positive\n",
              "Actual Negative                  96                   0\n",
              "Actual Positive                   2                   2"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAFpCAYAAAC1Vt35AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zrllN3yECsEN"
      },
      "source": [
        "Try re-running the cell above with different values for these four parameters:\n",
        "- `n_samples`\n",
        "- `weights`\n",
        "- `class_sep`\n",
        "- `class_balance`\n",
        "\n",
        "For example, with a 50% / 50% class distribution:\n",
        "```\n",
        "n_samples = 1000\n",
        "weights = (0.50, 0.50)\n",
        "class_sep = 0.8\n",
        "class_balance = None\n",
        "```\n",
        "\n",
        "With a 95% / 5% class distribution:\n",
        "```\n",
        "n_samples = 1000\n",
        "weights = (0.95, 0.05)\n",
        "class_sep = 0.8\n",
        "class_balance = None\n",
        "```\n",
        "\n",
        "With the same 95% / 5% class distribution, but changing the Logistic Regression's `class_balance` parameter to `'balanced'` (instead of its default `None`)\n",
        "```\n",
        "n_samples = 1000\n",
        "weights = (0.95, 0.05)\n",
        "class_sep = 0.8\n",
        "class_balance = 'balanced'\n",
        "```\n",
        "\n",
        "With the same 95% / 5% class distribution, but with different values for `class_balance`:\n",
        "- `{0: 1, 1: 1}` _(equivalent to `None`)_\n",
        "- `{0: 1, 1: 2}`\n",
        "- `{0: 1, 1: 10}` _(roughly equivalent to `'balanced'` for this dataset)_\n",
        "- `{0: 1, 1: 100}`\n",
        "- `{0: 1, 1: 10000}`\n",
        "\n",
        "How do the evaluation metrics and decision region plots change?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5-3MS-jANssN"
      },
      "source": [
        "## What you can do about imbalanced classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2KwgStd-yUUr"
      },
      "source": [
        "[Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/) gives \"a rough outline of useful approaches\" : \n",
        "\n",
        "- Do nothing. Sometimes you get lucky and nothing needs to be done. You can train on the so-called natural (or stratified) distribution and sometimes it works without need for modification.\n",
        "- Balance the training set in some way:\n",
        "  - Oversample the minority class.\n",
        "  - Undersample the majority class.\n",
        "  - Synthesize new minority classes.\n",
        "- Throw away minority examples and switch to an anomaly detection framework.\n",
        "- At the algorithm level, or after it:\n",
        "  - Adjust the class weight (misclassification costs).\n",
        "  - Adjust the decision threshold.\n",
        "  - Modify an existing algorithm to be more sensitive to rare classes.\n",
        "- Construct an entirely new algorithm to perform well on imbalanced data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iO7kOZ2HN0EA"
      },
      "source": [
        "#### We demonstrated two of these options: \n",
        "\n",
        "- \"Adjust the class weight (misclassification costs)\" — many scikit-learn classifiers have a `class_balance` parameter\n",
        "- \"Adjust the decision threshold\" — you can lean more about this in a great blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415).\n",
        "\n",
        "#### Another option to be aware of:\n",
        "- The [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library can be used to \"oversample the minority class, undersample the majority class, or synthesize new minority classes.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P_XjBTW5SBwZ"
      },
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "#### Bank Marketing\n",
        "- Try the `class_weight` parameter.\n",
        "- Explore and visualize your data. \n",
        "- Wrangle [bad data](https://github.com/Quartz/bad-data-guide), outliers, and missing values.\n",
        "- Try engineering more features. You can transform, bin, and combine features. \n",
        "- Try selecting fewer features.\n",
        "\n",
        "\n",
        "#### Imbalanced Classes demo with synthetic data\n",
        "- Play around with the demo. Change parameter values.\n",
        "- Be able to calculate precision, recall, F1, and accuracy \"by hand\", given a confusion matrix and access to Wikipedia.\n",
        "\n",
        "# STRETCH\n",
        "- Read the blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415). You can replicate the code as-is,  [\"the hard way\"](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit). Or you can apply it to the Bank Marketing dataset.\n",
        "- Try the [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library.\n",
        "- Try other [scikit-learn classifiers](https://scikit-learn.org/stable/supervised_learning.html), beyond Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Y_jBq1TZWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "e66ab742-5c3b-44e0-b95e-1788e85f4f80"
      },
      "source": [
        "bank.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>...</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   age        job  marital    education  default housing loan    contact  \\\n",
              "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
              "1   57   services  married  high.school  unknown      no   no  telephone   \n",
              "2   37   services  married  high.school       no     yes   no  telephone   \n",
              "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
              "4   56   services  married  high.school       no      no  yes  telephone   \n",
              "\n",
              "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
              "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
              "\n",
              "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
              "0          93.994          -36.4      4.857       5191.0  no  \n",
              "1          93.994          -36.4      4.857       5191.0  no  \n",
              "2          93.994          -36.4      4.857       5191.0  no  \n",
              "3          93.994          -36.4      4.857       5191.0  no  \n",
              "4          93.994          -36.4      4.857       5191.0  no  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpGn5NzTTiRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = bank.drop(columns='y')\n",
        "y = bank['y'] == 'yes'\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
        "X, y, train_size=.8, val_size=.1, test_size=.1, random_state=99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h1zMFbbeGyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "8e5176d5-0049-4aa0-a7b1-d7e597652833"
      },
      "source": [
        "class_weight = None\n",
        "pipeline = make_pipeline(\n",
        "ce.OneHotEncoder(use_cat_names=True),\n",
        "StandardScaler(),\n",
        "LogisticRegression(solver = 'lbfgs', class_weight = class_weight, max_iter = 1000)\n",
        ")\n",
        "pipeline.fit(X_train,y_train)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('onehotencoder', OneHotEncoder(cols=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'],\n",
              "       drop_invariant=False, handle_missing='value',\n",
              "       handle_unknown='value', return_df=True, use_cat_names=True,\n",
              "       verbose=0)), ('stan...enalty='l2', random_state=None, solver='lbfgs',\n",
              "          tol=0.0001, verbose=0, warm_start=False))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iEmRM2wr8uE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4388b5e-c546-4e58-ebaa-9a2a61cd999f"
      },
      "source": [
        "y_pred = pipeline.predict(X_val)\n",
        "y_pred"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, ..., False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrW_BFAndfDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "4a93e5e0-0488-4b37-a189-942f148cc763"
      },
      "source": [
        "y_pred = pipeline.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "print('accuracy', accuracy_score(y_val, y_pred))\n",
        "display(pd.DataFrame(\n",
        "confusion_matrix(y_val,y_pred),\n",
        "columns=['predicted neg', 'predicted pos'],\n",
        "index=['actual neg', 'actual pos']))\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.97      0.95      3651\n",
            "        True       0.66      0.43      0.52       468\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      4119\n",
            "   macro avg       0.79      0.70      0.73      4119\n",
            "weighted avg       0.90      0.91      0.90      4119\n",
            "\n",
            "accuracy 0.909686817188638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted neg</th>\n",
              "      <th>predicted pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>actual neg</th>\n",
              "      <td>3546</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>actual pos</th>\n",
              "      <td>267</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            predicted neg  predicted pos\n",
              "actual neg           3546            105\n",
              "actual pos            267            201"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5f32BVUgInJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "781c8483-2f6e-41a9-accd-08e1061481c8"
      },
      "source": [
        "#plt.figure(figsize=(10,6))\n",
        "#plot_decision_regions(X_val.values, y_val.eq(True).mul(1).values, pipeline, legend=0)\n",
        "y_pred_proba = pipeline.predict_proba(X_val)[:,1]\n",
        "print('rocauc',roc_auc_score(y_val, y_pred_proba))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rocauc 0.9366055898512761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eF5YHfvjiNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9a5449f5-f3c2-43bc-8417-00d0053aadb5"
      },
      "source": [
        "from sklearn.linear_model import BayesianRidge \n",
        "pipeline2 = make_pipeline(\n",
        "ce.OneHotEncoder(use_cat_names=True),\n",
        "StandardScaler(),\n",
        "BayesianRidge()\n",
        ")\n",
        "pipeline2.fit(X_train,y_train)\n",
        "\n",
        "y_pred = pipeline2.predict(X_val)\n",
        "y_pred"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.07571519,  0.07541294, -0.01350961, ...,  0.04605524,\n",
              "        0.24345687, -0.06695524])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqtSuePlrXee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_val, y_pred))\n",
        "print('accuracy', accuracy_score(y_val, y_pred))\n",
        "display(pd.DataFrame(\n",
        "confusion_matrix(y_val,y_pred),\n",
        "columns=['predicted neg', 'predicted pos'],\n",
        "index=['actual neg', 'actual pos']))\n",
        "\n",
        "y_pred_proba = pipeline2.predict_proba(X_val)[:,1]\n",
        "print('rocauc',roc_auc_score(y_val, y_pred_proba))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}