{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Unit_2_Sprint_Challenge_3_Classification_Validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danhorsley/DS-Unit-2-Sprint-3-Classification-Validation/blob/master/DS_Unit_2_Sprint_Challenge_3_Classification_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByxMKGv2X-dh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "b77057c1-5929-4b13-c694-896758fbc40c"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.2.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.24.2)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.5.3)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PC9RfopIWrc9"
      },
      "source": [
        " _Lambda School Data Science Unit 2_\n",
        " \n",
        " # Classification & Validation Sprint Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UV7ArLFQN84W"
      },
      "source": [
        "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bAZcbTtiUlkI"
      },
      "source": [
        "#### For this Sprint Challenge, you'll predict whether a person's income exceeds $50k/yr, based on census data.\n",
        "\n",
        "You can read more about the Adult Census Income dataset at the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/adult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dERF_tHPRSpR",
        "colab_type": "text"
      },
      "source": [
        "#### Run this cell to load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gvV9VORbxyvu",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "columns = ['age', \n",
        "           'workclass', \n",
        "           'fnlwgt', \n",
        "           'education', \n",
        "           'education-num', \n",
        "           'marital-status', \n",
        "           'occupation', \n",
        "           'relationship', \n",
        "           'race', \n",
        "           'sex', \n",
        "           'capital-gain', \n",
        "           'capital-loss', \n",
        "           'hours-per-week', \n",
        "           'native-country', \n",
        "           'income']\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', \n",
        "                 header=None, names=columns)\n",
        "\n",
        "df['income'] = df['income'].str.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlYYuy1FRSpy",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 — Begin with baselines\n",
        "\n",
        "Split the data into an **X matrix** (all the features) and **y vector** (the target).\n",
        "\n",
        "(You _don't_ need to split the data into train and test sets here. You'll be asked to do that at the _end_ of Part 1.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1_17xUhRSp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "01a4806c-6231-41bf-8215-26e6149aa56e"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
              "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
              "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
              "       'income'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO8A9g7bRfY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features=['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
        "target='income'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IxKfgx4ycb3c"
      },
      "source": [
        "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
        " \n",
        "(You can answer this question either with a scikit-learn function or with a pandas function.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3oo31Remcq-x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "92fe59dc-c600-4169-c47a-9e7e914658a9"
      },
      "source": [
        "#it will either be the percentage of the majority class....\n",
        "from sklearn.metrics import accuracy_score\n",
        "df['income'].value_counts(normalize=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<=50K    0.75919\n",
              ">50K     0.24081\n",
              "Name: income, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC7m-d2hSuSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "df['income_binary']=np.where(df['income']=='<=50K',0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKho95KASJRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['majority_class_baseline']=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOO2BWsFSsML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c0d6bf62-d836-4343-8600-4cb5ba37212e"
      },
      "source": [
        "#or you use sklearn function to calculate same number\n",
        "accuracy_score(df['income_binary'],df['majority_class_baseline'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7591904425539756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_KdxE1TrcriI"
      },
      "source": [
        "What **ROC AUC score** would you get here with a **majority class baseline?**\n",
        "\n",
        "(You can answer this question either with a scikit-learn function or with no code, just your understanding of ROC AUC.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GOt32uDUQXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will be 0.5 as roc curve will be a straight line going from (0,0) to (1,1) so area under the curve is 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILS0fN0Cctyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a24673f5-a118-469a-b35c-e7bd3af471cb"
      },
      "source": [
        "#using sklearn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(df['income_binary'], df['majority_class_baseline'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QqYNDtwKYhji"
      },
      "source": [
        "In this Sprint Challenge, you will use **\"Cross-Validation with Independent Test Set\"** for your model validaton method.\n",
        "\n",
        "First, **split the data into `X_train, X_test, y_train, y_test`**. You can include 80% of the data in the train set, and hold out 20% for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mPKf86yDYf0t",
        "colab": {}
      },
      "source": [
        "target='income_binary'\n",
        "X=df[features].copy()\n",
        "y=df[target].copy()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw2GNZzvRSrW",
        "colab_type": "text"
      },
      "source": [
        "## Part 2 — Modeling with Logistic Regression!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E_ATNJdqTCuZ"
      },
      "source": [
        "- You may do exploratory data analysis and visualization, but it is not required.\n",
        "- You may **use all the features, or select any features** of your choice, as long as you select at least one numeric feature and one categorical feature.\n",
        "- **Scale your numeric features**, using any scikit-learn [Scaler](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) of your choice.\n",
        "- **Encode your categorical features**. You may use any encoding (One-Hot, Ordinal, etc) and any library (category_encoders, scikit-learn, pandas, etc) of your choice.\n",
        "- You may choose to use a pipeline, but it is not required.\n",
        "- Use a **Logistic Regression** model.\n",
        "- Use scikit-learn's [**cross_val_score**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function. For [scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules), use **accuracy**.\n",
        "- **Print your model's cross-validation accuracy score.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew_WQB7kVtvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "4b8608c4-448a-4cb7-a6d6-4baa318dcd30"
      },
      "source": [
        "#i've checked for missing data so no need to use imputer\n",
        "X_train.isna().sum()[:4]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age          0\n",
              "workclass    0\n",
              "fnlwgt       0\n",
              "education    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ipIBuiEV9NU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "e5be3f8d-2bf2-4ec8-a80d-669098263ec3"
      },
      "source": [
        "#there doesn't seem to be overly many categories in each categorical column so will just set them to categoricals\n",
        "#X_train['occupation'].value_counts()#X_train['marital-status'].value_counts()#X_train['education'].value_counts()#X_train['workclass'].value_counts()\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Prof-specialty       3312\n",
              " Craft-repair         3278\n",
              " Exec-managerial      3228\n",
              " Adm-clerical         3044\n",
              " Sales                2921\n",
              " Other-service        2628\n",
              " Machine-op-inspct    1624\n",
              " ?                    1454\n",
              " Transport-moving     1280\n",
              " Handlers-cleaners    1097\n",
              " Farming-fishing       801\n",
              " Tech-support          739\n",
              " Protective-serv       513\n",
              " Priv-house-serv       123\n",
              " Armed-Forces            6\n",
              "Name: occupation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW5XWQVLYnrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting rid of warnings\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgYzi1IfRSrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c50a8cc5-e41b-4bf0-c5ca-cd8829568e8e"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "preprocessor=make_pipeline(ce.OrdinalEncoder(),StandardScaler())\n",
        "\n",
        "processed_Xtrain= preprocessor.fit_transform(X_train)\n",
        "#just checking it was looking ok!  pd.DataFrame(processed_Xtrain).head()\n",
        "LogReg=LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "LogReg.fit(processed_Xtrain,y_train)\n",
        "scores_array=cross_val_score(LogReg, processed_Xtrain, y_train, scoring='accuracy', cv=5)\n",
        "scores_array"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.82207294, 0.82975048, 0.82015355, 0.8187752 , 0.83086965])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CA2JshBY9BP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0c216614-50af-4582-aa4d-1ee7294806a0"
      },
      "source": [
        "#printing mean score for final cv score\n",
        "scores_array.mean()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8243243625660446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av65DbF6RSr0",
        "colab_type": "text"
      },
      "source": [
        "## Part 3 — Modeling with Tree Ensembles!\n",
        "\n",
        "Part 3 is the same as Part 2, except this time, use a **Random Forest** or **Gradient Boosting** classifier. You may use scikit-learn, xgboost, or any other library. Then, print your model's cross-validation accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qAxxkjG7gACP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a8aec45d-3569-4ac3-9610-65c6865257cc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rand_for=RandomForestClassifier(max_depth=3, n_estimators=100,n_jobs=-1, random_state=42)\n",
        "\n",
        "RF_scores = cross_val_score(rand_for, processed_Xtrain, y_train, scoring='accuracy', cv=5)\n",
        "RF_scores"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.82341651, 0.82975048, 0.82495202, 0.82472644, 0.83163755])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj4S-yGZZmRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cb49144e-8045-4834-9683-599e7a6f99f1"
      },
      "source": [
        "#final accuracy score for random forest is slightly higher\n",
        "RF_scores.mean()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8268965974658506"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiV30F_Kda-A",
        "colab_type": "text"
      },
      "source": [
        "#Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH1sPR76cjP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e5fd36d9-4dcc-483d-b878-53466ffb970e"
      },
      "source": [
        "\n",
        "#now let's look at feature importance when we used teh random forest classifier\n",
        "import matplotlib.pyplot as plt\n",
        "rand_for.fit(processed_Xtrain,y_train)\n",
        "importances = pd.Series(rand_for.feature_importances_, X_train.columns)\n",
        "title='random forest clf feature importances'\n",
        "importances.sort_values().plot.barh(color='#FF6347', title=title)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAEICAYAAADY/mp2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI98b-m_eSAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we can see capital gain is by far teh most important followed by marital status\n",
        "#native country, fnlwgt, race and worlclass have 0 or almost 0 importance so we can eliminate those"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQjlYdXfcWvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first of all columns education and education-num are one and the same - \n",
        "#jsut a number code for each entry so we can eliminate 'education column'\n",
        "new_features=['age', 'workclass', 'education-num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "target='income_binary'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmz984dro3rV",
        "colab_type": "text"
      },
      "source": [
        "#model selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSNZqvpmggDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LxR3dCvedna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1756
        },
        "outputId": "fbcd39b1-5b7f-4378-e5a6-30a61f4ee1cc"
      },
      "source": [
        "models = [LogisticRegression(solver='lbfgs', max_iter=1000), \n",
        "          DecisionTreeClassifier(max_depth=3),  \n",
        "          RandomForestClassifier(max_depth=3, n_estimators=100, n_jobs=-1, random_state=42), \n",
        "          XGBClassifier(max_depth=3, n_estimators=100, n_jobs=-1, random_state=42)]\n",
        "\n",
        "X_cut=X.copy()[new_features]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cut, y, test_size=0.2, random_state=42)\n",
        "processors=[make_pipeline(ce.OrdinalEncoder(),StandardScaler()),make_pipeline(ce.OrdinalEncoder(),MinMaxScaler())]\n",
        "\n",
        "for model in models:\n",
        "  for processor in processors:\n",
        "            processed_Xtrain= processor.fit_transform(X_train)\n",
        "            print('{} '.format(model)[:15],' and ',processor, '\\n')\n",
        "            threshold = 0.5\n",
        "            score = cross_val_score(model, processed_Xtrain, y_train, scoring='accuracy', cv=5).mean()\n",
        "            print('Cross-Validation Accuracy:', score, '\\n', '\\n')\n",
        "            y_pred_proba=cross_val_predict(model, processed_Xtrain, y_train, cv=5, n_jobs=-1, \n",
        "                                 method='predict_proba')[:,1]\n",
        "            y_pred=y_pred_proba>threshold\n",
        "            cm=pd.DataFrame(confusion_matrix(y_train, y_pred), \n",
        "            columns=['Predicted Negative', 'Predicted Positive'], \n",
        "            index=['Actual Negative', 'Actual Positive'])\n",
        "            print(cm)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegress  and  Pipeline(memory=None,\n",
            "     steps=[('ordinalencoder', OrdinalEncoder(cols=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex'],\n",
            "        drop_invariant=False, handle_missing='value',\n",
            "        handle_unknown='value',\n",
            "        mapping=[{'col': 'workclass', 'mapping':  Local-gov           1\n",
            " Private          ..._df=True, verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]) \n",
            "\n",
            "Cross-Validation Accuracy: 0.8244011379979064 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               18675                1103\n",
            "Actual Positive                3471                2799\n",
            "LogisticRegress  and  Pipeline(memory=None,\n",
            "     steps=[('ordinalencoder', OrdinalEncoder(cols=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex'],\n",
            "        drop_invariant=False, handle_missing='value',\n",
            "        handle_unknown='value',\n",
            "        mapping=[{'col': 'workclass', 'mapping':  Local-gov           1\n",
            " Private          ...       return_df=True, verbose=0)), ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1)))]) \n",
            "\n",
            "Cross-Validation Accuracy: 0.8206388470567514 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               18690                1088\n",
            "Actual Positive                3584                2686\n",
            "DecisionTreeCla  and  Pipeline(memory=None,\n",
            "     steps=[('ordinalencoder', OrdinalEncoder(cols=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex'],\n",
            "        drop_invariant=False, handle_missing='value',\n",
            "        handle_unknown='value',\n",
            "        mapping=[{'col': 'workclass', 'mapping':  Local-gov           1\n",
            " Private          ..._df=True, verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]) \n",
            "\n",
            "Cross-Validation Accuracy: 0.8063957442622008 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               19416                 362\n",
            "Actual Positive                4681                1589\n",
            "DecisionTreeCla  and  Pipeline(memory=None,\n",
            "     steps=[('ordinalencoder', OrdinalEncoder(cols=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex'],\n",
            "        drop_invariant=False, handle_missing='value',\n",
            "        handle_unknown='value',\n",
            "        mapping=[{'col': 'workclass', 'mapping':  Local-gov           1\n",
            " Private          ...       return_df=True, verbose=0)), ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1)))]) \n",
            "\n",
            "Cross-Validation Accuracy: 0.8063957442622008 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               19416                 362\n",
            "Actual Positive                4681                1589\n",
            "RandomForestCla  and  Pipeline(memory=None,\n",
            "     steps=[('ordinalencoder', OrdinalEncoder(cols=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex'],\n",
            "        drop_invariant=False, handle_missing='value',\n",
            "        handle_unknown='value',\n",
            "        mapping=[{'col': 'workclass', 'mapping':  Local-gov           1\n",
            " Private          ..._df=True, verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]) \n",
            "\n",
            "Cross-Validation Accuracy: 0.8341908972695642 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               19456                 322\n",
            "Actual Positive                3997                2273\n",
            "RandomForestCla  and  Pipeline(memory=None,\n",
            "     steps=[('ordinalencoder', OrdinalEncoder(cols=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex'],\n",
            "        drop_invariant=False, handle_missing='value',\n",
            "        handle_unknown='value',\n",
            "        mapping=[{'col': 'workclass', 'mapping':  Local-gov           1\n",
            " Private          ...       return_df=True, verbose=0)), ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1)))]) \n",
            "\n",
            "Cross-Validation Accuracy: 0.8341908972695642 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               19456                 322\n",
            "Actual Positive                3997                2273\n",
            "XGBClassifier(b  and  Pipeline(memory=None,\n",
            "     steps=[('ordinalencoder', OrdinalEncoder(cols=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex'],\n",
            "        drop_invariant=False, handle_missing='value',\n",
            "        handle_unknown='value',\n",
            "        mapping=[{'col': 'workclass', 'mapping':  Local-gov           1\n",
            " Private          ..._df=True, verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]) \n",
            "\n",
            "Cross-Validation Accuracy: 0.8627536572055821 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               18814                 964\n",
            "Actual Positive                2611                3659\n",
            "XGBClassifier(b  and  Pipeline(memory=None,\n",
            "     steps=[('ordinalencoder', OrdinalEncoder(cols=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex'],\n",
            "        drop_invariant=False, handle_missing='value',\n",
            "        handle_unknown='value',\n",
            "        mapping=[{'col': 'workclass', 'mapping':  Local-gov           1\n",
            " Private          ...       return_df=True, verbose=0)), ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1)))]) \n",
            "\n",
            "Cross-Validation Accuracy: 0.8627536572055821 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               18814                 964\n",
            "Actual Positive                2611                3659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoACoj0rgy5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "77ab1ed3-601d-4213-920c-7ce91da85bec"
      },
      "source": [
        "#so it looks like XGB classifier was way out in front on >86% accuracy and minmax/standard made no difference\n",
        "#let's use grid search to determine the best parameters\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "process=make_pipeline(ce.OrdinalEncoder(),StandardScaler())\n",
        "processed_Xtrain= process.fit_transform(X_train)\n",
        "\n",
        "depths=[2,3] \n",
        "n_estimator=[75,100,150]\n",
        "booster=['gbtree', 'gblinear', 'dart']\n",
        "#thresholds=[0.5,0.6,0.7]\n",
        "param_grid = [{'max_depth': [2,3] , 'n_estimators': [75,100,150],'booster': ['gbtree', 'gblinear', 'dart']}]\n",
        "scores = ['accuracy']\n",
        " \n",
        "for score in scores:\n",
        "  xgb=GridSearchCV(XGBClassifier(n_jobs=-1,random_state=42),param_grid,scoring=score)\n",
        "  xgb.fit(processed_Xtrain,y_train)\n",
        "  print(\"Best parameters set found on grid:\")\n",
        "  print()\n",
        "  print(xgb.best_params_)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters set found on grid:\n",
            "\n",
            "{'booster': 'gbtree', 'max_depth': 3, 'n_estimators': 150}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdpFXs1zg1CK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "0a5f9637-c624-4b37-9314-7ce4ce712b08"
      },
      "source": [
        "final_model=XGBClassifier(max_depth=3,booster='gbtree',n_estimators=150,n_jobs=-1,random_state=42)\n",
        "#so best params were gbtree, 150 estimators and max_depth 3\n",
        "#let's run that for a confusion matrix\n",
        "threshold = 0.5\n",
        "score = cross_val_score(final_model, processed_Xtrain, y_train, scoring='accuracy', cv=5).mean()\n",
        "print('Cross-Validation Accuracy:', score, '\\n', '\\n')\n",
        "y_pred_proba=cross_val_predict(model, processed_Xtrain, y_train, cv=5, n_jobs=-1, \n",
        "                                 method='predict_proba')[:,1]\n",
        "y_pred=y_pred_proba>threshold\n",
        "cm=pd.DataFrame(confusion_matrix(y_train, y_pred), \n",
        "columns=['Predicted Negative', 'Predicted Positive'], \n",
        "            index=['Actual Negative', 'Actual Positive'])\n",
        "print(cm)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation Accuracy: 0.8664007186734608 \n",
            " \n",
            "\n",
            "                 Predicted Negative  Predicted Positive\n",
            "Actual Negative               18814                 964\n",
            "Actual Positive                2611                3659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXOBOWYTphFu",
        "colab_type": "text"
      },
      "source": [
        "final score was slightly above after fine tuning parameters\n",
        "Cross-Validation Accuracy: 0.8664007186734608 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jkyHoRIbEgRR"
      },
      "source": [
        "# Part 4 — Calculate classification metrics from a confusion matrix\n",
        "\n",
        "Suppose this is the confusion matrix for your binary classification model:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td colspan=\"2\" rowspan=\"2\"></td>\n",
        "    <td colspan=\"2\">Predicted</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Negative</td>\n",
        "    <td>Positive</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"2\">Actual</td>\n",
        "    <td>Negative</td>\n",
        "    <td style=\"border: solid\">85</td>\n",
        "    <td style=\"border: solid\">58</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Positive</td>\n",
        "    <td style=\"border: solid\">8</td>\n",
        "    <td style=\"border: solid\"> 36</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LhyMM5H-JpVB"
      },
      "source": [
        "Calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFcIEmjLZvhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first i split the numbers into tru/false positives/negatives\n",
        "true_positives=36  #predicted positive and WAS positive\n",
        "true_negatives=85  #predicted negative and WAS negative\n",
        "false_positives=58 #predicted positive BUT was negative\n",
        "false_negatives=8 #predicted negative BUT was positive\n",
        "\n",
        "total=36+85+58+8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TZPwqdh2KUcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c6b6c435-a1aa-472d-c83c-c71e87635612"
      },
      "source": [
        "accuracy=(true_positives+true_negatives)/total\n",
        "accuracy"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6470588235294118"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BRWLfGcGKeQw"
      },
      "source": [
        "Calculate precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A-FEZ4i_Kf_n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2a345026-668f-45d8-9053-2d743231f837"
      },
      "source": [
        "precision=true_positives/(true_positives+false_positives)\n",
        "precision"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3829787234042553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h_mH2NYDKi2C"
      },
      "source": [
        "Calculate recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U4_wJGyjKkXJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "657ddeb3-707b-4e1e-8606-17cea0328ecb"
      },
      "source": [
        "recall=true_positives/(true_positives+false_negatives)\n",
        "recall"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8181818181818182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5am1gLcnnyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1497fbbe-2994-4268-d976-5920ddf5d06d"
      },
      "source": [
        "#F1 = 2 * (precision * recall) / (precision + recall)\n",
        "2*(precision*recall)/(precision+recall)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5217391304347826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D36eh0qOnyX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c64b0bdc-6c80-4743-d937-6c6df6f8ed62"
      },
      "source": [
        "#falsepositives rate is false positives/total number of negatives\n",
        "58/(85+58)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40559440559440557"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9KEaWsk5Kk9W"
      },
      "source": [
        "# BONUS — How you can earn a score of 3\n",
        "\n",
        "### Part 1\n",
        "Do feature engineering, to try improving your cross-validation score.\n",
        "\n",
        "### Part 2\n",
        "Experiment with feature selection, preprocessing, categorical encoding, and hyperparameter optimization, to try improving your cross-validation score.\n",
        "\n",
        "### Part 3\n",
        "Which model had the best cross-validation score? Refit this model on the train set and do a final evaluation on the held out test set — what is the test score? \n",
        "\n",
        "### Part 4\n",
        "Calculate F1 score and False Positive Rate. "
      ]
    }
  ]
}