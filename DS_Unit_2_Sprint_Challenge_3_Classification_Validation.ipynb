{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PC9RfopIWrc9"
   },
   "source": [
    " _Lambda School Data Science Unit 2_\n",
    " \n",
    " # Classification & Validation Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UV7ArLFQN84W"
   },
   "source": [
    "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAZcbTtiUlkI"
   },
   "source": [
    "#### For this Sprint Challenge, you'll predict whether a person's income exceeds $50k/yr, based on census data.\n",
    "\n",
    "You can read more about the Adult Census Income dataset at the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvV9VORbxyvu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['age', \n",
    "           'workclass', \n",
    "           'fnlwgt', \n",
    "           'education', \n",
    "           'education-num', \n",
    "           'marital-status', \n",
    "           'occupation', \n",
    "           'relationship', \n",
    "           'race', \n",
    "           'sex', \n",
    "           'capital-gain', \n",
    "           'capital-loss', \n",
    "           'hours-per-week', \n",
    "           'native-country', \n",
    "           'income']\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', \n",
    "                 header=None, names=columns)\n",
    "\n",
    "df['income'] = df['income'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 — Begin with baselines\n",
    "\n",
    "Split the data into an **X matrix** (all the features) and **y vector** (the target).\n",
    "\n",
    "(You _don't_ need to split the data into train and test sets here. You'll be asked to do that at the _end_ of Part 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 14), (32561,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns='income', axis=1)\n",
    "y = df['income']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxKfgx4ycb3c"
   },
   "source": [
    "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
    " \n",
    "(You can answer this question either with a scikit-learn function or with a pandas function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oo31Remcq-x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    0.75919\n",
       ">50K     0.24081\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A majority class baseline would have a 75.9% accuracy rate by always guessing that a person's income was less than $50K. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KdxE1TrcriI"
   },
   "source": [
    "What **ROC AUC score** would you get here with a **majority class baseline?**\n",
    "\n",
    "(You can answer this question either with a scikit-learn function or with no code, just your understanding of ROC AUC.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILS0fN0Cctyc"
   },
   "source": [
    "You would get a ROC AUC score of 0.5 given a majority class baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqYNDtwKYhji"
   },
   "source": [
    "In this Sprint Challenge, you will use **\"Cross-Validation with Independent Test Set\"** for your model validaton method.\n",
    "\n",
    "First, **split the data into `X_train, X_test, y_train, y_test`**. You can include 80% of the data in the train set, and hold out 20% for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPKf86yDYf0t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 14), (6513, 14), (26048,), (6513,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 — Modeling with Logistic Regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_ATNJdqTCuZ"
   },
   "source": [
    "- You may do exploratory data analysis and visualization, but it is not required.\n",
    "- You may **use all the features, or select any features** of your choice, as long as you select at least one numeric feature and one categorical feature.\n",
    "- **Scale your numeric features**, using any scikit-learn [Scaler](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) of your choice.\n",
    "- **Encode your categorical features**. You may use any encoding (One-Hot, Ordinal, etc) and any library (category_encoders, scikit-learn, pandas, etc) of your choice.\n",
    "- You may choose to use a pipeline, but it is not required.\n",
    "- Use a **Logistic Regression** model.\n",
    "- Use scikit-learn's [**cross_val_score**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function. For [scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules), use **accuracy**.\n",
    "- **Print your model's cross-validation accuracy score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "- Built data dictionary to prepare for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Processing (Regression)</th>\n",
       "      <th>Processing (Trees)</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>int</td>\n",
       "      <td>73</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workclass</td>\n",
       "      <td>object</td>\n",
       "      <td>9</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>Ordinal</td>\n",
       "      <td>? Represents unkown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fnlwgt</td>\n",
       "      <td>int</td>\n",
       "      <td>18440</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>object</td>\n",
       "      <td>16</td>\n",
       "      <td>Hash</td>\n",
       "      <td>Hash</td>\n",
       "      <td>Consider creating new feature with reduced cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>education-num</td>\n",
       "      <td>int</td>\n",
       "      <td>16</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>None</td>\n",
       "      <td>Implied ordering is warranted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>marital-status</td>\n",
       "      <td>object</td>\n",
       "      <td>7</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>Ordinal</td>\n",
       "      <td>Ordering is meaningless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>occupation</td>\n",
       "      <td>object</td>\n",
       "      <td>15</td>\n",
       "      <td>Hash</td>\n",
       "      <td>Ordinal</td>\n",
       "      <td>Consider creating new features with reduced ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relationship</td>\n",
       "      <td>object</td>\n",
       "      <td>6</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>Ordinal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>race</td>\n",
       "      <td>object</td>\n",
       "      <td>5</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>Ordinal</td>\n",
       "      <td>Consider grouping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sex</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>Switch to binary int</td>\n",
       "      <td>Switch to binary int</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>capital-gain</td>\n",
       "      <td>int</td>\n",
       "      <td>115</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>capital-loss</td>\n",
       "      <td>int</td>\n",
       "      <td>87</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hours-per-week</td>\n",
       "      <td>int</td>\n",
       "      <td>93</td>\n",
       "      <td>Standardization</td>\n",
       "      <td>None</td>\n",
       "      <td>Ordering has meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>native-country</td>\n",
       "      <td>object</td>\n",
       "      <td>42</td>\n",
       "      <td>Hash</td>\n",
       "      <td>Ordinal</td>\n",
       "      <td>Consider Grouping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[target] income</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>Switch to binary int</td>\n",
       "      <td>Switch to binary int</td>\n",
       "      <td>Split is approximately 3/4 no, 1/4 yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Attribute   Dtype  Unique Values Processing (Regression)  \\\n",
       "0               age     int             73         Standardization   \n",
       "1         workclass  object              9                  OneHot   \n",
       "2            fnlwgt     int          18440         Standardization   \n",
       "3         education  object             16                    Hash   \n",
       "4     education-num     int             16         Standardization   \n",
       "5    marital-status  object              7                  OneHot   \n",
       "6        occupation  object             15                    Hash   \n",
       "7      relationship  object              6                  OneHot   \n",
       "8              race  object              5                  OneHot   \n",
       "9               sex  object              2    Switch to binary int   \n",
       "10     capital-gain     int            115         Standardization   \n",
       "11     capital-loss     int             87         Standardization   \n",
       "12   hours-per-week     int             93         Standardization   \n",
       "13   native-country  object             42                    Hash   \n",
       "14  [target] income  object              2    Switch to binary int   \n",
       "\n",
       "      Processing (Trees)                                              Notes  \n",
       "0                   None                                                NaN  \n",
       "1                Ordinal                                ? Represents unkown  \n",
       "2                   None                                                NaN  \n",
       "3                   Hash  Consider creating new feature with reduced cat...  \n",
       "4                   None                      Implied ordering is warranted  \n",
       "5                Ordinal                            Ordering is meaningless  \n",
       "6                Ordinal  Consider creating new features with reduced ca...  \n",
       "7                Ordinal                                                NaN  \n",
       "8                Ordinal                                  Consider grouping  \n",
       "9   Switch to binary int                                                NaN  \n",
       "10                  None                                                NaN  \n",
       "11                  None                                                NaN  \n",
       "12                  None                               Ordering has meaning  \n",
       "13               Ordinal                                  Consider Grouping  \n",
       "14  Switch to binary int             Split is approximately 3/4 no, 1/4 yes  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pd.read_excel('Sprint_Data_Dict.xlsx')\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Make Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(X):\n",
    "    X = X.copy()\n",
    "    X['sex'] = X['sex'].replace({'Female':0,'Male':1})\n",
    "    X['Age*Education'] = X['age'] * X['education-num']\n",
    "    X['White_American'] = np.where( (X['race'].str.strip() == 'White') & (X['native-country'].str.strip() == 'United-States'), 1, 0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = make_features(X_train)\n",
    "X_test = make_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_target(y):\n",
    "    y = y.replace({'<=50K':0,'>50K':1})\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = prepare_target(y_train)\n",
    "y_test = prepare_target(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = []\n",
    "one_hot_features = ['workclass','marital-status','relationship','race']\n",
    "hash_features = ['education','native-country']\n",
    "num_features = ['age','fnlwgt','education-num','Age*Education','capital-gain','capital-loss','hours-per-week']\n",
    "\n",
    "ordinal_proccessor = make_pipeline(\n",
    "    ce.OrdinalEncoder()\n",
    ")\n",
    "\n",
    "one_hot_processor = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True)\n",
    ")\n",
    "\n",
    "hash_processor = make_pipeline(\n",
    "    ce.HashingEncoder(n_components=8)\n",
    ")\n",
    "\n",
    "num_processor = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "#   (ordinal_proccesor, ordinal_features), Not used\n",
    "    (one_hot_processor, one_hot_features),\n",
    "    (hash_processor, hash_features),\n",
    "    (num_processor, num_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = make_pipeline(\n",
    "    preprocess,\n",
    "    LogisticRegression(solver='lbfgs', class_weight=None, max_iter=1000)\n",
    ")\n",
    "\n",
    "scoring = ['accuracy', 'f1','roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# Note switch to cross_validate to access multiple score types\n",
    "# scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=3)\n",
    "\n",
    "scores = cross_validate(model, X_train, y_train, return_train_score=True, scoring=scoring, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Cross-Validation Mean Accuracy Score:', scores['test_accuracy'].mean())\n",
    "print('Train Cross-Validation Mean F1 Score:', scores['test_f1'].mean())\n",
    "print('Train Cross-Validation Mean ROC AUC Score:', scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 — Modeling with Tree Ensembles!\n",
    "\n",
    "Part 3 is the same as Part 2, except this time, use a **Random Forest** or **Gradient Boosting** classifier. You may use scikit-learn, xgboost, or any other library. Then, print your model's cross-validation accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAxxkjG7gACP"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grow_forest = make_pipeline(\n",
    "    preprocess,\n",
    "    RandomForestClassifier(max_depth=8, n_estimators=100)\n",
    ")\n",
    "\n",
    "scores = cross_validate(grow_forest, X_train, y_train, return_train_score=True, scoring=scoring, cv=3)\n",
    "\n",
    "print('Train Cross-Validation Mean Accuracy Score:', scores['test_accuracy'].mean())\n",
    "print('Train Cross-Validation Mean F1 Score:', scores['test_f1'].mean())\n",
    "print('Train Cross-Validation Mean ROC AUC Score:', scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_booster = make_pipeline(\n",
    "    preprocess,\n",
    "    XGBClassifier(n_estimators=100)\n",
    ")\n",
    "\n",
    "scores = cross_validate(grad_booster, X_train, y_train, return_train_score=True, scoring=scoring, cv=5)\n",
    "\n",
    "print('Train Cross-Validation Mean Accuracy Score:', scores['test_accuracy'].mean())\n",
    "print('Train Cross-Validation Mean F1 Score:', scores['test_f1'].mean())\n",
    "print('Train Cross-Validation Mean ROC AUC Score:', scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "X_train = preprocess.fit_transform(X_train, y_train)\n",
    "X_test = preprocess.transform(X_test)\n",
    "\n",
    "booster = XGBClassifier(n_estimators=100)\n",
    "booster.fit(X_train, y_train)\n",
    "\n",
    "y_pred = booster.predict(X_test)\n",
    "y_pred_proba = booster.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Test Accuracy Score:', accuracy_score(y_test, y_pred) )\n",
    "print('Test F1 Score:', f1_score(y_test, y_pred))\n",
    "print('Test ROC AUC Score:', roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "conf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "             columns=['Predicted Negative', 'Predicted Positive'], \n",
    "             index=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "fpr = conf_mat.iat[0,1] / (conf_mat.iat[0,1] + conf_mat.iat[0,0])\n",
    "\n",
    "print('False Positive Rate:', fpr)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkyHoRIbEgRR"
   },
   "source": [
    "## Part 4 — Calculate classification metrics from a confusion matrix\n",
    "\n",
    "Suppose this is the confusion matrix for your binary classification model:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "    <td colspan=\"2\">Predicted</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Negative</td>\n",
    "    <td>Positive</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">Actual</td>\n",
    "    <td>Negative</td>\n",
    "    <td style=\"border: solid\">85</td>\n",
    "    <td style=\"border: solid\">58</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Positive</td>\n",
    "    <td style=\"border: solid\">8</td>\n",
    "    <td style=\"border: solid\"> 36</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhyMM5H-JpVB"
   },
   "source": [
    "Calculate accuracy\n",
    "\n",
    "Total Correct Predictions / Total Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZPwqdh2KUcB"
   },
   "outputs": [],
   "source": [
    "(36 + 85) / (85+58+8+36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWLfGcGKeQw"
   },
   "source": [
    "Calculate precision\n",
    "\n",
    "Accuracy = Predicted Positive Correct / Total Positive Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-FEZ4i_Kf_n"
   },
   "outputs": [],
   "source": [
    "36 / ( 36+ 58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_mH2NYDKi2C"
   },
   "source": [
    "Calculate recall\n",
    "\n",
    "Recall = Predicted Positive Correctly / Total Positives in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4_wJGyjKkXJ"
   },
   "outputs": [],
   "source": [
    "36 / (8 + 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KEaWsk5Kk9W"
   },
   "source": [
    "## BONUS — How you can earn a score of 3\n",
    "\n",
    "### Part 1\n",
    "Do feature engineering, to try improving your cross-validation score.\n",
    "\n",
    "### Part 2\n",
    "Experiment with feature selection, preprocessing, categorical encoding, and hyperparameter optimization, to try improving your cross-validation score.\n",
    "\n",
    "### Part 3\n",
    "Which model had the best cross-validation score? Refit this model on the train set and do a final evaluation on the held out test set — what is the test score? \n",
    "\n",
    "### Part 4\n",
    "Calculate F1 score and False Positive Rate. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
