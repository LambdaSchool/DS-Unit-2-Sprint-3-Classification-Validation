{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_231_Logistic_Regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Granero0011/DS-Unit-2-Sprint-3-Classification-Validation/blob/master/LS_DS_231_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N7SXF6jEBd5_"
      },
      "source": [
        "# Lambda School Data Science - Logistic Regression\n",
        "\n",
        "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E7-AOngjadRN"
      },
      "source": [
        "## Lecture - Where Linear goes Wrong\n",
        "### Return of the Titanic 🚢\n",
        "\n",
        "You've likely already explored the rich dataset that is the Titanic - let's use regression and try to predict survival with it. The data is [available from Kaggle](https://www.kaggle.com/c/titanic/data), so we'll also play a bit with [the Kaggle API](https://github.com/Kaggle/kaggle-api)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k7neGtFk2Z9",
        "colab_type": "text"
      },
      "source": [
        "### Get data, option 1: Kaggle API\n",
        "\n",
        "#### Sign up for Kaggle and get an API token\n",
        "1. [Sign up for a Kaggle account](https://www.kaggle.com/), if you don’t already have one. \n",
        "2. [Follow these instructions](https://github.com/Kaggle/kaggle-api#api-credentials) to create a Kaggle “API Token” and download your `kaggle.json` file. If you are using Anaconda, put the file in the directory specified in the instructions.\n",
        "\n",
        "_This will enable you to download data directly from Kaggle. If you run into problems, don’t worry — I’ll give you an easy alternative way to download today’s data, so you can still follow along with the lecture hands-on. And then we’ll help you through the Kaggle process after the lecture._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbZJsu34k2Z_",
        "colab_type": "text"
      },
      "source": [
        "#### Put `kaggle.json` in the correct location\n",
        "\n",
        "- ***If you're using Anaconda,*** put the file in the directory specified in the [instructions](https://github.com/Kaggle/kaggle-api#api-credentials).\n",
        "\n",
        "- ***If you're using Google Colab,*** upload the file to your Google Drive, and run this cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHu44npCk2aA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "94e05323-24af-4808-c1ad-825dc2510873"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%env KAGGLE_CONFIG_DIR=/content/drive/My Drive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "env: KAGGLE_CONFIG_DIR=/content/drive/My Drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60DzDPQZk2aE",
        "colab_type": "text"
      },
      "source": [
        "#### Install the Kaggle API package and use it to get the data\n",
        "\n",
        "You also have to join the Titanic competition to have access to the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MnHLWPYDcyIe",
        "outputId": "8f30436a-75a0-4432-a4c5-313353cd3624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9PT3E31k2aJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81844995-e06d-4ea7-a150-4a84e4092cf8"
      },
      "source": [
        "!kaggle competitions download -c titanic"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "403 - Forbidden\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWjxZ584k2aN",
        "colab_type": "text"
      },
      "source": [
        "### Get data, option 2: Download from the competition page\n",
        "1. [Sign up for a Kaggle account](https://www.kaggle.com/), if you don’t already have one. \n",
        "2. [Go to the Titanic competition page](https://www.kaggle.com/c/titanic) to download the [data](https://www.kaggle.com/c/titanic/data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqs2qsH9k2aO",
        "colab_type": "text"
      },
      "source": [
        "### Get data, option 3: Use Seaborn\n",
        "\n",
        "```\n",
        "import seaborn as sns\n",
        "train = sns.load_dataset('titanic')\n",
        "```\n",
        "\n",
        "But Seaborn's version of the Titanic dataset is not identical to Kaggle's version, as we'll see during this lesson!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnBBiaBnk2aP",
        "colab_type": "text"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dh3P0C4k2aQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "57463229-9d02-4ecf-f83f-ed2109f5a36d"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('train.csv')\n",
        "test  = pd.read_csv('test.csv')\n",
        "train.shape, test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1135afb733eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'train.csv' does not exist: b'train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF_6L0p0k2aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.sample(n=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w91VK7eXk2ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.sample(n=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QulkIz-Ak2ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'Survived'\n",
        "train[target].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXL1DLZnk2al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.describe(include='number')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEa5okBLk2av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.describe(exclude='number')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJyBQD3Lk2a2",
        "colab_type": "text"
      },
      "source": [
        "### How would we try to do this with linear regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGYOv2ZPk2a5",
        "colab_type": "text"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/impute.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fcxfpsjdFJwM",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "features = ['Pclass', 'Age', 'Fare']\n",
        "target  = 'Survived'\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_test  = test[features]\n",
        "\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed  = imputer.transform(X_test)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_imputed, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7bmHFPik2bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape, X_train_imputed.shape, X_test.shape, X_test_imputed.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLGcLZESk2bF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.head(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p26zWIQZk2bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_imputed[:6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtnv8kC0k2bO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train['Age'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c9W7idwk2bR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5we9XBuMk2bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_imputed[-5:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXL3Jhxvk2bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test['Age'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9P7eSBEk2ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([X_train, X_test])['Age'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN7KcGGSk2bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "test_case = np.array([[1, 5, 500]]) # Rich 5-year old in first class\n",
        "lin_reg.predict(test_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtP-19Zvk2bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = lin_reg.predict(X_test_imputed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoDyMIfBk2bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series(y_pred).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA3etDcnk2bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series(lin_reg.coef_, X_train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcUZ3WI-k2bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_reg.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-0UlTvFk2bx",
        "colab_type": "text"
      },
      "source": [
        "### How would we do this with Logistic Regression?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dpUm8Dl-u2aB",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Linear Regression\n",
        "# lin_reg = LinearRegression()\n",
        "# lin_reg.fit(X_train_imputed, y_train)\n",
        "# lin_reg.predict(test_case)\n",
        "\n",
        "log_reg = LogisticRegression(solver='lbfgs')\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Prediction for rich 5 year old:', log_reg.predict(test_case))\n",
        "print('Predicted probabilities for rich 5 year old:', log_reg.predict_proba(test_case))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk35cpNUk2b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 0.5\n",
        "(log_reg.predict_proba(X_test_imputed)[:, 1] > threshold).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPvvUFc2k2b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manual_predictions = (log_reg.predict_proba(X_test_imputed)[:,1] > threshold).astype(int)\n",
        "direct_predictions = log_reg.predict(X_test_imputed)\n",
        "\n",
        "all(manual_predictions == direct_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKkTvVeLk2b8",
        "colab_type": "text"
      },
      "source": [
        "### How accurate is the Logistic Regression?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_sEyxsLk2b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = log_reg.score(X_train_imputed, y_train)\n",
        "print('Train Accuracy Score', score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBN2B8R6k2cB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = log_reg.score(X_test_imputed, y_test)\n",
        "print('Test Accuracy Score', score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t_fIlGnk2cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(log_reg, X_train_imputed, y_train, cv=10)\n",
        "print('Cross-Validation Accuracy Scores', scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SByjKT1Yk2cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = pd.Series(scores)\n",
        "scores.min(), scores.mean(), scores.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2jjXn4Lk2cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_imputed.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8NrkB4rk2cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = log_reg.predict(X_train_imputed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzIhV_qkk2cR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwnXHPLMk2cU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxtw2x96k2cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XFA1EF7k2cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:5].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d2tiJM6k2ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_predictions = 4\n",
        "total_predictions = 5\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XdsYY31k2cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train[:5], y_pred[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orc9Sv07k2cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jT9GZaRk2cu",
        "colab_type": "text"
      },
      "source": [
        "### What's the math for the Logistic Regression?\n",
        "\n",
        "https://en.wikipedia.org/wiki/Logistic_function\n",
        "\n",
        "https://en.wikipedia.org/wiki/Logistic_regression#Probability_of_passing_an_exam_versus_hours_of_study"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Bq-54noR1uE",
        "colab": {}
      },
      "source": [
        "log_reg.coef_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "732SB9f9k2c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_reg.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q54lGVwok2c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The logistic sigmoid \"squishing\" function, \n",
        "# implemented to work with numpy arrays\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.e**(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMja_O8Vk2c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sigmoid(np.dot(log_reg.coef_, test_case.T) + log_reg.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6UWWLjGk2dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sigmoid(log_reg.coef_ @ test_case.T + log_reg.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lndgGr_ck2dI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_reg.predict_proba(test_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlckJftuk2dO",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Get the [Category Encoder](http://contrib.scikit-learn.org/categorical-encoding/) library\n",
        "\n",
        "If you're running on Google Colab:\n",
        "\n",
        "```\n",
        "!pip install category_encoders\n",
        "```\n",
        "\n",
        "If you're running locally with Anaconda:\n",
        "\n",
        "```\n",
        "!conda install -c conda-forge category_encoders\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZzJj75fk2dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "sns_titanic = sns.load_dataset('titanic')\n",
        "print(sns_titanic.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_lKjsRvk2dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2eZX2Udk2dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns_titanic.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh3dR77hk2dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Titanic\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqql5XD_k2dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_features(X):\n",
        "    X = X.copy()\n",
        "    X['adult_male'] = (X['Sex'] == 'male') & (X['Age'] >= 16)\n",
        "    X['alone'] = (X['SibSp'] == 0) & (X['Parch'] == 0)\n",
        "    X['last_name'] = X['Name'].str.split(',').str[0]\n",
        "    X['title'] = X['Name'].str.split(',').str[1].str.split('.').str[0]\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh0H56dPk2dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = make_features(train)\n",
        "test  = make_features(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq1ZOUgVk2di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['adult_male'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76hLPDuBk2do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['alone'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw32U9BDk2dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['title'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T9kqUHxk2dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns_titanic.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iblW74C8afuR"
      },
      "source": [
        "## Assignment: real-world classification\n",
        "\n",
        "We're going to check out a larger dataset - the [FMA Free Music Archive data](https://github.com/mdeff/fma). It has a selection of CSVs with metadata and calculated audio features that you can load and try to use to classify genre of tracks. To get you started:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8-ywn3wk2dw",
        "colab_type": "text"
      },
      "source": [
        "### Get and unzip the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52hVXuCJk2dw",
        "colab_type": "text"
      },
      "source": [
        "#### Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsySnuKaKtQf",
        "outputId": "b9d58f6f-c202-4f9d-e16c-a519bb96b8fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
        "!unzip fma_metadata.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-06 21:32:40--  https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
            "Resolving os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)... 86.119.28.13, 2001:620:5ca1:2ff::ce53\n",
            "Connecting to os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)|86.119.28.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358412441 (342M) [application/zip]\n",
            "Saving to: ‘fma_metadata.zip.3’\n",
            "\n",
            "fma_metadata.zip.3  100%[===================>] 341.81M  26.0MB/s    in 14s     \n",
            "\n",
            "2019-05-06 21:32:54 (24.1 MB/s) - ‘fma_metadata.zip.3’ saved [358412441/358412441]\n",
            "\n",
            "Archive:  fma_metadata.zip\n",
            "replace fma_metadata/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " bunzipping: fma_metadata/README.txt  \n",
            "replace fma_metadata/checksums? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " bunzipping: fma_metadata/checksums  \n",
            "replace fma_metadata/not_found.pickle? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " bunzipping: fma_metadata/not_found.pickle  \n",
            "replace fma_metadata/raw_genres.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " bunzipping: fma_metadata/raw_genres.csv  \n",
            "replace fma_metadata/raw_albums.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " bunzipping: fma_metadata/raw_albums.csv  \n",
            "replace fma_metadata/raw_artists.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " bunzipping: fma_metadata/raw_artists.csv  \n",
            "replace fma_metadata/raw_tracks.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " bunzipping: fma_metadata/raw_tracks.csv  y\n",
            "\n",
            "replace fma_metadata/tracks.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  bunzipping: fma_metadata/tracks.csv  y\n",
            "y\n",
            "\n",
            "replace fma_metadata/genres.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  bunzipping: fma_metadata/genres.csv  \n",
            "replace fma_metadata/raw_echonest.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  bunzipping: fma_metadata/raw_echonest.csv  y\n",
            "\n",
            "replace fma_metadata/echonest.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  bunzipping: fma_metadata/echonest.csv  y\n",
            "y\n",
            "\n",
            "replace fma_metadata/features.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  bunzipping: fma_metadata/features.csv  y\n",
            "y\n",
            "y\n",
            "y\n",
            "y\n",
            "n\n",
            "N\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ove4DhjHk2dy",
        "colab_type": "text"
      },
      "source": [
        "#### Windows\n",
        "- Download the [zip file](https://os.unil.cloud.switch.ch/fma/fma_metadata.zip)\n",
        "- You may need to use [7zip](https://www.7-zip.org/download.html) to unzip it\n",
        "\n",
        "\n",
        "#### Mac\n",
        "- Download the [zip file](https://os.unil.cloud.switch.ch/fma/fma_metadata.zip)\n",
        "- You may need to use [p7zip](https://superuser.com/a/626731) to unzip it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bv_J80ck2dz",
        "colab_type": "text"
      },
      "source": [
        "### Look at first 3 lines of raw file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqwimlpwk2dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a1c203c7-3572-4b9f-eb96-be65c08a1d60"
      },
      "source": [
        "!head -n 4 fma_metadata/tracks.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",album,album,album,album,album,album,album,album,album,album,album,album,album,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,artist,set,set,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track,track\n",
            ",comments,date_created,date_released,engineer,favorites,id,information,listens,producer,tags,title,tracks,type,active_year_begin,active_year_end,associated_labels,bio,comments,date_created,favorites,id,latitude,location,longitude,members,name,related_projects,tags,website,wikipedia_page,split,subset,bit_rate,comments,composer,date_created,date_recorded,duration,favorites,genre_top,genres,genres_all,information,interest,language_code,license,listens,lyricist,number,publisher,tags,title\n",
            "track_id,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "2,0,2008-11-26 01:44:45,2009-01-05 00:00:00,,4,1,<p></p>,6073,,[],AWOL - A Way Of Life,7,Album,2006-01-01 00:00:00,,,\"<p>A Way Of Life, A Collective of Hip-Hop from NJ...................</p>\",0,2008-11-26 01:42:32,9,1,40.0583238,New Jersey,-74.4056612,\"Sajje Morocco,Brownbum,ZawidaGod,Custodian of Records,Zooberelli the Don,F.A.H,MadSicka,Damien Omenicci..and a van load more...\",AWOL,The list of past projects is 2 long but every1 and every style from Tabby Bonet 2 M.O.P..Azillion Records Flagship trackmaster DJ BrownBum is a beat Wizard.....A-2-Z..illion....(right now working with JerseyBlock Ent),['awol'],http://www.AzillionRecords.blogspot.com,,training,small,256000,0,,2008-11-26 01:48:12,2008-11-26 00:00:00,168,2,Hip-Hop,[21],[21],,4656,en,Attribution-NonCommercial-ShareAlike 3.0 International,1293,,3,,[],Food\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-stokUWk2d1",
        "colab_type": "text"
      },
      "source": [
        "### Read with pandas\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG9z3voGk2d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "tracks = pd.read_csv('fma_metadata/tracks.csv', header=[0,1], index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s36RmPqk2d3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "0e9aca95-bd7f-4599-eb4b-4a94d32d5420"
      },
      "source": [
        "tracks.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"10\" halign=\"left\">album</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"10\" halign=\"left\">track</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>date_created</th>\n",
              "      <th>date_released</th>\n",
              "      <th>engineer</th>\n",
              "      <th>favorites</th>\n",
              "      <th>id</th>\n",
              "      <th>information</th>\n",
              "      <th>listens</th>\n",
              "      <th>producer</th>\n",
              "      <th>tags</th>\n",
              "      <th>...</th>\n",
              "      <th>information</th>\n",
              "      <th>interest</th>\n",
              "      <th>language_code</th>\n",
              "      <th>license</th>\n",
              "      <th>listens</th>\n",
              "      <th>lyricist</th>\n",
              "      <th>number</th>\n",
              "      <th>publisher</th>\n",
              "      <th>tags</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>track_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:44:45</td>\n",
              "      <td>2009-01-05 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
              "      <td>6073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4656</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
              "      <td>1293</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:44:45</td>\n",
              "      <td>2009-01-05 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
              "      <td>6073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1470</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
              "      <td>514</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Electric Ave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:44:45</td>\n",
              "      <td>2009-01-05 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
              "      <td>6073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1933</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
              "      <td>1151</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>This World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:45:08</td>\n",
              "      <td>2008-02-06 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47632</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54881</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
              "      <td>50135</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Freeway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:45:05</td>\n",
              "      <td>2009-01-06 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;p&gt; \"spiritual songs\" from Nicky Cook&lt;/p&gt;</td>\n",
              "      <td>2710</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>978</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
              "      <td>361</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Spiritual Level</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            album                                                     \\\n",
              "         comments         date_created        date_released engineer   \n",
              "track_id                                                               \n",
              "2               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
              "3               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
              "5               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
              "10              0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
              "20              0  2008-11-26 01:45:05  2009-01-06 00:00:00      NaN   \n",
              "\n",
              "                                                                          \\\n",
              "         favorites id                                information listens   \n",
              "track_id                                                                   \n",
              "2                4  1                                    <p></p>    6073   \n",
              "3                4  1                                    <p></p>    6073   \n",
              "5                4  1                                    <p></p>    6073   \n",
              "10               4  6                                        NaN   47632   \n",
              "20               2  4  <p> \"spiritual songs\" from Nicky Cook</p>    2710   \n",
              "\n",
              "                        ...       track                         \\\n",
              "         producer tags  ... information interest language_code   \n",
              "track_id                ...                                      \n",
              "2             NaN   []  ...         NaN     4656            en   \n",
              "3             NaN   []  ...         NaN     1470            en   \n",
              "5             NaN   []  ...         NaN     1933            en   \n",
              "10            NaN   []  ...         NaN    54881            en   \n",
              "20            NaN   []  ...         NaN      978            en   \n",
              "\n",
              "                                                                              \\\n",
              "                                                    license listens lyricist   \n",
              "track_id                                                                       \n",
              "2         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1293      NaN   \n",
              "3         Attribution-NonCommercial-ShareAlike 3.0 Inter...     514      NaN   \n",
              "5         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1151      NaN   \n",
              "10        Attribution-NonCommercial-NoDerivatives (aka M...   50135      NaN   \n",
              "20        Attribution-NonCommercial-NoDerivatives (aka M...     361      NaN   \n",
              "\n",
              "                                                 \n",
              "         number publisher tags            title  \n",
              "track_id                                         \n",
              "2             3       NaN   []             Food  \n",
              "3             4       NaN   []     Electric Ave  \n",
              "5             6       NaN   []       This World  \n",
              "10            1       NaN   []          Freeway  \n",
              "20            3       NaN   []  Spiritual Level  \n",
              "\n",
              "[5 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFQ4hK5Vk2d7",
        "colab_type": "text"
      },
      "source": [
        "### Fit Logistic Regression!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cnuxb4uk2d8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "476388de-bf26-4acf-c959-5ffbc98d518a"
      },
      "source": [
        "tracks.columns.tolist()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('album', 'comments'),\n",
              " ('album', 'date_created'),\n",
              " ('album', 'date_released'),\n",
              " ('album', 'engineer'),\n",
              " ('album', 'favorites'),\n",
              " ('album', 'id'),\n",
              " ('album', 'information'),\n",
              " ('album', 'listens'),\n",
              " ('album', 'producer'),\n",
              " ('album', 'tags'),\n",
              " ('album', 'title'),\n",
              " ('album', 'tracks'),\n",
              " ('album', 'type'),\n",
              " ('artist', 'active_year_begin'),\n",
              " ('artist', 'active_year_end'),\n",
              " ('artist', 'associated_labels'),\n",
              " ('artist', 'bio'),\n",
              " ('artist', 'comments'),\n",
              " ('artist', 'date_created'),\n",
              " ('artist', 'favorites'),\n",
              " ('artist', 'id'),\n",
              " ('artist', 'latitude'),\n",
              " ('artist', 'location'),\n",
              " ('artist', 'longitude'),\n",
              " ('artist', 'members'),\n",
              " ('artist', 'name'),\n",
              " ('artist', 'related_projects'),\n",
              " ('artist', 'tags'),\n",
              " ('artist', 'website'),\n",
              " ('artist', 'wikipedia_page'),\n",
              " ('set', 'split'),\n",
              " ('set', 'subset'),\n",
              " ('track', 'bit_rate'),\n",
              " ('track', 'comments'),\n",
              " ('track', 'composer'),\n",
              " ('track', 'date_created'),\n",
              " ('track', 'date_recorded'),\n",
              " ('track', 'duration'),\n",
              " ('track', 'favorites'),\n",
              " ('track', 'genre_top'),\n",
              " ('track', 'genres'),\n",
              " ('track', 'genres_all'),\n",
              " ('track', 'information'),\n",
              " ('track', 'interest'),\n",
              " ('track', 'language_code'),\n",
              " ('track', 'license'),\n",
              " ('track', 'listens'),\n",
              " ('track', 'lyricist'),\n",
              " ('track', 'number'),\n",
              " ('track', 'publisher'),\n",
              " ('track', 'tags'),\n",
              " ('track', 'title')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hybSS9myeHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "6f61a6c8-cb9e-4632-be28-4db8b2f6997e"
      },
      "source": [
        "tracks.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "album   comments                  0\n",
              "        date_created           3529\n",
              "        date_released         36280\n",
              "        engineer              91279\n",
              "        favorites                 0\n",
              "        id                        0\n",
              "        information           23425\n",
              "        listens                   0\n",
              "        producer              88514\n",
              "        tags                      0\n",
              "        title                  1025\n",
              "        tracks                    0\n",
              "        type                   6508\n",
              "artist  active_year_begin     83863\n",
              "        active_year_end      101199\n",
              "        associated_labels     92303\n",
              "        bio                   35418\n",
              "        comments                  0\n",
              "        date_created            856\n",
              "        favorites                 0\n",
              "        id                        0\n",
              "        latitude              62030\n",
              "        location              36364\n",
              "        longitude             62030\n",
              "        members               59725\n",
              "        name                      0\n",
              "        related_projects      93422\n",
              "        tags                      0\n",
              "        website               27318\n",
              "        wikipedia_page       100993\n",
              "set     split                     0\n",
              "        subset                    0\n",
              "track   bit_rate                  0\n",
              "        comments                  0\n",
              "        composer             102904\n",
              "        date_created              0\n",
              "        date_recorded        100415\n",
              "        duration                  0\n",
              "        favorites                 0\n",
              "        genre_top             56976\n",
              "        genres                    0\n",
              "        genres_all                0\n",
              "        information          104225\n",
              "        interest                  0\n",
              "        language_code         91550\n",
              "        license                  87\n",
              "        listens                   0\n",
              "        lyricist             106263\n",
              "        number                    0\n",
              "        publisher            105311\n",
              "        tags                      0\n",
              "        title                     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3FW6H6V4z3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trackstrack= tracks.track"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAPLHFHf44BU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b76dd724-351c-4e6f-e0ca-e2e422ad0193"
      },
      "source": [
        "trackstrack.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bit_rate              0\n",
              "comments              0\n",
              "composer         102904\n",
              "date_created          0\n",
              "date_recorded    100415\n",
              "duration              0\n",
              "favorites             0\n",
              "genre_top         56976\n",
              "genres                0\n",
              "genres_all            0\n",
              "information      104225\n",
              "interest              0\n",
              "language_code     91550\n",
              "license              87\n",
              "listens               0\n",
              "lyricist         106263\n",
              "number                0\n",
              "publisher        105311\n",
              "tags                  0\n",
              "title                 1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78I1hbKS5dAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "features = ['duration', 'bit_rate']\n",
        "target  = 'genres'\n",
        "\n",
        "X = trackstrack[features]\n",
        "y= trackstrack[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeD4CgVi70Ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed  = imputer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivp5p4Ml8YnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "6e406101-9f90-4a46-ae41-f88637b5180a"
      },
      "source": [
        "log_reg = LogisticRegression(solver= 'lbfgs', multi_class='auto')\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Prediction :', log_reg.predict(X_test))\n",
        "print('Predicted probabilities', log_reg.predict_proba(X_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Prediction : ['[21]' '[21]' '[21]' ... '[21]' '[21]' '[21]']\n",
            "Predicted probabilities [[9.03814013e-04 1.22792768e-04 2.58403128e-04 ... 6.69225885e-04\n",
            "  4.74501329e-04 3.84596514e-03]\n",
            " [1.34036307e-03 2.47375556e-05 1.09550039e-04 ... 7.34754909e-04\n",
            "  3.69406053e-04 2.41641010e-02]\n",
            " [1.29528523e-03 4.62257414e-05 1.60102450e-04 ... 7.84173957e-04\n",
            "  4.41669514e-04 1.44878368e-02]\n",
            " ...\n",
            " [1.34035670e-03 2.47375008e-05 1.09549766e-04 ... 7.34753779e-04\n",
            "  3.69404918e-04 2.41661845e-02]\n",
            " [1.34011062e-03 2.47353815e-05 1.09539209e-04 ... 7.34710026e-04\n",
            "  3.69361053e-04 2.42467431e-02]\n",
            " [9.03873851e-04 1.22793763e-04 2.58406862e-04 ... 6.69220935e-04\n",
            "  4.74514485e-04 3.83821527e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hzNi1__Iqsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        },
        "outputId": "7c00bea1-451e-4540-b46f-6be80e91d775"
      },
      "source": [
        "trackstrack.genres"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "track_id\n",
              "2                    [21]\n",
              "3                    [21]\n",
              "5                    [21]\n",
              "10                   [10]\n",
              "20              [76, 103]\n",
              "26              [76, 103]\n",
              "30              [76, 103]\n",
              "46              [76, 103]\n",
              "48              [76, 103]\n",
              "134                  [21]\n",
              "135              [45, 58]\n",
              "136              [45, 58]\n",
              "137               [1, 32]\n",
              "138               [1, 32]\n",
              "139                  [17]\n",
              "140                  [17]\n",
              "141                  [17]\n",
              "142                  [17]\n",
              "144                   [4]\n",
              "145                   [4]\n",
              "146                   [4]\n",
              "147                   [4]\n",
              "148                   [1]\n",
              "149                   [1]\n",
              "150                   [1]\n",
              "151                  [25]\n",
              "152                  [25]\n",
              "153                  [26]\n",
              "154                  [26]\n",
              "155                  [26]\n",
              "               ...       \n",
              "155290    [18, 107, 1235]\n",
              "155291    [18, 107, 1235]\n",
              "155292    [18, 107, 1235]\n",
              "155293    [18, 107, 1235]\n",
              "155294    [18, 107, 1235]\n",
              "155295    [18, 107, 1235]\n",
              "155296    [18, 107, 1235]\n",
              "155297    [18, 107, 1235]\n",
              "155298          [17, 103]\n",
              "155299          [17, 103]\n",
              "155300          [17, 103]\n",
              "155301          [17, 103]\n",
              "155302          [17, 103]\n",
              "155303          [17, 103]\n",
              "155304          [17, 103]\n",
              "155305          [17, 103]\n",
              "155306          [17, 103]\n",
              "155307                [1]\n",
              "155308                [1]\n",
              "155309                [1]\n",
              "155310                [1]\n",
              "155311                [1]\n",
              "155312                [1]\n",
              "155314               [25]\n",
              "155315               [25]\n",
              "155316               [25]\n",
              "155317               [25]\n",
              "155318               [25]\n",
              "155319               [25]\n",
              "155320      [10, 12, 169]\n",
              "Name: genres, Length: 106574, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kQUVlUKQMPPW"
      },
      "source": [
        "This dataset is bigger than many you've worked with so far, and while it should fit in Colab, it can take awhile to run. That's part of the challenge!\n",
        "\n",
        "Your tasks:\n",
        "- Clean up the variable names in the dataframe\n",
        "- Use logistic regression to fit a model predicting (primary/top) genre\n",
        "- Inspect, iterate, and improve your model\n",
        "- Answer the following questions (written, ~paragraph each):\n",
        "  - What are the best predictors of genre?\n",
        "  - What information isn't very useful for predicting genre?\n",
        "  - What surprised you the most about your results?\n",
        "\n",
        "*Important caveats*:\n",
        "- This is going to be difficult data to work with - don't let the perfect be the enemy of the good!\n",
        "- Be creative in cleaning it up - if the best way you know how to do it is download it locally and edit as a spreadsheet, that's OK!\n",
        "- If the data size becomes problematic, consider sampling/subsetting, or [downcasting numeric datatypes](https://www.dataquest.io/blog/pandas-big-data/).\n",
        "- You do not need perfect or complete results - just something plausible that runs, and that supports the reasoning in your written answers\n",
        "\n",
        "If you find that fitting a model to classify *all* genres isn't very good, it's totally OK to limit to the most frequent genres, or perhaps trying to combine or cluster genres as a preprocessing step. Even then, there will be limits to how good a model can be with just this metadata - if you really want to train an effective genre classifier, you'll have to involve the other data (see stretch goals).\n",
        "\n",
        "This is real data - there is no \"one correct answer\", so you can take this in a variety of directions. Just make sure to support your findings, and feel free to share them as well! This is meant to be practice for dealing with other \"messy\" data, a common task in data science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlI5OXfSag9C"
      },
      "source": [
        "## Resources and stretch goals\n",
        "\n",
        "- Check out the other .csv files from the FMA dataset, and see if you can join them or otherwise fit interesting models with them\n",
        "- [Logistic regression from scratch in numpy](https://blog.goodaudience.com/logistic-regression-from-scratch-in-numpy-5841c09e425f) - if you want to dig in a bit more to both the code and math (also takes a gradient descent approach, introducing the logistic loss function)\n",
        "- Create a visualization to show predictions of your model - ideally show a confidence interval based on error!\n",
        "- Check out and compare classification models from scikit-learn, such as [SVM](https://scikit-learn.org/stable/modules/svm.html#classification), [decision trees](https://scikit-learn.org/stable/modules/tree.html#classification), and [naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html). The underlying math will vary significantly, but the API (how you write the code) and interpretation will actually be fairly similar.\n",
        "- Sign up for [Kaggle](https://kaggle.com), and find a competition to try logistic regression with\n",
        "- (Not logistic regression related) If you enjoyed the assignment, you may want to read up on [music informatics](https://en.wikipedia.org/wiki/Music_informatics), which is how those audio features were actually calculated. The FMA includes the actual raw audio, so (while this is more of a longterm project than a stretch goal, and won't fit in Colab) if you'd like you can check those out and see what sort of deeper analysis you can do."
      ]
    }
  ]
}