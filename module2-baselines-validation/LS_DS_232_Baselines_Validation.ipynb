{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_232_Baselines_Validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkrant/DS-Unit-2-Sprint-3-Classification-Validation/blob/master/module2-baselines-validation/LS_DS_232_Baselines_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-c8L7bFIm6h",
        "colab_type": "text"
      },
      "source": [
        "_Lambda School Data Science — Classification & Validation_ \n",
        "\n",
        "# Baselines & Validation\n",
        "\n",
        "Objectives\n",
        "- Train/Validate/Test split\n",
        "- Cross-Validation\n",
        "- Begin with baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa9wI3VNIm6u",
        "colab_type": "text"
      },
      "source": [
        "## Weather data —  mean baseline\n",
        "\n",
        "Let's try baselines for regression.\n",
        "\n",
        "You can [get Past Weather by Zip Code from Climate.gov](https://www.climate.gov/maps-data/dataset/past-weather-zip-code-data-table). I downloaded the data for my town: Normal, Illinois."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yAynNGlIm6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "\n",
        "url = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Sprint-3-Classification-Validation/master/module2-baselines-validation/weather-normal-il.csv'\n",
        "weather = pd.read_csv(url, parse_dates=['DATE']).set_index('DATE')\n",
        "weather['2014-05':'2019-05'].plot(y='TMAX')\n",
        "plt.title('Daily high temperature in Normal, IL');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YxCoCahIm7I",
        "colab_type": "text"
      },
      "source": [
        "Over the years, across the seasons, the average daily high temperature in my town is about 63 degrees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYUtsi3RIm7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather['TMAX'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHkyMpzXIm7h",
        "colab_type": "text"
      },
      "source": [
        "Remember from [the preread:](https://github.com/LambdaSchool/DS-Unit-2-Sprint-3-Classification-Validation/blob/master/module2-baselines-validation/model-validation-preread.md#what-does-baseline-mean) \"A baseline for regression can be the mean of the training labels.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mocww6bkIm7l",
        "colab_type": "text"
      },
      "source": [
        "If I predicted that every day, the high will be 63 degrees, I'd be off by about 19 degrees on average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87VC3wPMIm7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "predicted = [weather['TMAX'].mean()] * len(weather)  \n",
        "mean_absolute_error(weather['TMAX'], predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGVwBZE7Im77",
        "colab_type": "text"
      },
      "source": [
        "But, we can get a better baseline here: \"A baseline for time-series regressions can be the value from the previous timestep.\"\n",
        "\n",
        "*Data Science for Business* explains, \n",
        "\n",
        "> Weather forecasters have two simple—but not simplistic—baseline models that they compare against. ***One (persistence) predicts that the weather tomorrow is going to be whatever it was today.*** The other (climatology) predicts whatever the average historical weather has been on this day from prior years. Each model performs considerably better than random guessing, and both are so easy to compute that they make natural baselines of comparison. Any new, more complex model must beat these."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv9CfKVYIm8A",
        "colab_type": "text"
      },
      "source": [
        "Let's predict that the weather tomorrow is going to be whatever it was today. Which is another way of saying that the weather today is going to be whatever it was yesterday.\n",
        "\n",
        "We can engineer this feature with one line of code, using the pandas [`shift`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shift.html) function.\n",
        "\n",
        "This new baseline is off by less than 6 degress on average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8eMarT7JIm8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather['TMAX_yesterday'] = weather.TMAX.shift(1)\n",
        "weather = weather.dropna()  # Drops the first date, because it doesn't have a \"yesterday\"\n",
        "mean_absolute_error(weather.TMAX, weather.TMAX_yesterday)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-sXvoAfIm8X",
        "colab_type": "text"
      },
      "source": [
        "I applied this same concept for [my first submission to the Kaggle Instacart competition.](https://github.com/rrherr/springboard/blob/master/Kaggle%20Instacart%20first%20submission.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrpyTvy5Im8c",
        "colab_type": "text"
      },
      "source": [
        "## Bank Marketing — majority class baseline\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
        "\n",
        ">The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \n",
        "\n",
        ">Output variable (desired target):  \n",
        ">y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n",
        ">bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns_nVy3QIm8i",
        "colab_type": "text"
      },
      "source": [
        "Get and read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Eo-s_zIm8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKXL1XFJIm82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip bank-additional.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI7j6I4eIm9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bank = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4GbcZFfIm9n",
        "colab_type": "text"
      },
      "source": [
        "Assign to X and y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCh_Jr-gIm9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = bank.drop(columns='y')\n",
        "y = bank['y'] == 'yes'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfRhIxkSIm9_",
        "colab_type": "text"
      },
      "source": [
        "## 3-way split: Train / Validation / Test "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM0-sPh8Im-F",
        "colab_type": "text"
      },
      "source": [
        "We know how to do a _two-way split_, with the [**`sklearn.model_selection.train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCrbGv7hIm-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTjpb6saIm-c",
        "colab_type": "text"
      },
      "source": [
        "How can we get from a two-way split, to a three-way split?\n",
        "\n",
        "We can use the same function again, to split the training data into training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1O_QIvXIm-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgZEKpe8Im-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGRzirytIm_L",
        "colab_type": "text"
      },
      "source": [
        "## Majority class baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0XGSukZIm_T",
        "colab_type": "text"
      },
      "source": [
        "Determine the majority class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e3PfHgOIm_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3lUbO2tIm_w",
        "colab_type": "text"
      },
      "source": [
        "What if we guessed the majority class for every prediction?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clkkgCRwIm_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kHtMGPXInAR",
        "colab_type": "text"
      },
      "source": [
        "#### [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
        "\n",
        "Baseline accuracy by guessing the majority class for every prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhHQkp3ZInAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6nED18DInA_",
        "colab_type": "text"
      },
      "source": [
        "#### [`sklearn.metrics.roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
        "\n",
        "Baseline \"ROC AUC\" score by guessing the majority class for every prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsWS68_uInBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld8r70GuInBz",
        "colab_type": "text"
      },
      "source": [
        "## Fast first models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_ZWobwBInB3",
        "colab_type": "text"
      },
      "source": [
        "### Ignore rows/columns with nulls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0h50ztEInB-",
        "colab_type": "text"
      },
      "source": [
        "Does this dataset have nulls?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UpEO6rSInCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBH0f7FjInCn",
        "colab_type": "text"
      },
      "source": [
        "### Ignore nonnumeric features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOKh-b0_InCt",
        "colab_type": "text"
      },
      "source": [
        "Here are the numeric features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t9SAsGhInC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y5QKHdiInDQ",
        "colab_type": "text"
      },
      "source": [
        "Here are the nonnumeric features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjF5HTqiInDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOYLk59AInDj",
        "colab_type": "text"
      },
      "source": [
        "Just select the nonnumeric features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvlkZlr1InDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_numeric = X_train.select_dtypes('number')\n",
        "X_val_numeric = X_val.select_dtypes('number')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyR1ngeOInD3",
        "colab_type": "text"
      },
      "source": [
        "### Shallow trees are good for fast, first baselines, and to look for \"leakage\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNp8SvxYInD8",
        "colab_type": "text"
      },
      "source": [
        "#### Shallow trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5uyp_IfInEB",
        "colab_type": "text"
      },
      "source": [
        "After naive baselines, *Data Science for Business* suggests [\"decision stumps.\"](https://en.wikipedia.org/wiki/Decision_stump)\n",
        "\n",
        "> A slightly more complex alternative is a model that only considers a very small amount of feature information. ...\n",
        "\n",
        "> One example is to build a \"decision stump\"—a decision tree with only one internal node, the root node. A tree limited to one internal node simply means that the tree induction selects the single most informative feature to make a decision. In a well-known paper in machine learning, [Robert Holte (1993)](https://link.springer.com/article/10.1023/A:1022631118932) showed that ***decision stumps often produce quite good baseline performance*** ...\n",
        "\n",
        "> A decision stump is an example of the strategy of ***choosing the single most informative piece of information*** available and basing all decisions on it. In some cases most of the leverage may be coming from a single feature, and this method assesses whether and to what extent this is the case.\n",
        "\n",
        "To fit a \"decision stump\" we could use a [`DecisionTreeClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) model with parameter `max_depth=1`.\n",
        "\n",
        "In this case, we'll let our tree grow a little deeper, and use the parameter `max_depth=2`\n",
        "\n",
        "In the previous code cell, we selected only the numeric features, to avoid data wrangling and save time. For now, we'll use only the numeric features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_EgYyxpInEH",
        "colab_type": "text"
      },
      "source": [
        "#### Looking for leakage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYCvZiP1InEL",
        "colab_type": "text"
      },
      "source": [
        "[Xavier Amatriain recommends,](https://www.quora.com/What-are-some-best-practices-for-training-machine-learning-models/answer/Xavier-Amatriain)\n",
        "\n",
        "\"Make sure your training features do not contain data from the “future” (aka time traveling). While this might be easy and obvious in some cases, it can get tricky. ... If your test metric becomes really good all of the sudden, ask yourself what you might be doing wrong. Chances are you are time travelling or overfitting in some way.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFclrhL-InEQ",
        "colab_type": "text"
      },
      "source": [
        "We can test this with the [UCI repository's Bank Marketing dataset](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing). It has a feature which leaks information from the future and should be dropped:\n",
        "\n",
        ">11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input ... should be discarded if the intention is to have a realistic predictive model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvLvjafmInEW",
        "colab_type": "text"
      },
      "source": [
        "#### Let's train a shallow tree basline\n",
        "\n",
        "... without dropping the leaky `duration` feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXt41l0oInEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-UcH5KsInEx",
        "colab_type": "text"
      },
      "source": [
        "Then we can visualize the tree to see which feature(s) were the \"most informative\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3kbDRFlInE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "dot_data = export_graphviz(tree, out_file=None, feature_names=X_train_numeric.columns, \n",
        "                           class_names=['No', 'Yes'], filled=True, impurity=False, proportion=True)\n",
        "\n",
        "graphviz.Source(dot_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l901x6U1InFD",
        "colab_type": "text"
      },
      "source": [
        "This baseline has a ROC AUC score above 0.85, and it uses the `duration` feature, as well as `nr.employed`, a \"social and economic context attribute\" for \"number of employees - quarterly indicator.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0RCyRXuInFS",
        "colab_type": "text"
      },
      "source": [
        "#### Let's drop the  `duration` feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tof3tyFMInFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0OSYxPdInFi",
        "colab_type": "text"
      },
      "source": [
        "When the `duration` feature is dropped, then the ROC AUC score drops. Which is what we expect, it's not a bad thing in this situation!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlLdGjKIInFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glmgmHLNInF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dot_data = export_graphviz(tree, out_file=None, feature_names=X_train_numeric.columns, \n",
        "                           class_names=['No', 'Yes'], filled=True, impurity=False, proportion=True)\n",
        "\n",
        "graphviz.Source(dot_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lbd4uaaInGK",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression\n",
        "\n",
        "Logistic Regression is another great option for fast, first baselines!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa05_WenInGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmM5a18SInGX",
        "colab_type": "text"
      },
      "source": [
        "### With Scaler\n",
        "https://scikit-learn.org/stable/modules/preprocessing.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8nsqQBuInGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T71K0W7wInGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbeVuHk4InG2",
        "colab_type": "text"
      },
      "source": [
        "### Same, as a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eknV5BJKInG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM8-JqlqInHF",
        "colab_type": "text"
      },
      "source": [
        "### Encode \"low cardinality\" categoricals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JbQ2Z7bInHJ",
        "colab_type": "text"
      },
      "source": [
        "[Cardinality](https://simple.wikipedia.org/wiki/Cardinality) means the number of unique values that a feature has:\n",
        "> In mathematics, the cardinality of a set means the number of its elements. For example, the set A = {2, 4, 6} contains 3 elements, and therefore A has a cardinality of 3. \n",
        "\n",
        "One-hot encoding adds a dimension for each unique value of each categorical feature. So, it may not be a good choice for \"high cardinality\" categoricals that have dozens, hundreds, or thousands of unique values. \n",
        "\n",
        "In this dataset, all the categoricals seem to be \"low cardinality\", so we can use one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnzPrQbvInHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMW83uYGInHg",
        "colab_type": "text"
      },
      "source": [
        "#### Install the [Category Encoders](https://github.com/scikit-learn-contrib/categorical-encoding) library\n",
        "\n",
        "If you're running on Google Colab:\n",
        "\n",
        "```\n",
        "!pip install category_encoders\n",
        "```\n",
        "\n",
        "If you're running locally with Anaconda:\n",
        "\n",
        "```\n",
        "!conda install -c conda-forge category_encoders\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaHi4Y2wInHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCxEkgHjInIa",
        "colab_type": "text"
      },
      "source": [
        "# Baseline with cross-validation + independent test set\n",
        "A complete example, as an alternative to Train/Validate/Test\n",
        "\n",
        "\n",
        "#### scikit-learn documentation\n",
        "- [`sklearn.model_selection.cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
        "- [ The `scoring` parameter: defining model evaluation rules](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbnxWLjwInIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "import category_encoders as ce\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "\n",
        "# Load data\n",
        "bank = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\n",
        "\n",
        "# Assign to X, y\n",
        "X = bank.drop(columns='y')\n",
        "y = bank['y'] == 'yes'\n",
        "\n",
        "# Drop leaky & random features\n",
        "X = X.drop(columns='duration')\n",
        "\n",
        "# Split Train, Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Make pipeline\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True), \n",
        "    StandardScaler(), \n",
        "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        ")\n",
        "\n",
        "# Cross-validate with training data\n",
        "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=10, n_jobs=-1, verbose=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLqzbBiNInI_",
        "colab_type": "text"
      },
      "source": [
        "This is the baseline score that more sophisticated models must beat. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtR9FDt3InJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Cross-Validation ROC AUC scores:', scores)\n",
        "print('Average:', scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvAh4KtLInJW",
        "colab_type": "text"
      },
      "source": [
        "Is more effort justified? It depends. The blogpost [\"Always start with a stupid model\"](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa) explains,\n",
        "\n",
        "> Here is a very common story: a team wants to implement a model to predict something like the probability of a user clicking an ad. They start with a logistic regression and quickly (after some minor tuning) reach 90% accuracy.\n",
        "\n",
        "> From there, the question is: Should the team focus on getting the accuracy up to 95%, or should they solve other problems 90% of the way?\n",
        "\n",
        "> ***If a baseline does well, then you’ve saved yourself the headache of setting up a more complex model. If it does poorly, the kind of mistakes it makes are very instructive*** ...\n",
        "\n",
        "So what else can we learn from this baseline? \n",
        "\n",
        "[\"Always start with a stupid model\"](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa) suggests to look at\n",
        "\n",
        "> **What type of signal your model picks up on.** Most baselines will allow you to extract ***feature importances***, revealing which aspects of the input are most predictive. Analyzing feature importance is a great way to realize how your model is making decisions, and what it might be missing.\n",
        "\n",
        "We can do that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7ozVYLcInJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (Re)fit on training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Visualize coefficients\n",
        "plt.figure(figsize=(10,30))\n",
        "plt.title('Coefficients')\n",
        "coefficients = pipeline.named_steps['logisticregression'].coef_[0]\n",
        "feature_names = pipeline.named_steps['onehotencoder'].transform(X_train).columns\n",
        "pd.Series(coefficients, feature_names).sort_values().plot.barh(color='gray');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8a5DxWwInJ0",
        "colab_type": "text"
      },
      "source": [
        "[The post](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa) also recommends we consider, \n",
        "\n",
        "> **What signal your model is missing.** If there is a certain aspect of the data that seems intuitively important but that your model is ignoring, ***a good next step is to engineer a feature*** or pick a different model that could better leverage this particular aspect of your data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHJnI5eDInJ6",
        "colab_type": "text"
      },
      "source": [
        "### Look at your data (you still need to do it!)\n",
        "\n",
        "Cautionary tales\n",
        "- [Exploring the ChestXray14 dataset: problems](https://lukeoakdenrayner.wordpress.com/2017/12/18/the-chestxray14-dataset-problems/)\n",
        "- [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide)\n",
        "\n",
        "Incomplete list of issues to address\n",
        "- Categoricals (text, dates/times, high cardinality)\n",
        "- Feature Engineering (extraction, interaction, transformations)\n",
        "- Missing Values\n",
        "- Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIDgbt4rInKA",
        "colab_type": "text"
      },
      "source": [
        "# ASSIGNMENT options\n",
        "\n",
        "- **Replicate the lesson code.** [Do it \"the hard way\" or with the \"Benjamin Franklin method.\"](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit)\n",
        "- Apply the lesson to other datasets you've worked with before, and compare results.\n",
        "- Iterate and improve your **Bank Marketing** model. Engineer new features.\n",
        "- Get **weather** data for your own area and calculate both baselines.  _\"One (persistence) predicts that the weather tomorrow is going to be whatever it was today. The other (climatology) predicts whatever the average historical weather has been on this day from prior years.\"_ What is the mean absolute error for each baseline? What if you average the two together? \n",
        "- [This example from scikit-learn documentation](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html) demonstrates its improved `OneHotEncoder` and new `ColumnTransformer` objects, which can replace functionality from [third-party libraries](https://github.com/scikit-learn-contrib) like category_encoders and sklearn-pandas. Adapt this example, which uses Titanic data, to work with Bank Marketing or another dataset.\n",
        "- When would this notebook's pipelines fail? How could you fix them? Add more [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) and [imputation](https://scikit-learn.org/stable/modules/impute.html) to your [pipelines](https://scikit-learn.org/stable/modules/compose.html) with scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg8KmHgCJ1yB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "363650d4-e5cf-4345-867b-e4c1b7a6389a"
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "pd.options.display.max_columns = None\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data')\n",
        "df.sample(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>MDVP:Fo(Hz)</th>\n",
              "      <th>MDVP:Fhi(Hz)</th>\n",
              "      <th>MDVP:Flo(Hz)</th>\n",
              "      <th>MDVP:Jitter(%)</th>\n",
              "      <th>MDVP:Jitter(Abs)</th>\n",
              "      <th>MDVP:RAP</th>\n",
              "      <th>MDVP:PPQ</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>MDVP:Shimmer</th>\n",
              "      <th>MDVP:Shimmer(dB)</th>\n",
              "      <th>Shimmer:APQ3</th>\n",
              "      <th>Shimmer:APQ5</th>\n",
              "      <th>MDVP:APQ</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>status</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>spread1</th>\n",
              "      <th>spread2</th>\n",
              "      <th>D2</th>\n",
              "      <th>PPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>phon_R01_S24_1</td>\n",
              "      <td>125.036</td>\n",
              "      <td>143.946</td>\n",
              "      <td>116.187</td>\n",
              "      <td>0.01280</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>0.00743</td>\n",
              "      <td>0.00623</td>\n",
              "      <td>0.02228</td>\n",
              "      <td>0.03886</td>\n",
              "      <td>0.342</td>\n",
              "      <td>0.02135</td>\n",
              "      <td>0.02174</td>\n",
              "      <td>0.03088</td>\n",
              "      <td>0.06406</td>\n",
              "      <td>0.08151</td>\n",
              "      <td>15.338</td>\n",
              "      <td>1</td>\n",
              "      <td>0.629574</td>\n",
              "      <td>0.714485</td>\n",
              "      <td>-4.020042</td>\n",
              "      <td>0.265315</td>\n",
              "      <td>2.671825</td>\n",
              "      <td>0.340623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>phon_R01_S44_6</td>\n",
              "      <td>149.818</td>\n",
              "      <td>163.417</td>\n",
              "      <td>144.786</td>\n",
              "      <td>0.00336</td>\n",
              "      <td>0.00002</td>\n",
              "      <td>0.00174</td>\n",
              "      <td>0.00198</td>\n",
              "      <td>0.00521</td>\n",
              "      <td>0.02145</td>\n",
              "      <td>0.198</td>\n",
              "      <td>0.01155</td>\n",
              "      <td>0.01341</td>\n",
              "      <td>0.01666</td>\n",
              "      <td>0.03464</td>\n",
              "      <td>0.00595</td>\n",
              "      <td>23.008</td>\n",
              "      <td>1</td>\n",
              "      <td>0.329577</td>\n",
              "      <td>0.757180</td>\n",
              "      <td>-6.277170</td>\n",
              "      <td>0.109397</td>\n",
              "      <td>2.209021</td>\n",
              "      <td>0.156368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
              "97   phon_R01_S24_1      125.036       143.946       116.187         0.01280   \n",
              "182  phon_R01_S44_6      149.818       163.417       144.786         0.00336   \n",
              "\n",
              "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
              "97            0.00010   0.00743   0.00623     0.02228       0.03886   \n",
              "182           0.00002   0.00174   0.00198     0.00521       0.02145   \n",
              "\n",
              "     MDVP:Shimmer(dB)  Shimmer:APQ3  Shimmer:APQ5  MDVP:APQ  Shimmer:DDA  \\\n",
              "97              0.342       0.02135       0.02174   0.03088      0.06406   \n",
              "182             0.198       0.01155       0.01341   0.01666      0.03464   \n",
              "\n",
              "         NHR     HNR  status      RPDE       DFA   spread1   spread2  \\\n",
              "97   0.08151  15.338       1  0.629574  0.714485 -4.020042  0.265315   \n",
              "182  0.00595  23.008       1  0.329577  0.757180 -6.277170  0.109397   \n",
              "\n",
              "           D2       PPE  \n",
              "97   2.671825  0.340623  \n",
              "182  2.209021  0.156368  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ7hasGYJ3gv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "26866ac1-566b-4c35-b146-26efce650fff"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name                0\n",
              "MDVP:Fo(Hz)         0\n",
              "MDVP:Fhi(Hz)        0\n",
              "MDVP:Flo(Hz)        0\n",
              "MDVP:Jitter(%)      0\n",
              "MDVP:Jitter(Abs)    0\n",
              "MDVP:RAP            0\n",
              "MDVP:PPQ            0\n",
              "Jitter:DDP          0\n",
              "MDVP:Shimmer        0\n",
              "MDVP:Shimmer(dB)    0\n",
              "Shimmer:APQ3        0\n",
              "Shimmer:APQ5        0\n",
              "MDVP:APQ            0\n",
              "Shimmer:DDA         0\n",
              "NHR                 0\n",
              "HNR                 0\n",
              "status              0\n",
              "RPDE                0\n",
              "DFA                 0\n",
              "spread1             0\n",
              "spread2             0\n",
              "D2                  0\n",
              "PPE                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJx-64b7K_hy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "ea402fdb-3e20-4fe7-9b62-40d52e8130df"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name                 object\n",
              "MDVP:Fo(Hz)         float64\n",
              "MDVP:Fhi(Hz)        float64\n",
              "MDVP:Flo(Hz)        float64\n",
              "MDVP:Jitter(%)      float64\n",
              "MDVP:Jitter(Abs)    float64\n",
              "MDVP:RAP            float64\n",
              "MDVP:PPQ            float64\n",
              "Jitter:DDP          float64\n",
              "MDVP:Shimmer        float64\n",
              "MDVP:Shimmer(dB)    float64\n",
              "Shimmer:APQ3        float64\n",
              "Shimmer:APQ5        float64\n",
              "MDVP:APQ            float64\n",
              "Shimmer:DDA         float64\n",
              "NHR                 float64\n",
              "HNR                 float64\n",
              "status                int64\n",
              "RPDE                float64\n",
              "DFA                 float64\n",
              "spread1             float64\n",
              "spread2             float64\n",
              "D2                  float64\n",
              "PPE                 float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYSE7d8SLFgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9734eb87-f245-4a9a-926d-7fd7a4901908"
      },
      "source": [
        "df.status.value_counts(normalize=True) # 1 = Parkinson's   0 = healthy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.753846\n",
              "0    0.246154\n",
              "Name: status, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKhTeBzQNAjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0cb54cd-5278-4a07-e296-06e0d6f0970c"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M33fJciNMJoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(columns=['status', 'name'])\n",
        "y = df['status']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6a7XyXVO1qS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "504c8cf5-fe1f-403f-ad60-985915f7f3d4"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MDVP:Fo(Hz)</th>\n",
              "      <th>MDVP:Fhi(Hz)</th>\n",
              "      <th>MDVP:Flo(Hz)</th>\n",
              "      <th>MDVP:Jitter(%)</th>\n",
              "      <th>MDVP:Jitter(Abs)</th>\n",
              "      <th>MDVP:RAP</th>\n",
              "      <th>MDVP:PPQ</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>MDVP:Shimmer</th>\n",
              "      <th>MDVP:Shimmer(dB)</th>\n",
              "      <th>Shimmer:APQ3</th>\n",
              "      <th>Shimmer:APQ5</th>\n",
              "      <th>MDVP:APQ</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>status</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>spread1</th>\n",
              "      <th>spread2</th>\n",
              "      <th>D2</th>\n",
              "      <th>PPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>154.228641</td>\n",
              "      <td>197.104918</td>\n",
              "      <td>116.324631</td>\n",
              "      <td>0.006220</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.003306</td>\n",
              "      <td>0.003446</td>\n",
              "      <td>0.009920</td>\n",
              "      <td>0.029709</td>\n",
              "      <td>0.282251</td>\n",
              "      <td>0.015664</td>\n",
              "      <td>0.017878</td>\n",
              "      <td>0.024081</td>\n",
              "      <td>0.046993</td>\n",
              "      <td>0.024847</td>\n",
              "      <td>21.885974</td>\n",
              "      <td>0.753846</td>\n",
              "      <td>0.498536</td>\n",
              "      <td>0.718099</td>\n",
              "      <td>-5.684397</td>\n",
              "      <td>0.226510</td>\n",
              "      <td>2.381826</td>\n",
              "      <td>0.206552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>41.390065</td>\n",
              "      <td>91.491548</td>\n",
              "      <td>43.521413</td>\n",
              "      <td>0.004848</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.002968</td>\n",
              "      <td>0.002759</td>\n",
              "      <td>0.008903</td>\n",
              "      <td>0.018857</td>\n",
              "      <td>0.194877</td>\n",
              "      <td>0.010153</td>\n",
              "      <td>0.012024</td>\n",
              "      <td>0.016947</td>\n",
              "      <td>0.030459</td>\n",
              "      <td>0.040418</td>\n",
              "      <td>4.425764</td>\n",
              "      <td>0.431878</td>\n",
              "      <td>0.103942</td>\n",
              "      <td>0.055336</td>\n",
              "      <td>1.090208</td>\n",
              "      <td>0.083406</td>\n",
              "      <td>0.382799</td>\n",
              "      <td>0.090119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>88.333000</td>\n",
              "      <td>102.145000</td>\n",
              "      <td>65.476000</td>\n",
              "      <td>0.001680</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000920</td>\n",
              "      <td>0.002040</td>\n",
              "      <td>0.009540</td>\n",
              "      <td>0.085000</td>\n",
              "      <td>0.004550</td>\n",
              "      <td>0.005700</td>\n",
              "      <td>0.007190</td>\n",
              "      <td>0.013640</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>8.441000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.256570</td>\n",
              "      <td>0.574282</td>\n",
              "      <td>-7.964984</td>\n",
              "      <td>0.006274</td>\n",
              "      <td>1.423287</td>\n",
              "      <td>0.044539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>117.572000</td>\n",
              "      <td>134.862500</td>\n",
              "      <td>84.291000</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>0.004985</td>\n",
              "      <td>0.016505</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>0.008245</td>\n",
              "      <td>0.009580</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.024735</td>\n",
              "      <td>0.005925</td>\n",
              "      <td>19.198000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.421306</td>\n",
              "      <td>0.674758</td>\n",
              "      <td>-6.450096</td>\n",
              "      <td>0.174351</td>\n",
              "      <td>2.099125</td>\n",
              "      <td>0.137451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>148.790000</td>\n",
              "      <td>175.829000</td>\n",
              "      <td>104.315000</td>\n",
              "      <td>0.004940</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.002690</td>\n",
              "      <td>0.007490</td>\n",
              "      <td>0.022970</td>\n",
              "      <td>0.221000</td>\n",
              "      <td>0.012790</td>\n",
              "      <td>0.013470</td>\n",
              "      <td>0.018260</td>\n",
              "      <td>0.038360</td>\n",
              "      <td>0.011660</td>\n",
              "      <td>22.085000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.495954</td>\n",
              "      <td>0.722254</td>\n",
              "      <td>-5.720868</td>\n",
              "      <td>0.218885</td>\n",
              "      <td>2.361532</td>\n",
              "      <td>0.194052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>182.769000</td>\n",
              "      <td>224.205500</td>\n",
              "      <td>140.018500</td>\n",
              "      <td>0.007365</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.003835</td>\n",
              "      <td>0.003955</td>\n",
              "      <td>0.011505</td>\n",
              "      <td>0.037885</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.020265</td>\n",
              "      <td>0.022380</td>\n",
              "      <td>0.029400</td>\n",
              "      <td>0.060795</td>\n",
              "      <td>0.025640</td>\n",
              "      <td>25.075500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.587562</td>\n",
              "      <td>0.761881</td>\n",
              "      <td>-5.046192</td>\n",
              "      <td>0.279234</td>\n",
              "      <td>2.636456</td>\n",
              "      <td>0.252980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>260.105000</td>\n",
              "      <td>592.030000</td>\n",
              "      <td>239.170000</td>\n",
              "      <td>0.033160</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.021440</td>\n",
              "      <td>0.019580</td>\n",
              "      <td>0.064330</td>\n",
              "      <td>0.119080</td>\n",
              "      <td>1.302000</td>\n",
              "      <td>0.056470</td>\n",
              "      <td>0.079400</td>\n",
              "      <td>0.137780</td>\n",
              "      <td>0.169420</td>\n",
              "      <td>0.314820</td>\n",
              "      <td>33.047000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.685151</td>\n",
              "      <td>0.825288</td>\n",
              "      <td>-2.434031</td>\n",
              "      <td>0.450493</td>\n",
              "      <td>3.671155</td>\n",
              "      <td>0.527367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
              "count   195.000000    195.000000    195.000000      195.000000   \n",
              "mean    154.228641    197.104918    116.324631        0.006220   \n",
              "std      41.390065     91.491548     43.521413        0.004848   \n",
              "min      88.333000    102.145000     65.476000        0.001680   \n",
              "25%     117.572000    134.862500     84.291000        0.003460   \n",
              "50%     148.790000    175.829000    104.315000        0.004940   \n",
              "75%     182.769000    224.205500    140.018500        0.007365   \n",
              "max     260.105000    592.030000    239.170000        0.033160   \n",
              "\n",
              "       MDVP:Jitter(Abs)    MDVP:RAP    MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
              "count        195.000000  195.000000  195.000000  195.000000    195.000000   \n",
              "mean           0.000044    0.003306    0.003446    0.009920      0.029709   \n",
              "std            0.000035    0.002968    0.002759    0.008903      0.018857   \n",
              "min            0.000007    0.000680    0.000920    0.002040      0.009540   \n",
              "25%            0.000020    0.001660    0.001860    0.004985      0.016505   \n",
              "50%            0.000030    0.002500    0.002690    0.007490      0.022970   \n",
              "75%            0.000060    0.003835    0.003955    0.011505      0.037885   \n",
              "max            0.000260    0.021440    0.019580    0.064330      0.119080   \n",
              "\n",
              "       MDVP:Shimmer(dB)  Shimmer:APQ3  Shimmer:APQ5    MDVP:APQ  Shimmer:DDA  \\\n",
              "count        195.000000    195.000000    195.000000  195.000000   195.000000   \n",
              "mean           0.282251      0.015664      0.017878    0.024081     0.046993   \n",
              "std            0.194877      0.010153      0.012024    0.016947     0.030459   \n",
              "min            0.085000      0.004550      0.005700    0.007190     0.013640   \n",
              "25%            0.148500      0.008245      0.009580    0.013080     0.024735   \n",
              "50%            0.221000      0.012790      0.013470    0.018260     0.038360   \n",
              "75%            0.350000      0.020265      0.022380    0.029400     0.060795   \n",
              "max            1.302000      0.056470      0.079400    0.137780     0.169420   \n",
              "\n",
              "              NHR         HNR      status        RPDE         DFA     spread1  \\\n",
              "count  195.000000  195.000000  195.000000  195.000000  195.000000  195.000000   \n",
              "mean     0.024847   21.885974    0.753846    0.498536    0.718099   -5.684397   \n",
              "std      0.040418    4.425764    0.431878    0.103942    0.055336    1.090208   \n",
              "min      0.000650    8.441000    0.000000    0.256570    0.574282   -7.964984   \n",
              "25%      0.005925   19.198000    1.000000    0.421306    0.674758   -6.450096   \n",
              "50%      0.011660   22.085000    1.000000    0.495954    0.722254   -5.720868   \n",
              "75%      0.025640   25.075500    1.000000    0.587562    0.761881   -5.046192   \n",
              "max      0.314820   33.047000    1.000000    0.685151    0.825288   -2.434031   \n",
              "\n",
              "          spread2          D2         PPE  \n",
              "count  195.000000  195.000000  195.000000  \n",
              "mean     0.226510    2.381826    0.206552  \n",
              "std      0.083406    0.382799    0.090119  \n",
              "min      0.006274    1.423287    0.044539  \n",
              "25%      0.174351    2.099125    0.137451  \n",
              "50%      0.218885    2.361532    0.194052  \n",
              "75%      0.279234    2.636456    0.252980  \n",
              "max      0.450493    3.671155    0.527367  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUUnIsdwMz2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "55269ea3-23c6-4d52-f1fe-4888c7661c68"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
              "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
              "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
              "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA', 'spread1',\n",
              "       'spread2', 'D2', 'PPE'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSW-ZfVzM6gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLZ1zEQzM9RB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "62c4e659-a677-4ba3-a169-1c12031c3c75"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(), \n",
        "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        ")\n",
        "\n",
        "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=10, n_jobs=-1, verbose=10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0250s.) Setting batch_size=256.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0250s.) Setting batch_size=16.\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eaVi2E5TLaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a22c6bc7-52b9-4e8c-ae04-d2ebd1ed0be4"
      },
      "source": [
        "scores"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.875     , 0.83333333, 0.9375    , 0.97916667, 0.77083333,\n",
              "       0.89583333, 0.95833333, 0.8125    , 1.        , 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRGcWVobUSlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1695
        },
        "outputId": "28e5c20e-2863-4759-a44a-93c6116f8843"
      },
      "source": [
        "# (Re)fit on training data\n",
        "import matplotlib.pyplot as plt\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Visualize coefficients\n",
        "plt.figure(figsize=(10,30))\n",
        "plt.title('Coefficients')\n",
        "coefficients = pipeline.named_steps['logisticregression'].coef_[0]\n",
        "feature_names = X.columns.tolist()#pipeline.named_steps['onehotencoder'].transform(X_train).columns\n",
        "pd.Series(coefficients, feature_names).sort_values().plot.barh(color='gray');"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAaOCAYAAABxwKRaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x2160 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7_bZU0pUq3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}